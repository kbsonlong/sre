[{"categories":["VSCode"],"content":"打开setting.json \"[markdown]\": { \"editor.quickSuggestions\": true } ","date":"2022-09-11","objectID":"/post/4faa15/:0:1","tags":["vscode","snippets"],"title":"VSCode 配置Markdown模板","uri":"/post/4faa15/"},{"categories":["VSCode"],"content":"配置模板 Ctrl + Shift + P 输入snippet 点击首选项：配置用户代码片片段 选择markdown.json ","date":"2022-09-11","objectID":"/post/4faa15/:0:2","tags":["vscode","snippets"],"title":"VSCode 配置Markdown模板","uri":"/post/4faa15/"},{"categories":["VSCode"],"content":"编写模板 { // Place your snippets for markdown here. Each snippet is defined under a snippet name and has a prefix, body and // description. The prefix is what is used to trigger the snippet and the body will be expanded and inserted. Possible variables are: // $1, $2 for tab stops, $0 for the final cursor position, and ${1:label}, ${2:another} for placeholders. Placeholders with the // same ids are connected. // Example: // \"Print to console\": { // \"prefix\": \"log\", // \"body\": [ // \"console.log('$1');\", // \"$2\" // ], // \"description\": \"Log output to console\" // } \"blog meta template\": { \"prefix\": \"meta\", \"body\": [ \"---\", \"title: ${TM_FILENAME_BASE}\", \"slug: ${RANDOM_HEX}\", \"date: ${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:${CURRENT_SECOND}+08:00\", \"draft: false\", \"author: kbsonlong\", \"authorEmail: kbsonlong@gmail.com\", \"tags: [${1}]\", \"categories: [${2}]\", \"featuredImage: https://imgapi.cn/api.php?zd=zsy\u0026fl=meizi\u0026random=${RANDOM}\", \"---\" ] }, \"last modifier time\": { \"prefix\": \"last\", \"body\": \"${CURRENT_YEAR}-${CURRENT_MONTH}-${CURRENT_DATE}T${CURRENT_HOUR}:${CURRENT_MINUTE}:${CURRENT_SECOND}+08:00\" }, \"more themplate\" :{ \"prefix\": \"more\", \"body\": \"\u003c!--more--\u003e\", \"description\": \"文章摘要手动分割\" } } ","date":"2022-09-11","objectID":"/post/4faa15/:0:3","tags":["vscode","snippets"],"title":"VSCode 配置Markdown模板","uri":"/post/4faa15/"},{"categories":["VSCode"],"content":"常用变量 TM_SELECTED_TEXT 当前选定的文本或空字符串 TM_CURRENT_LINE 当前行的内容 TM_CURRENT_WORD 光标下的单词的内容或空字符串 TM_LINE_INDEX 基于零索引的行号 TM_LINE_NUMBER 基于一索引的行号 TM_FILENAME 当前文档的文件名 TM_FILENAME_BASE 当前文档的文件名（不含后缀名) TM_DIRECTORY 当前文档的目录 RELATIVE_FILEPATH 当前文件的相对目录 TM_FILEPATH 当前文档的完整文件路径 CLIPBOARD 剪切板里的内容 CURRENT_YEAR 当前年(四位数) CURRENT_MONTH 当前月 CURRENT_DATE 当前日 CURRENT_DAY_NAME_SHORT 当天的短名称（’Mon’） CURRENT_HOUR 当前小时 CURRENT_MINUTE 当前分钟 CURRENT_SECOND 当前秒 插入随机值 RANDOM 6位随机10进制数 RANDOM_HEX 6位16进制数 UUID 一个版本4的UUID /** 286055 f570d8 0a831688-a7f1-4668-9964-f6100114792c */ BLOCK_COMMENT_START 块注释开始标识,如 PHP /* 或 HTML \u003c!-- BLOCK_COMMENT_END 块注释结束标识,如 PHP */ 或 HTML --\u003e LINE_COMMENT 行注释，如： PHP // 或 HTML \u003c!-- --\u003e ","date":"2022-09-11","objectID":"/post/4faa15/:0:4","tags":["vscode","snippets"],"title":"VSCode 配置Markdown模板","uri":"/post/4faa15/"},{"categories":["云原生"],"content":"准备工作 S2I自定义镜像构建器 ● assemble（必需）：从源代码构建应用程序制品的脚本 assemble。 ● run（必需）：用于运行应用程序的脚本。 ● save-artifacts（可选）：管理增量构建过程中的所有依赖。 ● usage（可选）：提供说明的脚本。 ● test （可选）：用于测试的脚本。 ","date":"2022-09-11","objectID":"/post/d83d7d/:0:1","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["云原生"],"content":"创建镜像构建器 准备S2I目录 安装s2i wget https://github.com/openshift/source-to-image/releases/download/v1.2.04/source-to-image-v1.1.14-874754de-linux-386.tar.gz tar -xvf source-to-image-v1.1.14-874754de-linux-386.tar.gz ls s2i source-to-image-v1.1.14-874754de-linux-386.tar.gz sti cp s2i /usr/local/bin 初始化镜像构建器 s2i create java-ubuntu22 java-ubuntu22 cd java-ubuntu22 目录结构初始化 . ├── Dockerfile ├── Makefile ├── README.md ├── prometheus-config.yml ├── s2i │ └── bin │ ├── assemble │ ├── run │ ├── save-artifacts │ └── usage └── test ├── run └── test-app ├── b2i-jar-java8.jar ## 默认不存在 └── index.html 4 directories, 11 files ","date":"2022-09-11","objectID":"/post/d83d7d/:0:2","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["云原生"],"content":"修改Dockerfile # java-ubuntu22 FROM ubuntu:22.04 # TODO: Put the maintainer name in the image metadata # LABEL maintainer=\"Your Name \u003cyour@email.com\u003e\" # TODO: Rename the builder environment variable to inform users about application you provide them # ENV BUILDER_VERSION 1.0 # TODO: Set labels used in OpenShift to describe the builder image LABEL io.k8s.description=\"Java 8 web application\" \\ io.k8s.display-name=\"Java 8 Web\" \\ io.openshift.expose-services=\"8080:http\" \\ io.openshift.tags=\"builder,java,web\" \\ # this label tells s2i where to find its mandatory scripts # (run, assemble, save-artifacts) io.openshift.s2i.scripts-url=\"image:///usr/libexec/s2i\" # TODO: Install required packages here: # RUN yum install -y ... \u0026\u0026 yum clean all -y RUN apt-get update \u0026\u0026 apt-get install -y \\ curl \\ wget \\ openjdk-8-jdk \u0026\u0026 \\ rm -rf /var/lib/apt/lists WORKDIR /opt # TODO (optional): Copy the builder files into /opt/app-root # COPY ./\u003cbuilder_folder\u003e/ /opt/app-root/ # TODO: Copy the S2I scripts to /usr/libexec/s2i, since openshift/base-centos7 image # sets io.openshift.s2i.scripts-url label that way, or update that label COPY ./s2i/bin/ /usr/libexec/s2i # TODO: Drop the root user and make the content of /opt/app-root owned by user 1001 # RUN chown -R 1001:1001 /opt/app-root RUN chgrp -R 0 /usr/libexec/s2i \\ \u0026\u0026 chmod -R u=rwx,go=rx /usr/libexec/s2i \u0026\u0026 \\ chgrp -R 0 /opt \\ \u0026\u0026 chmod -R u=rwx,go=rx /opt \u0026\u0026 \\ chown -R 1001:1001 /opt \u0026\u0026 \\ chown -R 1001:1001 /usr/libexec/s2i/assemble RUN mkdir -p /opt/prometheus/etc \\ \u0026\u0026 curl https://repo1.maven.org/maven2/io/prometheus/jmx/jmx_prometheus_javaagent/0.17.0/jmx_prometheus_javaagent-0.17.0.jar \\ -o /opt/prometheus/jmx_prometheus_javaagent.jar COPY prometheus-config.yml /opt/prometheus/etc # This default user is created in the openshift/base-centos7 image USER 1001 # TODO: Set the default port for applications built using this image EXPOSE 8080 # TODO: Set the default CMD for the image CMD [\"/usr/libexec/s2i/usage\"] ","date":"2022-09-11","objectID":"/post/d83d7d/:0:3","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["云原生"],"content":"修改S2I脚本 assemble #!/bin/bash -e # # S2I assemble script for the 'java-ubuntu22' image. # The 'assemble' script builds your application source so that it is ready to run. # # For more information refer to the documentation: # https://github.com/openshift/source-to-image/blob/master/docs/builder_image.md # # If the 'java-ubuntu22' assemble script is executed with the '-h' flag, print the usage. if [[ \"$1\" == \"-h\" ]]; then exec /usr/libexec/s2i/usage fi # Restore artifacts from the previous build (if they exist). # echo \"---\u003e Installing application...\" mkdir -p /opt/app ls /tmp/src/* mv /tmp/src/* /opt/app/ chmod +x /opt/app/*.jar 默认情况下，s2i build将应用程序源代码放在/tmp/src。上述命令将应用程序jar包复制到/opt/app/目录下 run #!/bin/bash -e # # S2I run script for the 'java-ubuntu22' image. # The run script executes the server that runs your application. # # For more information see the documentation: # https://github.com/openshift/source-to-image/blob/master/docs/builder_image.md # PROMETHEUS_JMX_OPTS=\"-javaagent:/opt/prometheus/jmx_prometheus_javaagent.jar=${PROMETHEUS_JMX_PORT}:/opt/prometheus/etc/prometheus-config.yml\" # Always include jolokia-opts, which can be empty if switched off via env JAVA_OPTIONS=\"${JAVA_OPTIONS:+${JAVA_OPTIONS} }\" # Temporary options variable until the harmonization hawt-app PR #5 has been applied (hopefully) JVM_ARGS=\"${JVM_ARGS:+${JVM_ARGS} }${JAVA_OPTIONS} ${PROMETHEUS_JMX_OPTS}\" export JAVA_OPTIONS JVM_ARGS PROMETHEUS_JMX_OPTS exec java -jar ${JVM_ARGS} /opt/app/app.jar ","date":"2022-09-11","objectID":"/post/d83d7d/:0:4","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["云原生"],"content":"构建与运行 创建镜像构建器 make build 使用镜像构建器创建应用程序镜像 # s2i build ./test/test-app java-ubuntu22 sample-app ---\u003e Installing application... /tmp/src/b2i-jar-java8.jar /tmp/src/index.html Build completed successfully 按照assemble脚本定义的逻辑，S2I使用镜像构建器作为基础创建应用程序镜像，并从test/test-app目录注入源代码。 测试运行应用程序镜像 # docker run -p 8080:8080 -p 12345:12345 -e PROMETHEUS_JMX_PORT=12345 sample-app . ____ _ __ _ _ /\\\\ / ___'_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ ( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\ \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) ' |____| .__|_| |_|_| |_\\__, | / / / / =========|_|==============|___/=/_/_/_/ :: Spring Boot :: (v1.4.1.BUILD-SNAPSHOT) 2022-07-28 07:51:48.829 INFO 1 --- [ main] io.kubesphere.devops.Application : Starting Application v0.0.1-SNAPSHOT on 322634c30cc2 with PID 1 (/opt/app/app.jar started by ? in /opt) 2022-07-28 07:51:48.839 INFO 1 --- [ main] io.kubesphere.devops.Application : No active profile set, falling back to default profiles: default 2022-07-28 07:51:48.906 INFO 1 --- [ main] ationConfigEmbeddedWebApplicationContext : Refreshing org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5ae50ce6: startup date [Thu Jul 28 07:51:48 GMT 2022]; root of context hierarchy 2022-07-28 07:51:49.694 INFO 1 --- [ main] s.b.c.e.t.TomcatEmbeddedServletContainer : Tomcat initialized with port(s): 8080 (http) 2022-07-28 07:51:49.700 INFO 1 --- [ main] o.apache.catalina.core.StandardService : Starting service Tomcat 2022-07-28 07:51:49.701 INFO 1 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet Engine: Apache Tomcat/8.5.5 2022-07-28 07:51:49.749 INFO 1 --- [ost-startStop-1] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 2022-07-28 07:51:49.749 INFO 1 --- [ost-startStop-1] o.s.web.context.ContextLoader : Root WebApplicationContext: initialization completed in 845 ms 2022-07-28 07:51:49.820 INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.ServletRegistrationBean : Mapping servlet: 'dispatcherServlet' to [/] 2022-07-28 07:51:49.822 INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'characterEncodingFilter' to: [/*] 2022-07-28 07:51:49.822 INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'hiddenHttpMethodFilter' to: [/*] 2022-07-28 07:51:49.823 INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'httpPutFormContentFilter' to: [/*] 2022-07-28 07:51:49.823 INFO 1 --- [ost-startStop-1] o.s.b.w.servlet.FilterRegistrationBean : Mapping filter: 'requestContextFilter' to: [/*] 2022-07-28 07:51:49.988 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerAdapter : Looking for @ControllerAdvice: org.springframework.boot.context.embedded.AnnotationConfigEmbeddedWebApplicationContext@5ae50ce6: startup date [Thu Jul 28 07:51:48 GMT 2022]; root of context hierarchy 2022-07-28 07:51:50.047 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/]}\" onto public java.lang.String io.kubesphere.devops.HelloWorldController.sayHello() 2022-07-28 07:51:50.050 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/error],produces=[text/html]}\" onto public org.springframework.web.servlet.ModelAndView org.springframework.boot.autoconfigure.web.BasicErrorController.errorHtml(javax.servlet.http.HttpServletRequest,javax.servlet.http.HttpServletResponse) 2022-07-28 07:51:50.050 INFO 1 --- [ main] s.w.s.m.m.a.RequestMappingHandlerMapping : Mapped \"{[/error]}\" onto public org.springframework.http.ResponseEntity\u003cjava.util.Map\u003cjava.lang.String, java.lang.Object\u003e\u003e org.springframework.boot.autoconfigure.web.BasicErrorController.error(javax.servlet.http.HttpServletRequest) 2022-07-28 07:51:50.063 INFO 1 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping : Mapped URL path [/webjars/**] onto handler of type [class org.springframework.web.servlet.resource.ResourceHttpRequestHandler] 2022-07-28 07:51:50.063 INFO 1 --- [ main] o.s.w.s.handler.SimpleUrlHandlerMapping :","date":"2022-09-11","objectID":"/post/d83d7d/:0:5","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["云原生"],"content":"自定义S2I模板 apiVersion: devops.kubesphere.io/v1alpha1 kind: S2iBuilderTemplate metadata: labels: controller-tools.k8s.io: \"1.0\" builder-type.kubesphere.io/s2i: \"s2i\" name: java-ubuntu spec: containerInfo: - builderImage: java-ubuntu22 ## 自定义的镜像构建器镜像 codeFramework: java # type of code framework defaultBaseImage: java-ubuntu22 # default Image Builder (can be replaced by a customized image) version: 0.0.1 # Builder template version description: \"模板描述\" # Builder template description kubectl apply -f s2ibuildertemplate.yaml 标签名称 选项 定义 builder-type.kubesphere.io/s2i “s2i” 模板类型为 S2I，基于应用程序源代码构建镜像。 builder-type.kubesphere.io/b2i “b2i” 模板类型为 B2I，基于二进制文件或其他制品构建镜像。 binary-type.kubesphere.io “jar”,“war”,“binary” 该类型为 B2I 类型的补充，在选择 B2I 类型时需要。例如，当提供 Jar 包时，选择 “jar” 类型。在 KubeSphere v2.1.1 及更高版本，允许自定义 B2I 模板。 官方demo apiVersion: devops.kubesphere.io/v1alpha1 kind: S2iBuilderTemplate metadata: annotations: descriptionCN: Java 应用的构建器模版。通过该模版可构建出直接运行的应用镜像。 descriptionEN: This is a builder template for Java builds whose result can be run directly without any further application server.It's suited ideally for microservices with a flat classpath (including \"far jars\"). devops.kubesphere.io/s2i-template-url: https://github.com/kubesphere/s2i-java-container/blob/master/java/images helm.sh/hook: pre-install labels: binary-type.kubesphere.io: jar builder-type.kubesphere.io/b2i: b2i builder-type.kubesphere.io/s2i: s2i controller-tools.k8s.io: \"1.0\" name: java spec: codeFramework: java containerInfo: - buildVolumes: - s2i_java_cache:/tmp/artifacts builderImage: kubesphere/java-8-centos7:v3.2.0 runtimeArtifacts: - source: /deployments runtimeImage: kubesphere/java-8-runtime:v3.2.0 - buildVolumes: - s2i_java_cache:/tmp/artifacts builderImage: kubesphere/java-11-centos7:v3.2.0 runtimeArtifacts: - source: /deployments runtimeImage: kubesphere/java-11-runtime:v3.2.0 defaultBaseImage: kubesphere/java-8-centos7:v3.2.0 description: This is a builder template for Java builds whose result can be run directly without any further application server.It's suited ideally for microservices with a flat classpath (including \"far jars\") environment: - defaultValue: \"\" description: Arguments to use when calling Maven, replacing the default package hawt-app:build -DskipTests -e. Please be sure to run the hawt-app:build goal (when not already bound to the package execution phase), otherwise the startup scripts won't work. key: MAVEN_ARGS required: false type: string - defaultValue: \"\" description: Additional Maven arguments, useful for temporary adding arguments like -X or -am -pl . key: MAVEN_ARGS_APPEND required: false type: string - defaultValue: \"\" description: With Repositories you specify from which locations you want to download certain artifacts, such as dependencies and maven-plugins. key: MAVEN_MIRROR_URL required: false type: string - defaultValue: \"\" description: If set then the Maven repository is removed after the artifact is built. This is useful for keeping the created application image small, but prevents incremental builds. The default is false key: MAVEN_CLEAR_REPO required: false type: boolean - defaultValue: \"\" description: Path to target/ where the jar files are created for multi module builds. These are added to ${MAVEN_ARGS} key: ARTIFACT_DIR required: false type: string - defaultValue: \"\" description: Arguments to use when copying artifacts from the output dir to the application dir. Useful to specify which artifacts will be part of the image. It defaults to -r hawt-app/* when a hawt-app dir is found on the build directory, otherwise jar files only will be included (*.jar). key: ARTIFACT_COPY_ARGS required: false type: string - defaultValue: \"\" description: the directory where the application resides. All paths in your application are relative to this directory. By default it is the same directory where this startup script resides. key: JAVA_APP_DIR required: false type: string - defaultValue: \"\" description: directory holding the Java jar files as well a","date":"2022-09-11","objectID":"/post/d83d7d/:0:6","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["云原生"],"content":"参考资料 s2i-base-container s2i-java-container s2i-java-runtimeImage ","date":"2022-09-11","objectID":"/post/d83d7d/:0:7","tags":["kubesphere","operator"],"title":"S2I自定义构建器和模板","uri":"/post/d83d7d/"},{"categories":["golang"],"content":"初始化demo项目 mkdir -p gin-middleware-demo cd gin-middleware-demo go mod init github.com/kbsonlong/gin-middleware-demo middleware/middle.go package middleware import ( \"fmt\" \"time\" \"github.com/gin-gonic/gin\" ) func MdOne() gin.HandlerFunc { return func(c *gin.Context) { fmt.Println(\"开始执行第一个 gin 中间件:\" + time.Now().String()) c.Next() fmt.Println(\"第一个 gin 中间件返回内容:\" + time.Now().String()) } } func MdTwo() gin.HandlerFunc { return func(c *gin.Context) { fmt.Println(\"开始执行第二个 gin 中间件:\" + time.Now().String()) c.Next() fmt.Println(\"第二个 gin 中间件返回内容:\" + time.Now().String()) } } func MdThree() gin.HandlerFunc { return func(c *gin.Context) { fmt.Println(\"开始执行第三个 gin 中间件:\" + time.Now().String()) c.Next() fmt.Println(\"第三个 gin 中间件返回内容:\" + time.Now().String()) } } routers/router.go package routers import ( \"github.com/gin-gonic/gin\" \"github.com/kbsonlong/gin-middleware-demo/middleware\" ) func InitRouter() *gin.Engine { r := gin.New() r.Use(middleware.MdOne()) r.Use(middleware.MdTwo()) r.Use(middleware.MdThree()) gin.SetMode(\"debug\") r.GET(\"/\", func(ctx *gin.Context) { ctx.JSON(200, gin.H{ \"message\": \"test\", }) }) return r } main.go package main import ( \"github.com/kbsonlong/gin-middleware-demo/routers\" ) func main() { router := routers.InitRouter() router.Run() } ","date":"2022-09-11","objectID":"/post/97ba92/:0:1","tags":["gin"],"title":"Gin中间件执行顺序","uri":"/post/97ba92/"},{"categories":["golang"],"content":"运行测试 go mod tidy go run main.go [GIN-debug] [WARNING] Running in \"debug\" mode. Switch to \"release\" mode in production. - using env: export GIN_MODE=release - using code: gin.SetMode(gin.ReleaseMode) [GIN-debug] GET / --\u003e github.com/kbsonlong/gin-middleware-demo/routers.InitRouter.func1 (4 handlers) [GIN-debug] [WARNING] You trusted all proxies, this is NOT safe. We recommend you to set a value. Please check https://pkg.go.dev/github.com/gin-gonic/gin#readme-don-t-trust-all-proxies for details. [GIN-debug] Environment variable PORT is undefined. Using port :8080 by default [GIN-debug] Listening and serving HTTP on :8080 另一终端执行 curl 127.0.0.1:8080 {\"message\":\"test\"} 可以看到控制台输出内容 开始执行第一个 gin 中间件:2022-07-08 17:18:57.499033 +0800 CST m=+3.029327751 开始执行第二个 gin 中间件:2022-07-08 17:18:57.499215 +0800 CST m=+3.029509918 开始执行第三个 gin 中间件:2022-07-08 17:18:57.499218 +0800 CST m=+3.029513043 第三个 gin 中间件返回内容:2022-07-08 17:18:57.499295 +0800 CST m=+3.029589876 第二个 gin 中间件返回内容:2022-07-08 17:18:57.499298 +0800 CST m=+3.029593335 第一个 gin 中间件返回内容:2022-07-08 17:18:57.4993 +0800 CST m=+3.029594876 调整中间件Use顺序 ...... r.Use(middleware.MdOne()) r.Use(middleware.MdThree()) r.Use(middleware.MdTwo()) gin.SetMode(\"debug\") ...... 第二个中间件和第三个中间件顺序对调 开始执行第一个 gin 中间件:2022-07-08 17:20:57.702026 +0800 CST m=+2.567931210 开始执行第三个 gin 中间件:2022-07-08 17:20:57.702215 +0800 CST m=+2.568120210 开始执行第二个 gin 中间件:2022-07-08 17:20:57.702218 +0800 CST m=+2.568123543 第二个 gin 中间件返回内容:2022-07-08 17:20:57.702305 +0800 CST m=+2.568210460 第三个 gin 中间件返回内容:2022-07-08 17:20:57.702308 +0800 CST m=+2.568214043 第一个 gin 中间件返回内容:2022-07-08 17:20:57.702311 +0800 CST m=+2.568216293 可以看到第三个中间件在第二个中间件之前执行 注释第三个中间件Next func MdThree() gin.HandlerFunc { return func(c *gin.Context) { fmt.Println(\"开始执行第三个 gin 中间件:\" + time.Now().String()) // c.Next() fmt.Println(\"第三个 gin 中间件返回内容:\" + time.Now().String()) } } 开始执行第一个 gin 中间件:2022-07-08 17:22:43.132983 +0800 CST m=+4.061931376 开始执行第三个 gin 中间件:2022-07-08 17:22:43.133126 +0800 CST m=+4.062074668 第三个 gin 中间件返回内容:2022-07-08 17:22:43.133128 +0800 CST m=+4.062076751 开始执行第二个 gin 中间件:2022-07-08 17:22:43.13313 +0800 CST m=+4.062078210 第二个 gin 中间件返回内容:2022-07-08 17:22:43.133203 +0800 CST m=+4.062151335 第一个 gin 中间件返回内容:2022-07-08 17:22:43.133205 +0800 CST m=+4.062153460 ","date":"2022-09-11","objectID":"/post/97ba92/:0:2","tags":["gin"],"title":"Gin中间件执行顺序","uri":"/post/97ba92/"},{"categories":["golang"],"content":"总结 Gin中间件的调用顺序与Use顺序有关，代码运行顺序和Next前后顺序有关。 Next之前代码先进先出 Next之后代码后进先出 没有引用Next代码直接运行 ","date":"2022-09-11","objectID":"/post/97ba92/:0:3","tags":["gin"],"title":"Gin中间件执行顺序","uri":"/post/97ba92/"},{"categories":["云原生"],"content":" Sidecar 自动注入机制是将 sidecar 代理自动添加到用户创建的 pod。 它使用 MutatingWebhook 机制在 pod 创建的时候将 sidecar 的容器和卷添加到每个 pod 的模版里。 用户可以通过 webhooks namespaceSelector 机制来限定需要启动自动注入的范围，也可以通过注解的方式针对每个 pod 来单独启用和禁用自动注入功能。 Sidecar 是否会被自动注入取决于下面 3 条配置和 2 条安全规则： 配置: webhooks namespaceSelector 默认策略 policy pod 级别的覆盖注解 安全规则: sidecar 默认不能被注入到 kube-system 和 kube-public 这两个 namespace sidecar 不能被注入到使用 host network 网络的 pod 里 下面的表格展示了基于上述三个配置条件的最终注入状态。上述的安全规则不会被覆盖。 namespaceSelector 匹配 默认策略 sidecar.istio.io/inject 注解 Sidecar 是否注入 是 enabled true (default) 是 是 enabled false 否 是 disabled true 是 是 disabled false (default) 否 否 enabled true (default) 否 否 enabled false 否 否 disabled true 否 否 disabled false (default) 否 以下内容基于Istio 1.13.2版本 ","date":"2022-09-11","objectID":"/post/dd0bd7/:0:0","tags":["istio"],"title":"深入了解Istio Sicader自动注入","uri":"/post/dd0bd7/"},{"categories":["云原生"],"content":"NewWehook方法 pkg/kube/inject/webhook.go func NewWebhook(p WebhookParameters) (*Webhook, error) { if p.Mux == nil { return nil, errors.New(\"expected mux to be passed, but was not passed\") } wh := \u0026Webhook{ watcher: p.Watcher, meshConfig: p.Env.Mesh(), env: p.Env, revision: p.Revision, } p.Watcher.SetHandler(wh.updateConfig) sidecarConfig, valuesConfig, err := p.Watcher.Get() if err != nil { return nil, err } wh.updateConfig(sidecarConfig, valuesConfig) //初始化Webhook实例的时候注册/inject对应的处理器 p.Mux.HandleFunc(\"/inject\", wh.serveInject) p.Mux.HandleFunc(\"/inject/\", wh.serveInject) p.Env.Watcher.AddMeshHandler(func() { wh.mu.Lock() wh.meshConfig = p.Env.Mesh() wh.mu.Unlock() }) return wh, nil } ","date":"2022-09-11","objectID":"/post/dd0bd7/:0:1","tags":["istio"],"title":"深入了解Istio Sicader自动注入","uri":"/post/dd0bd7/"},{"categories":["云原生"],"content":"serveInject方法 pkg/kube/inject/webhook.go 大概825-895行 func (wh *Webhook) serveInject(w http.ResponseWriter, r *http.Request) { totalInjections.Increment() var body []byte // 获取请求体 if r.Body != nil { if data, err := kube.HTTPConfigReader(r); err == nil { body = data } else { http.Error(w, err.Error(), http.StatusBadRequest) return } } if len(body) == 0 { handleError(\"no body found\") http.Error(w, \"no body found\", http.StatusBadRequest) return } // verify the content type is accurate contentType := r.Header.Get(\"Content-Type\") if contentType != \"application/json\" { handleError(fmt.Sprintf(\"contentType=%s, expect application/json\", contentType)) http.Error(w, \"invalid Content-Type, want `application/json`\", http.StatusUnsupportedMediaType) return } path := \"\" if r.URL != nil { path = r.URL.Path } var reviewResponse *kube.AdmissionResponse var obj runtime.Object var ar *kube.AdmissionReview // 解码请求体 if out, _, err := deserializer.Decode(body, nil, obj); err != nil { handleError(fmt.Sprintf(\"Could not decode body: %v\", err)) reviewResponse = toAdmissionResponse(err) } else { log.Debugf(\"AdmissionRequest for path=%s\\n\", path) ar, err = kube.AdmissionReviewKubeToAdapter(out) if err != nil { handleError(fmt.Sprintf(\"Could not decode object: %v\", err)) } // 进入inject方法逻辑判断 reviewResponse = wh.inject(ar, path) } response := kube.AdmissionReview{} response.Response = reviewResponse var responseKube runtime.Object var apiVersion string if ar != nil { apiVersion = ar.APIVersion response.TypeMeta = ar.TypeMeta if response.Response != nil { if ar.Request != nil { response.Response.UID = ar.Request.UID } } } responseKube = kube.AdmissionReviewAdapterToKube(\u0026response, apiVersion) resp, err := json.Marshal(responseKube) if err != nil { log.Errorf(\"Could not encode response: %v\", err) http.Error(w, fmt.Sprintf(\"could not encode response: %v\", err), http.StatusInternalServerError) } if _, err := w.Write(resp); err != nil { log.Errorf(\"Could not write response: %v\", err) http.Error(w, fmt.Sprintf(\"could not write response: %v\", err), http.StatusInternalServerError) } } ","date":"2022-09-11","objectID":"/post/dd0bd7/:0:2","tags":["istio"],"title":"深入了解Istio Sicader自动注入","uri":"/post/dd0bd7/"},{"categories":["云原生"],"content":"inject方法 pkg/kube/inject/webhook.go 大概在748-823行 func (wh *Webhook) inject(ar *kube.AdmissionReview, path string) *kube.AdmissionResponse { req := ar.Request var pod corev1.Pod if err := json.Unmarshal(req.Object.Raw, \u0026pod); err != nil { handleError(fmt.Sprintf(\"Could not unmarshal raw object: %v %s\", err, string(req.Object.Raw))) return toAdmissionResponse(err) } // Managed fields is sometimes extremely large, leading to excessive CPU time on patch generation // It does not impact the injection output at all, so we can just remove it. pod.ManagedFields = nil // Deal with potential empty fields, e.g., when the pod is created by a deployment podName := potentialPodName(pod.ObjectMeta) if pod.ObjectMeta.Namespace == \"\" { pod.ObjectMeta.Namespace = req.Namespace } log.Infof(\"Sidecar injection request for %v/%v\", req.Namespace, podName) log.Debugf(\"Object: %v\", string(req.Object.Raw)) log.Debugf(\"OldObject: %v\", string(req.OldObject.Raw)) wh.mu.RLock() // Sicader注入判断逻辑 if !injectRequired(IgnoredNamespaces.UnsortedList(), wh.Config, \u0026pod.Spec, pod.ObjectMeta) { log.Infof(\"Skipping %s/%s due to policy check\", pod.ObjectMeta.Namespace, podName) totalSkippedInjections.Increment() wh.mu.RUnlock() return \u0026kube.AdmissionResponse{ Allowed: true, } } proxyConfig := mesh.DefaultProxyConfig() if wh.env.PushContext != nil \u0026\u0026 wh.env.PushContext.ProxyConfigs != nil { if generatedProxyConfig := wh.env.PushContext.ProxyConfigs.EffectiveProxyConfig( \u0026model.NodeMetadata{ Namespace: pod.Namespace, Labels: pod.Labels, Annotations: pod.Annotations, }, wh.meshConfig); generatedProxyConfig != nil { proxyConfig = *generatedProxyConfig } } deploy, typeMeta := kube.GetDeployMetaFromPod(\u0026pod) params := InjectionParameters{ pod: \u0026pod, deployMeta: deploy, typeMeta: typeMeta, templates: wh.Config.Templates, defaultTemplate: wh.Config.DefaultTemplates, aliases: wh.Config.Aliases, meshConfig: wh.meshConfig, proxyConfig: \u0026proxyConfig, valuesConfig: wh.valuesConfig, revision: wh.revision, injectedAnnotations: wh.Config.InjectedAnnotations, proxyEnvs: parseInjectEnvs(path), } wh.mu.RUnlock() patchBytes, err := injectPod(params) if err != nil { handleError(fmt.Sprintf(\"Pod injection failed: %v\", err)) return toAdmissionResponse(err) } reviewResponse := kube.AdmissionResponse{ Allowed: true, Patch: patchBytes, PatchType: func() *string { pt := \"JSONPatch\" return \u0026pt }(), } totalSuccessfulInjections.Increment() return \u0026reviewResponse } ","date":"2022-09-11","objectID":"/post/dd0bd7/:0:3","tags":["istio"],"title":"深入了解Istio Sicader自动注入","uri":"/post/dd0bd7/"},{"categories":["云原生"],"content":"injectRequired方法 pkg/kube/inject/inject.go 大概在180-290行 func injectRequired(ignored []string, config *Config, podSpec *corev1.PodSpec, metadata metav1.ObjectMeta) bool { // nolint: lll // Skip injection when host networking is enabled. The problem is // that the iptables changes are assumed to be within the pod when, // in fact, they are changing the routing at the host level. This // often results in routing failures within a node which can // affect the network provider within the cluster causing // additional pod failures. // 主机网络模式不注入sicader if podSpec.HostNetwork { return false } // skip special kubernetes system namespaces // kube-system、kube-public、kube-node-lease、local-path-storage四个名称空间不被注入sicader for _, namespace := range ignored { if metadata.Namespace == namespace { return false } } annos := metadata.GetAnnotations() var useDefault bool var inject bool // annotation 是否开启注入 `sidecar.istio.io/inject: \"true\"` objectSelector := annos[annotation.SidecarInject.Name] if lbl, labelPresent := metadata.GetLabels()[annotation.SidecarInject.Name]; labelPresent { // The label is the new API; if both are present we prefer the label objectSelector = lbl } switch strings.ToLower(objectSelector) { // http://yaml.org/type/bool.html case \"y\", \"yes\", \"true\", \"on\": inject = true case \"\": useDefault = true } // If an annotation is not explicitly given, check the LabelSelectors, starting with NeverInject // 判断 configmap `istio-sidecar-injector` NeverInject 匹配标签选择器 if useDefault { for _, neverSelector := range config.NeverInjectSelector { selector, err := metav1.LabelSelectorAsSelector(\u0026neverSelector) if err != nil { log.Warnf(\"Invalid selector for NeverInjectSelector: %v (%v)\", neverSelector, err) } else if !selector.Empty() \u0026\u0026 selector.Matches(labels.Set(metadata.Labels)) { log.Debugf(\"Explicitly disabling injection for pod %s/%s due to pod labels matching NeverInjectSelector config map entry.\", metadata.Namespace, potentialPodName(metadata)) inject = false useDefault = false break } } } // If there's no annotation nor a NeverInjectSelector, check the AlwaysInject one // 判断 configmap `istio-sidecar-injector` AlwaysInject 匹配标签选择器 if useDefault { for _, alwaysSelector := range config.AlwaysInjectSelector { selector, err := metav1.LabelSelectorAsSelector(\u0026alwaysSelector) if err != nil { log.Warnf(\"Invalid selector for AlwaysInjectSelector: %v (%v)\", alwaysSelector, err) } else if !selector.Empty() \u0026\u0026 selector.Matches(labels.Set(metadata.Labels)) { log.Debugf(\"Explicitly enabling injection for pod %s/%s due to pod labels matching AlwaysInjectSelector config map entry.\", metadata.Namespace, potentialPodName(metadata)) inject = true useDefault = false break } } } var required bool // 判断 configmap `istio-sidecar-injector` 默认策略policy switch config.Policy { default: // InjectionPolicyOff log.Errorf(\"Illegal value for autoInject:%s, must be one of [%s,%s]. Auto injection disabled!\", config.Policy, InjectionPolicyDisabled, InjectionPolicyEnabled) required = false case InjectionPolicyDisabled: if useDefault { required = false } else { required = inject } case InjectionPolicyEnabled: if useDefault { required = true } else { required = inject } } if log.DebugEnabled() { // Build a log message for the annotations. annotationStr := \"\" for name := range AnnotationValidation { value, ok := annos[name] if !ok { value = \"(unset)\" } annotationStr += fmt.Sprintf(\"%s:%s \", name, value) } log.Debugf(\"Sidecar injection policy for %v/%v: namespacePolicy:%v useDefault:%v inject:%v required:%v %s\", metadata.Namespace, potentialPodName(metadata), config.Policy, useDefault, inject, required, annotationStr) } return required } ","date":"2022-09-11","objectID":"/post/dd0bd7/:0:4","tags":["istio"],"title":"深入了解Istio Sicader自动注入","uri":"/post/dd0bd7/"},{"categories":["云原生"],"content":"压测大纲 压测的必要性 压测部署架构图 环境准备 ","date":"2022-09-11","objectID":"/post/129682/:0:0","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"部署 Istio ","date":"2022-09-11","objectID":"/post/129682/:1:0","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"部署监控组件 ","date":"2022-09-11","objectID":"/post/129682/:2:0","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"部署压测服务 ","date":"2022-09-11","objectID":"/post/129682/:3:0","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"Fortio v1版本 apiVersion: apps/v1 kind: Deployment metadata: name: fortio-server-l3 labels: app: fortio-server-l3 version: v1 spec: replicas: 1 selector: matchLabels: app: fortio-server-l3 template: metadata: labels: app: fortio-server-l3 version: v1 spec: containers: - name: fortio-server-l3 # 在中国，你可以使用 docker.mirrors.ustc.edu.cn/fortio/fortio:latest image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio - server --- apiVersion: v1 kind: Service metadata: name: fortio-server-l3 spec: ports: - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-server-l3 type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata: name: fortio-server-l2 labels: app: fortio-server-l2 version: v1 spec: replicas: 1 selector: matchLabels: app: fortio-server-l2 template: metadata: labels: app: fortio-server-l2 version: v1 spec: containers: - name: fortio-server-l2 # 在中国，你可以使用 docker.mirrors.ustc.edu.cn/fortio/fortio:latest image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8072 name: http-m - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio args: [\"server\", \"-P\", \"8072 fortio-server-l3:8080\"] --- apiVersion: v1 kind: Service metadata: name: fortio-server-l2 spec: ports: - name: http-m port: 8072 protocol: TCP targetPort: 8072 - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-server-l2 type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata: name: fortio-server-l1 labels: app: fortio-server-l1 version: v1 spec: replicas: 1 selector: matchLabels: app: fortio-server-l1 template: metadata: labels: app: fortio-server-l1 version: v1 spec: containers: - name: fortio-server-l1 # 在中国，你可以使用 docker.mirrors.ustc.edu.cn/fortio/fortio:latest image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8071 name: http-m - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio args: [\"server\", \"-P\", \"8071 fortio-server-l2:8072\"] --- apiVersion: v1 kind: Service metadata: name: fortio-server-l1 spec: ports: - name: http-m port: 8071 protocol: TCP targetPort: 8071 - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-server-l1 type: NodePort ","date":"2022-09-11","objectID":"/post/129682/:3:1","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"Fortio v2版本 apiVersion: apps/v1 kind: Deployment metadata: name: fortio-server-l3 labels: app: fortio-server-l3 version: v1 spec: replicas: 1 selector: matchLabels: app: fortio-server-l3 template: metadata: labels: app: fortio-server-l3 version: v1 spec: containers: - name: fortio-server-l3 # 在中国，你可以使用 docker.mirrors.ustc.edu.cn/fortio/fortio:latest image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio - server --- apiVersion: v1 kind: Service metadata: name: fortio-server-l3 spec: ports: - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-server-l3 type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata: name: fortio-server-l2 labels: app: fortio-server-l2 version: v1 spec: replicas: 1 selector: matchLabels: app: fortio-server-l2 template: metadata: labels: app: fortio-server-l2 version: v1 spec: containers: - name: fortio-server-l2 # 在中国，你可以使用 docker.mirrors.ustc.edu.cn/fortio/fortio:latest image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8072 name: http-m - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio args: [\"server\", \"-P\", \"8072 fortio-server-l3:8080\"] --- apiVersion: v1 kind: Service metadata: name: fortio-server-l2 spec: ports: - name: http-m port: 8072 protocol: TCP targetPort: 8072 - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-server-l2 type: NodePort --- apiVersion: apps/v1 kind: Deployment metadata: name: fortio-server-l1 labels: app: fortio-server-l1 version: v1 spec: replicas: 1 selector: matchLabels: app: fortio-server-l1 template: metadata: labels: app: fortio-server-l1 version: v1 spec: containers: - name: fortio-server-l1 # 在中国，你可以使用 docker.mirrors.ustc.edu.cn/fortio/fortio:latest image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8071 name: http-m - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio args: [\"server\", \"-P\", \"8071 fortio-server-l2:8072\"] --- apiVersion: v1 kind: Service metadata: name: fortio-server-l1 spec: ports: - name: http-m port: 8071 protocol: TCP targetPort: 8071 - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-server-l1 type: NodePort apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: fortio-server-l1 spec: hosts: - fortio-server-l1 http: - route: - destination: host: fortio-server-l1 subset: v1 weight: 10 - destination: host: fortio-server-l1 subset: v2 weight: 90 --- apiVersion: networking.istio.io/v1alpha3 kind: VirtualService metadata: name: fortio-server-l2 spec: hosts: - fortio-server-l2 http: - route: - destination: host: fortio-server-l2 subset: v1 weight: 0 - destination: host: fortio-server-l2 subset: v2 weight: 100 --- apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: fortio-server-l1 spec: host: fortio-server-l1 subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 --- apiVersion: networking.istio.io/v1alpha3 kind: DestinationRule metadata: name: fortio-server-l2 spec: host: fortio-server-l2 subsets: - name: v1 labels: version: v1 - name: v2 labels: version: v2 ","date":"2022-09-11","objectID":"/post/129682/:3:2","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"部署压测工具 apiVersion: apps/v1 kind: Deployment metadata: name: fortio-client labels: app: fortio-client version: v2 spec: replicas: 1 selector: matchLabels: app: fortio-client template: metadata: labels: app: fortio-client version: v2 spec: containers: - name: fortio-client image: fortio/fortio:latest ports: - containerPort: 8080 name: http-port - containerPort: 8078 name: udp-port - containerPort: 8079 name: grpc-port - containerPort: 8081 name: https-port command: - fortio - server --- apiVersion: v1 kind: Service metadata: name: fortio-client spec: ports: - name: http-port port: 8080 protocol: TCP targetPort: 8080 - name: https-port port: 8081 protocol: TCP targetPort: 8081 - name: http2-grpc port: 8079 protocol: TCP targetPort: 8079 - name: udp-grpc port: 8078 protocol: UDP targetPort: 8078 selector: app: fortio-client type: NodePort 性能压测 压测报告 画红线部分 min: 最小响应时间2.97ms average: 平均响应时间11.286ms P50: 50%的请求响应时间在10.18ms内 P75: 75%的请求响应时间在13.48ms内 P90: 90%的请求响应时间在17.13ms内 P99: 99%的请求响应时间在29.89ms内 P99.9: 99.9%的请求响应时间在80.91ms内 max: 最大响应时间324.597ms ","date":"2022-09-11","objectID":"/post/129682/:4:0","tags":["istio"],"title":"Istio性能测试","uri":"/post/129682/"},{"categories":["云原生"],"content":"Istio-operator安装 ","date":"2022-09-11","objectID":"/post/bf667a/:1:0","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":["云原生"],"content":"创建 istio-operator 名称空间 kubectl apply -f - \u003c\u003cEOF --- apiVersion: v1 kind: Namespace metadata: name: istio-operator EOF ","date":"2022-09-11","objectID":"/post/bf667a/:1:1","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":["云原生"],"content":"部署 Istio-operator kubectl apply -f - \u003c\u003cEOF --- # Source: istio-operator/templates/service_account.yaml apiVersion: v1 kind: ServiceAccount metadata: namespace: istio-operator name: istio-operator --- # Source: istio-operator/templates/crds.yaml # SYNC WITH manifests/charts/base/files apiVersion: apiextensions.k8s.io/v1 kind: CustomResourceDefinition metadata: name: istiooperators.install.istio.io labels: release: istio spec: conversion: strategy: None group: install.istio.io names: kind: IstioOperator listKind: IstioOperatorList plural: istiooperators singular: istiooperator shortNames: - iop - io scope: Namespaced versions: - additionalPrinterColumns: - description: Istio control plane revision jsonPath: .spec.revision name: Revision type: string - description: IOP current state jsonPath: .status.status name: Status type: string - description: 'CreationTimestamp is a timestamp representing the server time when this object was created. It is not guaranteed to be set in happens-before order across separate operations. Clients may not set this value. It is represented in RFC3339 form and is in UTC. Populated by the system. Read-only. Null for lists. More info: https://git.k8s.io/community/contributors/devel/api-conventions.md#metadata' jsonPath: .metadata.creationTimestamp name: Age type: date name: v1alpha1 subresources: status: {} schema: openAPIV3Schema: type: object x-kubernetes-preserve-unknown-fields: true served: true storage: true --- # Source: istio-operator/templates/clusterrole.yaml apiVersion: rbac.authorization.k8s.io/v1 kind: ClusterRole metadata: creationTimestamp: null name: istio-operator rules: # istio groups - apiGroups: - authentication.istio.io resources: - '*' verbs: - '*' - apiGroups: - config.istio.io resources: - '*' verbs: - '*' - apiGroups: - install.istio.io resources: - '*' verbs: - '*' - apiGroups: - networking.istio.io resources: - '*' verbs: - '*' - apiGroups: - security.istio.io resources: - '*' verbs: - '*' # k8s groups - apiGroups: - admissionregistration.k8s.io resources: - mutatingwebhookconfigurations - validatingwebhookconfigurations verbs: - '*' - apiGroups: - apiextensions.k8s.io resources: - customresourcedefinitions.apiextensions.k8s.io - customresourcedefinitions verbs: - '*' - apiGroups: - apps - extensions resources: - daemonsets - deployments - deployments/finalizers - replicasets verbs: - '*' - apiGroups: - autoscaling resources: - horizontalpodautoscalers verbs: - '*' - apiGroups: - monitoring.coreos.com resources: - servicemonitors verbs: - get - create - update - apiGroups: - policy resources: - poddisruptionbudgets verbs: - '*' - apiGroups: - rbac.authorization.k8s.io resources: - clusterrolebindings - clusterroles - roles - rolebindings verbs: - '*' - apiGroups: - coordination.k8s.io resources: - leases verbs: - get - create - update - apiGroups: - \"\" resources: - configmaps - endpoints - events - namespaces - pods - pods/proxy - pods/portforward - persistentvolumeclaims - secrets - services - serviceaccounts verbs: - '*' --- # Source: istio-operator/templates/clusterrole_binding.yaml kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: istio-operator subjects: - kind: ServiceAccount name: istio-operator namespace: istio-operator roleRef: kind: ClusterRole name: istio-operator apiGroup: rbac.authorization.k8s.io --- # Source: istio-operator/templates/service.yaml apiVersion: v1 kind: Service metadata: namespace: istio-operator labels: name: istio-operator name: istio-operator spec: ports: - name: http-metrics port: 8383 targetPort: 8383 protocol: TCP selector: name: istio-operator --- # Source: istio-operator/templates/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: namespace: istio-operator name: istio-operator spec: replicas: 1 revisionHistoryLimit: 10 selector: matchLabels: name: istio-operator template: metadata: labels: name: istio-operator spec: serviceAccountName: istio-operator containers: - name: istio-operator image: docker","date":"2022-09-11","objectID":"/post/bf667a/:1:2","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":["云原生"],"content":"创建 istio-system 名称空间 kubectl apply -f - \u003c\u003cEOF --- apiVersion: v1 kind: Namespace metadata: name: istio-system EOF ","date":"2022-09-11","objectID":"/post/bf667a/:1:3","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":["云原生"],"content":"使用demo配置项安装istio组件 kubectl apply -f - \u003c\u003cEOF apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system name: istiocontrolplane spec: profile: demo EOF ","date":"2022-09-11","objectID":"/post/bf667a/:1:4","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":["云原生"],"content":"更新IstioOperator kubectl apply -f - \u003c\u003cEOF apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system name: istiocontrolplane spec: profile: default EOF ","date":"2022-09-11","objectID":"/post/bf667a/:1:5","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":["云原生"],"content":"启用 istio-egressgateway 组件并增加 pilot 的资源要求和HPA kubectl apply -f - \u003c\u003cEOF apiVersion: install.istio.io/v1alpha1 kind: IstioOperator metadata: namespace: istio-system name: istiocontrolplane spec: profile: default components: pilot: k8s: resources: requests: cpu: 1000m # override from default 500m memory: 4096Mi # ... default 2048Mi hpaSpec: maxReplicas: 10 # ... default 5 minReplicas: 2 # ... default 1 egressGateways: - name: istio-egressgateway enabled: true EOF ","date":"2022-09-11","objectID":"/post/bf667a/:1:6","tags":["istio"],"title":"利用IstioOpertor安装Istio","uri":"/post/bf667a/"},{"categories":null,"content":"修改认证方式 # vim /etc/ocserv/ocserv.conf auth = \"plain[passwd=/etc/ocserv/ocpasswd,otp=/etc/ocserv/ocserv.otp]\" ","date":"2022-09-11","objectID":"/post/e96811/:0:1","tags":null,"title":"openconnect双因素认证","uri":"/post/e96811/"},{"categories":null,"content":"配置pam echo \"auth requisite pam_oath.so debug usersfile=/etc/ocserv/ocserv.otp window=20\" \u003e\u003e /etc/pam.d/ocserv ","date":"2022-09-11","objectID":"/post/e96811/:0:2","tags":null,"title":"openconnect双因素认证","uri":"/post/e96811/"},{"categories":null,"content":"创建用户OTP username=\"zengshenglong\" company=\"Company\" site_name=\"Site\" key=$(head -c 16 /dev/urandom |xxd -c 256 -ps) echo \"HOTP/T30 ${username} - ${key}\" \u003e\u003e/etc/ocserv/ocserv.otp oathtool --totp -w 5 $key secret=$(echo 0x${key}|xxd -r -c 256|base32) echo \"otpauth://hotp/${username}@${site_name}?secret=${secret}\u0026issuer=${company}\" | qrencode -o - -t UTF8 echo \"https://www.google.com/chart?chs=200x200\u0026chld=M|0\u0026cht=qr\u0026chl=otpauth://hotp/${username}@${site_name}?secret=$(echo ${secret}|cut -d = -f 1)\u0026issuer=${company}\" ","date":"2022-09-11","objectID":"/post/e96811/:0:3","tags":null,"title":"openconnect双因素认证","uri":"/post/e96811/"},{"categories":null,"content":"完整配置 auth = \"plain[passwd=/etc/ocserv/ocpasswd,otp=/etc/ocserv/ocserv.otp]\" tcp-port = 443 udp-port = 443 run-as-user = nobody run-as-group = daemon socket-file = /var/run/ocserv-socket server-cert = /etc/letsencrypt/live/myvpn.alongparty.cn/fullchain.pem server-key = /etc/letsencrypt/live/myvpn.alongparty.cn/privkey.pem isolate-workers = false banner = \"Welcome PCI DSS environment, please proceed with caution ! !\" pre-login-banner = \"You will enter the PCI DSS environment, please proceed with caution ! !\" max-clients = 16 max-same-clients = 2 rate-limit-ms = 100 server-stats-reset-time = 604800 keepalive = 32400 dpd = 90 mobile-dpd = 1800 switch-to-tcp-timeout = 25 try-mtu-discovery = true cert-user-oid = 0.9.2342.19200300.100.1.1 tls-priorities = \"NORMAL:%SERVER_PRECEDENCE:%COMPAT:-VERS-SSL3.0:-VERS-TLS1.0:-VERS-TLS1.1\" auth-timeout = 240 min-reauth-time = 300 max-ban-score = 80 ban-reset-time = 1200 cookie-timeout = 300 deny-roaming = false rekey-time = 172800 rekey-method = ssl use-occtl = true pid-file = /var/run/ocserv.pid device = vpns predictable-ips = true default-domain = example.com ipv4-network = 10.255.255.0 ipv4-netmask = 255.255.255.0 tunnel-all-dns = true dns = 8.8.8.8 dns = 4.2.2.4 dns = 2001:4860:4860::8888 dns = 2001:4860:4860::8844 ping-leases = false config-per-group = /etc/ocserv/group default-group-config = /etc/ocserv/group/default default-select-group = default auto-select-group = false cisco-client-compat = true dtls-legacy = true ","date":"2022-09-11","objectID":"/post/e96811/:0:4","tags":null,"title":"openconnect双因素认证","uri":"/post/e96811/"},{"categories":null,"content":"1.首先添加两个带分组的用户 ocpasswd -c /etc/ocserv/ocpasswd -g gruop1 user1 ocpasswd -c /etc/ocserv/ocpasswd -g gruop2 user2 ","date":"2022-09-11","objectID":"/post/bf9138/:0:1","tags":null,"title":"openconnect设置用户组实现多路由","uri":"/post/bf9138/"},{"categories":null,"content":"2.添加创建路由表组 mkdir /etc/ocserv/group echo -e \"route = 10.10.0.0/255.255.255.0\" \u003e\u003e /etc/ocserv/group/group1 echo -e \"no-route = 211.80.0.0/255.240.0.0\" \u003e\u003e /etc/ocserv/group/group2 以上连个路由表是演示group1和group2随便写的 请自行添加路由规则 此外路由表里还可以写DNS 短线时间的参数 ","date":"2022-09-11","objectID":"/post/bf9138/:0:2","tags":null,"title":"openconnect设置用户组实现多路由","uri":"/post/bf9138/"},{"categories":null,"content":"3.添加新的配置到ocserv.conf config-per-group = /etc/ocserv/group/ default-group-config = /etc/ocserv/group/group1 #如果创建用户的时候不分组 group1就是默认分组 用的就是group1的路由表 default-select-group = group1 #如果创建用户的时候不分组 group1就是默认分组 用的就是group1的路由表 auto-select-group = false ","date":"2022-09-11","objectID":"/post/bf9138/:0:3","tags":null,"title":"openconnect设置用户组实现多路由","uri":"/post/bf9138/"},{"categories":null,"content":"4.完整配置 auth = \"plain[/etc/ocserv/ocpasswd]\" tcp-port = 443 udp-port = 443 run-as-user = nobody run-as-group = daemon socket-file = /var/run/ocserv-socket server-cert = /etc/letsencrypt/live/myvpn.alongparty.cn/fullchain.pem server-key = /etc/letsencrypt/live/myvpn.alongparty.cn/privkey.pem isolate-workers = false max-clients = 16 max-same-clients = 2 rate-limit-ms = 100 server-stats-reset-time = 604800 keepalive = 32400 dpd = 90 mobile-dpd = 1800 switch-to-tcp-timeout = 25 try-mtu-discovery = true cert-user-oid = 0.9.2342.19200300.100.1.1 tls-priorities = \"NORMAL:%SERVER_PRECEDENCE:%COMPAT:-VERS-SSL3.0:-VERS-TLS1.0:-VERS-TLS1.1\" auth-timeout = 240 min-reauth-time = 300 max-ban-score = 80 ban-reset-time = 1200 cookie-timeout = 300 deny-roaming = false rekey-time = 172800 rekey-method = ssl use-occtl = true pid-file = /var/run/ocserv.pid device = vpns predictable-ips = true default-domain = example.com ipv4-network = 10.255.255.0 ipv4-netmask = 255.255.255.0 tunnel-all-dns = true dns = 8.8.8.8 dns = 4.2.2.4 dns = 2001:4860:4860::8888 dns = 2001:4860:4860::8844 ping-leases = false config-per-group = /etc/ocserv/group/ default-group-config = /etc/ocserv/group/default default-select-group = default auto-select-group = false cisco-client-compat = true dtls-legacy = true # cat /etc/ocserv/group/default route = 10.48.16.124/32 # cat /etc/ocserv/ocpasswd sysop01:sysop:$5$R7HQXGtZ1MpB.N82$iNf5viGa/XT/qLjfpFhPNqlvdEyw5KKaKZvK2jIVEG4 ","date":"2022-09-11","objectID":"/post/bf9138/:0:4","tags":null,"title":"openconnect设置用户组实现多路由","uri":"/post/bf9138/"},{"categories":null,"content":"Hey Welcome here 👋 ","date":"2022-09-11","objectID":"/about/:1:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"正在学习 ","date":"2022-09-11","objectID":"/about/:2:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"Service Mesh ","date":"2022-09-11","objectID":"/about/:2:1","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"Vue ","date":"2022-09-11","objectID":"/about/:2:2","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"Go ","date":"2022-09-11","objectID":"/about/:2:3","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"汇编和工具: 🛠 Check for a detailed stats here :point_right: Sourcerer ","date":"2022-09-11","objectID":"/about/:3:0","tags":null,"title":"关于","uri":"/about/"},{"categories":null,"content":"kbsonlong's friends","date":"2022-09-10","objectID":"/friends/","tags":null,"title":"友链","uri":"/friends/"},{"categories":null,"content":"Friendly Reminder Notice If you want to exchange link, please leave a comment in the above format. (personal non-commercial blogs / websites only)  Website failure, stop maintenance and improper content may be unlinked! Those websites that do not respect other people’s labor achievements, reprint without source, or malicious acts, please do not come to exchange. ","date":"2022-09-10","objectID":"/friends/:1:0","tags":null,"title":"友链","uri":"/friends/"},{"categories":null,"content":"获取仓库信息 curl --request GET \\ --url \"https://api.github.com/repos/kbsonlong/kubernetes-guide\" \\ --header \"Accept: application/vnd.github.v3+json\" \\ --header \"Authorization: Bearer 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\" ","date":"2022-08-11","objectID":"/post/5d7029/:0:1","tags":null,"title":"GitHub Api接口","uri":"/post/5d7029/"},{"categories":null,"content":"删除仓库 ","date":"2022-08-11","objectID":"/post/5d7029/:0:2","tags":null,"title":"GitHub Api接口","uri":"/post/5d7029/"},{"categories":["kubernetes"],"content":"什么是弹性伸缩？弹性伸缩和成本优化是何关系？ 应该如何做好企业级弹性伸缩与成本优化建设？ ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:0:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"一 背景 传统意义上来讲，弹性伸缩主要解决的问题是容量规划与实际负载的矛盾, 这矛盾通常因为资源使用普遍具有以下几个问题导致： （1）在线服务申请资源时考虑到突发流量和服务稳定性，预留大量的 buffer 资源，造成资源申请量普遍远超实际使用量。 （2）大部分在线服务的潮汐现象、波峰波谷特征非常明显，保留过多常态资源造成巨大浪费。 （3）开发和运维评估和配置的资源规格不合理，并且动态更新不及时。 随着云原生技术的发展，容器云的弹性能力进入大众视野，弹性伸缩也成为各大服务器厂商的标准配置，在高速发展的互联网企业中，弹性既能支撑业务优雅面对突发的大流量、亦能在业务低峰时伸缩资源维持低成本运行，尤其在当前的大环境下， 降本增效的弹性能力建设是必然。那应该如何打造我们的弹性伸缩能力、又如何利用弹性的能力解决高昂的成本问题？本文根据笔者过去的实践和思考， 简单阐述对计算资源弹性、容器云kubernetes[1]弹性、混合云弹性、Serverless[2]等的一些心得体会。 阅者受益： 计算资源弹性能力方向建设 容器云集群弹性方向建设 容器云应用弹性方向建设 混合云弹性建设 Serverless方向建设 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:1:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"二 计算资源弹性能力建设 业务还未部署在容器云的时候， 资源是私有云或公有云的虚拟机为主，设计弹性平台的落地产出就是提升虚拟机的资源利用率,降低服务器成本和动态感知业务增长,实现平滑扩容 弹性平台建设 弹性平台基于应用资源画像的洞察-分析-优化方向建设， 整体架构包括可视化端层、计算层（数据获取、应用分析、弹性决策设定）、实施自动化，核心就是通过对资源使用率监控数据进行洞察分析，感知不同业务线的资源使用情况，对资源持续低负载或高负载有全局视角， 判断应用是否需要进行伸缩活动， 因为虚拟机资源的伸缩活动是分钟级（5分钟）以上的， 做不到容器云的秒级弹性， 所以还要考虑虚机资源池化 平台可视化层主要提供资源利用率大盘、应用弹性伸缩建议、业务健康度监控、事件日志审计、管理后台入口 计算模块主要提供数据获取、数据分析、伸缩弹性判定决策树 自动化模块主要提供伸缩事件通知、流量摘除、伸缩资源变更、业务部署、流量拉入等 计算资源弹性平台架构 这里主要对决策树稍加阐述， 设定的算法逻辑主要考虑以下几点： 设计资源利用率升降配决策树 降配时类型优先级：通用型 \u003e 计算型 \u003e 网络增强型 升配时逆序 确定类型降配达标条件 主机：CPU利用率达到xx%，内存利用率达到xx% 设计优先横向实例数量扩缩 \u003e 纵向规格变更 弹性扩容冷却期，在发生弹性扩容24h内， 不再进行缩容操作 考虑特殊情况， 白名单机制，譬如电商618、双十一等就需要提前扩容 当然资源成本优化也会考虑云商折扣、资源的类型譬如包年包月、按量付费、Spot抢占实例的组合方式等，Spot抢占实例在容器云中发挥的作用比较大，会在下文介绍 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:2:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"三 容器云集群层面优化 随着云原生的发展， Kubernetes容器编排成为业务上云的首选。业界在容器上建设的路线基本遵循 Docker \u003e Kubernetes \u003e ServiceMesh \u003e Serverless 。因为容器云是当下的主流， 所以下面会用比较大的篇幅来介绍容器云的弹性伸缩及优化方式 容器云弹性分为集群弹性和容器应用弹性两个层面。容器应用层面的弹性属于K8S的HPA或者VPA资源管理的范畴， 集群层面的弹性属于k8S的节点伸缩、动态调度等，本节从集群弹性讲起，主要包括以下内容： 集群弹性Cluster Autoscaler[3] Node节点超卖 集群自定义调度[4] 集群重调度[5] 离线和在线业务混部 Spot[6]抢占实例替换 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.0、集群资源构成 相比虚机类的弹性， 容器云环境的弹性是更为智能、高效的、可落地的。以 CPU 资源为例，一个 Kubernetes 集群的Node节点资源组成结构大致如下： Kubernetes Node 资源构成 Node Capacity是Node的所有硬件资源 Kube-reserved是给kube组件预留的资源 System-reserved是给System进程预留的资源 Eviction-threshold（阈值）是kubelet eviction(收回)的阈值设定 Allocatable才是真正scheduler调度Pod时的参考值 Node Allocatable = Node Capacity - kube-reserved - system-reserved - eviction-threshold 资源碎片因为node配置低、大资源pod不能调度、cpu满足但mem不满足调度等 通常业务申请的资源多，但POD实际利用率低，也导致Node利用率低 3.1、Kubernetes弹性优化总览 Kubernetes弹性优化总览 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:1","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.2、集群弹性CA Kubernetes AutoScaling 提供多种机制来满足 Pod 自动伸缩需求： Pod 级别的自动伸缩：包括Horizontal Pod Autoscaler[8]（HPA）和Vertical Pod Autoscaler[9]。其中 HPA 会基于 kubernetes 集群内置资源指标或者自定义指标来计算 Pod 副本需求数并自动伸缩，VPA 会基于 Pod 在 CPU/Memory 资源历史使用详情来计算 Pod 合理的资源请求并驱逐 Pod 以更新资源配合； Node 级别的自动伸缩：Cluster Autoscaler[3]会综合考虑 Pod 部署挂起或集群容量等信息确定集群节点资源并相应调整集群 Node 数量。 我先聊一聊集群Node级别的弹性伸缩， 依托官方的ClusterAutoscaler组件，它可以根据部署的应用所请求的资源量来动态的伸缩集群，不同云厂商也分别实现了各自的Provider接入，对应的容器集群产品也都提供了弹性伸缩的功能，大家自行开启即可。如果你用的是自建集群， 可以参考云商实现适配自己集群的Provider。 在集群中部署CA主要解决以下几个问题： 1 思考需要多大的集群节点规模满足应用需求？ 2 当Pod Pending ，没有可调度节点？ 3 当多台节点利用率低， 不能被自动释放？ 整体架构 Autoscaler：核心模块，负责整体扩缩容功能 Estimator：负责评估计算扩容 Simulator：负责模拟调度，计算缩容 Cloud Provider：抽象了CloudProvider及NodeGroup等相关接口，与云API交互 CA架构 什么时候扩？ 由于资源不足，pod调度失败，导致pod处于pending状态时，CA会评估扩容节点过程， 新拉起一台机器加入到集群中 扩容流程 什么时候缩？ 当Node的资源利用率较低时，且此Node上存在的POD都能被重新调度到其他节点， CA组件就会执行评估缩容节点过程， 将这台Node节点上的POD驱逐到其他节点上，则此台Node就可以被释放 。需要注意适配缩容过程时需要考虑对POD的优雅调度 ， Cordon[10]节点 + Drain[11] 方式 缩容流程 什么样的节点不会被CA删除 节点上有pod被PodDisruptionBudget控制器限制。 节点上有命名空间是kube-system的pods。 节点上的pod不是被控制器创建，例如不是被deployment, replica set, job, stateful set创建。 节点上有pod使用了本地存储 节点上pod驱逐后无处可去，即没有其他node能调度这个pod 节点有注解：”cluster-autoscaler.kubernetes.io/scale-down-disabled”: “true” … ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:2","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.3、Node节点超卖 Node 资源超卖方案是针对 Node 级别的资源调整方案，通过AdmissionWebhook[13]修改K8s Node的Allocatable 实现， 达到在使用率较低的情况下，将原本较小的资源扩展为逻辑上较大的资源来处理。例如原有CPU为4核，超卖2倍则是可将这个CPU视作8核 Node Annotation xxx/cpu-oversold: “false” 开启\u0026关闭 Node 超卖增加灵活性 Node Annotation xxx/cpu-oversold-ratio=1.5 调整Node可分配值到1.5倍 超卖功能主要解决以下几个问题： 1 应用资源一般申请都超标、真实负载不高 2 测试环境节点超卖2-3倍节省成本 整体架构 Node超卖架构 静态超卖 静态超卖就是不考虑节点的真实负载， 只通过注解配置资源超卖比例 动态超卖 动态超卖就是根据每个节点的真实负载数据，进行不同比例的资源超卖或取消超卖 自研组件基于节点历史监控数据，动态的/周期性的去调整超卖比例。比如某个 Node 连续 5m/1d持续低负载并且节点已分配资源水位线很高了，那么可以把超卖比例适当调高，以此使 Node 能容纳更多的业务 Pod。如果节点已经是高负载， 那就维持或调小超卖比 当然超卖的设计也有常见一些问题需要考虑，譬如需要不断平衡Node节点的超卖与真实使用率、要支持指标采集灵活性支持1m或更长1d的不同选择、考虑大规模集群（5k节点）频繁的webhook更新对调度的性能影响等 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:3","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.4、集群调度 在使用Node节点超卖时， 我们其实还有一个动态调度器配合一起工作， 调度器感知超卖相关配置和资源实际使用情况， 为应用稳定性和高效调度提供保证， 所以介绍下在调度层面可做的优化 静态调度 Kubernetes的资源编排调度默认使用的是静态调度Schedule[14]，就是通过调度中预选+优选方式将Pod与Node绑定。静态调度的好处就是调度简单高效、集群资源管理方便，最大的缺点也很明显，就是不管节点实际负载，极容易导致集群负载不高 动态调度 目前主要有3种扩展调度器方法： extender扩展调度[15]，包含预选和优选接口的webhook，自实现逻辑对节点进行过滤和打分，参与调度流程中各个阶段的决策 自定义调度器[16]，通过修改pod的spec.schedulerName来选择调度器。比较灵活，但研发成本高。当集群有默认调度器和自定义调度器时，会出现两个调度器争抢 Scheduling Framework[17] Kubernetes v1.19版本stable的可拔插的调度框架，开发者可以通过实现扩展点定义的接口来实现插件 —推荐 因主版本受限， 我们内部还是使用的extender， 通过实现 Filter webhook 接口，接收 scheduler 请求 Filter 基于服务画像（服务、节点的cpu、mem均值、方差、欧氏距离聚类算法）来优化调度 基本解决以下几个问题： 1 分配高负载低的情况、分配低但实际负载高的情况 2 节点CPU高负载75%以上不进行调度 3 机器打分制， 譬如ess机器分数最低 4 在线离线混部资源分配限制 开启自定义调度前 开启自定义调度后 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:4","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.5、Descheduler重调度 上面讲到kube-scheduler默认是静态调度，属于’一次性’调度， 因为 Pod一旦被绑定了节点是不会自动触发重新调度的，那在后续node节点数量、标签、污点、容忍等的变动可能会导致已经被调度过的pod不是最优调度， 官方descheduler[18] 组件补足了这一点。Descheduler可以根据一些规则和配置策略来帮助我们重新平衡集群状态，其核心原理是根据其策略配置找到可以被移除的 Pod 并驱逐它们，其本身并不会进行调度被驱逐的 Pod，而是依靠默认的调度器来实现，目前支持的策略有： RemoveDuplicates —在集群中打散 Pod LowNodeUtilization — 调度POD到未充分利用的节点上 RemovePodsViolatingInterPodAntiAffinity — 确保从节点中删除违反 Pod 反亲和性的 Pod RemovePodsViolatingNodeAffinity — 确保从节点中删除违反NoSchedule污点的 Pod RemovePodsViolatingNodeTaints — 确保从节点中删除违反节点亲和性的 Pod RemovePodsViolatingTopologySpreadConstraint — 确保从节点驱逐违反拓扑分布约束的 Pods RemovePodsHavingTooManyRestarts — 确保从节点中删除重启次数过多的 Pods PodLifeTime — 驱逐比maxPodLifeTimeSeconds更旧的 Pods ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:5","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.6、离在线业务混部 因为离线和在线业务有明显的潮汐性，进行合理的混部提升资源利用率、降低成本的有效方案 。 在线服务：运行时间长，服务流量及资源利用率有潮汐特征，时延敏感，对服务 SLA 要求极高，如消息流 Feed 服务、电商交易服务等，一般在线 k8s 集群的高峰为 08:00 - 24:00 离线作业：运行时间分区间，运行期间资源利用率较高，时延不敏感，容错率高，中断一般允许重运行，如 Hadoop[21] 生态下的 MapReduce、Spark 作业，一般离线集群的高峰为 00:00 - 8:00 离线和在线业务混部是弹性的深水区， 因为不仅涉及调度部署、资源隔离与压制、容灾治理、跨部门合作等，所以一般也就只有大厂才真实落地 我介绍下我们在践行混部的路线，混部涉及到的比较复杂， 这里只介绍个思路， 大家也可以借鉴开源方案， 譬如阿里Koordinator[19]混部系统，腾讯的Caelus[20]混部方案等 整体架构 混部三步走 阶段1 实现 Hadoop 离线集群的资源共享 容器集群通过调度特定类型的服务特定阶段调度至 Hadoop 集群中空余的资源上，在离线集群的高峰到来之前进行迁移，保证离线集群高峰时期的资源 阶段2 整机腾挪方案 以集群转让节点的方式提高整体资源利用率 容器集群通过修改调度算法，实现低峰时期的空闲资源通过整机出让的方式，把机器资源共享至 Hadoop 离线集群 反之当在线服务的波峰来临，将Hadoop离线集群的机器通过整机出让的方式，把机器资源共享至 k8s在线集群 阶段3 离在线服务容器化混部 通过调度与隔离的手段进行资源共享与竞争 保障不同业务优先级(在线服务高优先级，离线服务低优先级) 离线服务低优先级，自动占用在线服务剩余宿主机资源 在线服务业务量增加的时候自动驱逐离线服务 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:6","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"3.7、Spot抢占实例 前文我们都是在介绍集群层面的技术优化，这一节介绍的是Spot资源。Spot抢占实例的资源成本大概只占按量实例的30%左右 Amazon EC2 Spot 实例让您可以利用 AWS 云中未使用的 EC2 容量。与按需实例的价格相比，使用 Spot 实例最高可以享受 90% 的折扣。得益于 AWS 的运行规模，Spot 实例可以在运行超大规模工作负载时实现规模并节省成本。您还可以选择休眠、停止或终止 Spot 实例，只需提前两分钟通知，我们就会收回 EC2 容量。 我们得到两个重要的信息， 1 spot实例最高可以享受90% 的折扣 2 实例终止提前两分钟通知 (阿里云是5分钟) 。那如果能用好抢占实例，就可以大幅降低我们的成本，所以我们尝试将云上业务的流量承载方式设置为如下： **30%**的预留实例用来承载基础流量 **10%**的按需实例用来做弹性按需 **60%**的抢占实例做弹性支撑 因为Spot实例具有随时会被回收终止的特点，所以Spot实例比较适合灵活性较高或具有容错性的应用程序，所以在K8s的无状态业务负载节点我们大量使用了Spot实例。如果你用的是云商的容器集群，那云商会提供Spot节点得选项， 如果是自建集群， 那建议通过阶段一、二完成建设 整体架构 Kubernetes+Spot抢占架构 阶段1 已AWS为例，通过SpotFleet[25]或ASG[26]获取所需的spot实例并加入k8s集群、通过CloudWatch[27]事件通知获取机器回收的消息、通过云函数Lambda[28]触发回收节点操作、完成spot实例优雅释放 阶段2 如果我们的业务达到很大的规模，建议通过离线训练、容器集群、优雅回收三个方向完整建设 首先通过对云商spot规格、价格、中断事件的数据收集和数据分析，考虑业务集群画像因素， 做深度智能推荐、中断预测 基于成本和稳定性双重考量，深度利用ondemand和spot实例组合，构建多可用区、业务分散策略、异常处理策略等 在节点工作阶段，通过中断预测提前预测实例回收事件发生概率，主动释放spot实例， 填充新的Node节点以减少不确定性，在节点回收阶段， 通过譬如提前扩容、弹性ECI兜底等减少pod不可调度风险 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:3:7","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"spot用法可以参考 容器成本降低50%，携程在AWS Spot上的实践[22] 趣头条[23] SpotIO[24] ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:4:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"四 容器云应用弹性方向建设 前文提到kunernetes autoscaling 包括Pod 级别的自动伸缩和Node级别的自动伸缩， 接下来就聊聊Pod 级别的自动伸缩，基本包括： 原生的水平伸缩HPA[29] 事件驱动弹性KEDA[30] HPA的扩展-CronHPA、EHPA[31]、AHPA[32] 原生纵向伸缩Vertical Pod Autoscaler[9] VPA扩展-CronVPA Pod request超卖 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:5:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"4.1、水平伸缩HPA HPA[29] 会基于 kubernetes 集群内置资源指标或者自定义指标来计算 Pod 副本需求数并自动伸缩 ，因为伸缩的是副本数， 所以比较适合无状态应用deployment。kubernetes HPA 原生支持依据 CPU/Memory 资源利用率弹性伸缩，仅仅通过简单的命令就可以创建出hpa伸缩对象 kubectl autoscale deployment hpa-demo –cpu-percent=10 –min=2 –max=5 整体架构 HPA架构 Prometheus-adapter 在 HPA 实践落地过程中，仅仅依赖 CPU/Memory 利用率弹性伸缩无法满足业务在多指标扩缩、弹性伸缩稳定性方面的诸多需求，可以配置自定义的监控指标来，譬如 Prometheus-adapter[33] 1.如果metrics数据pod可以暴露，则hpa的metrics type可以为pod类型，可以创建servicemonitor[34]从pod采集监控上报prometheus，也可以pod直接上报给prometheus 2.如果metrics数据来源为k8s集群外部，比如ecs上的各种exporter，可以用servicemonitor从外部采集数据上报给集群内的prometheus,hpa的metrics type为object类型 HPA接入Prometheus-adapter 4.2、KEDA 我们看到原生HPA在支持多方数据指标时，需要做大量的工作来适配，并且原生HPA不支持预定的伸缩（解决弹性滞后的问题）、缩容到0（解决测试环境资源浪费问题）等问题，所以就出现各种基于HPA的扩展， 譬如当前最广泛应用的扩展器KEDA[30] KEDA是用于 Kubernetes 的基于事件驱动弹性伸缩器，用户只需要创建 ScaledObject 或 ScaledJob 来定义你想要伸缩的对象和你想要使用的触发器，KEDA 会处理剩下的一切！ 附上KEDA架构图和对比原生HPA接入 Prometheus adapter的对比图 KEDA架构 HPA接入外部指标架构 KEDA接入外部指标架构 4.3、CronHPA、EHPA CronHPA 工作的核心是基于检测到的周期做“定时规划”，通过规划实现提前扩容的目的 EHPA[31]、AHPA[32] 基于预测算法，提前触发应用扩容，大家感兴趣的可以深入研究下腾讯开源的基于FinOps为核心理念的Crane[31]项目 EHPA架构 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:5:1","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"4.4、垂直扩容VPA Vertical Pod Autoscaler[9]是垂直扩容，根据 Pod 的资源利用率、历史数据、异常事件，来动态调整负载的 Request 值的组件，主要关注在有状态服务、单体应用的资源伸缩场景 整体架构 该项目包括3个组成部分： Recommender - 它监视当前和过去的资源消耗，并根据它提供推荐值容器的CPU和内存请求。 Updater - 它检查哪些托管窗格具有正确的资源集，如果没有，则检查它们，以便控制器可以使用更新的请求重新创建它们 Admission Plugin - 它在新pod上设置正确的资源请求（由于Updater的活动而刚刚由其控制器创建或重新创建） VPA架构 不过VPA也有一些限制条件： VPA更新资源时要重建POD VPA和HPA同时工作时的冲突问题不好解决 VPA性能尚未在大型集群中进行测试 除了VPA， 还有没有其他方式可以对资源设置的request资源进行弹性优化呢， 这里也介绍另外两种方式 4.5、CronVPA 基本的核心还是基于检测到的周期做“定时规划”，根据业务的过去的监控数据，规划实现提前修改request的目的， 虽然也避免不了POD要进行重建 4.6、POD Request 超卖 前文我们介绍过Node节点超卖，那还有一种更细粒度的就是Pod 的资源超卖，实现方式一样是通过webhook机制动态更改Pod的request设置（limit不超卖），或者更简单粗暴一些我们在研发申请资源的时候按照静态超卖的配置比例调整request设定， 当然这里要评估对业务稳定性的影响 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:5:2","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"五 基于混合云弹性建设 从弹性的视角来讲私有云平台可以应对常态化业务访问压力，那如果遇到流量剧增，公有云更能提供成熟可靠的秒级弹性伸缩服，因此进行混合云建设可以有效填补业务高低峰访问对资源需求波动较大的业务需求场景，与私有云平台实现优势互补；当然混合云的建设不仅是为弹性，更多是为议价、多活、容灾考虑。如下我以私有云IDC和阿里云为例，举例其中一种混合云的形态，数据层是DTS[35]同步、流量通过云解析DNS实现按照权重分发： 混合云架构 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:6:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"六 Serverless 文中提到的这些资源伸缩及优化的方式，无疑都需要有个强大的技术团队来做支撑，并且这些对未来的大多数公司来讲也不是弹性优化的首选，或许Serverless才是云原生弹性演进的未来 Serverless 不是特指某种技术，而是无服务器、按需弹性、按量计费、简化运维等的工具结合， 通过一个应用引擎框架集成云开发、FaaS、BaaS、托管K8s、DevOps、服务治理、弹性等帮助业务轻松上云 比较流行的的开源框架像Serverless[36] Knative[37] OpenFass[38] Serverless架构 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:7:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"七 总结 本文介绍了企业能够实施和采纳的弹性伸缩及优化的建设路线，基于上述部分方向建设，我们成功将资源CPU平均利用率从10%提升到30%，云服务器月度成本降低60%。本文更多是以全局视角让大家理解在弹性伸缩及优化建设的方向，希望对大家有所帮助。并未介绍过多技术细节，后面有机会再对文中方案做细节介绍 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:8:0","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"参考资料 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:8:1","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":["kubernetes"],"content":"[1]: https://kubernetes.io/ kubernetes [2]: https://en.wikipedia.org/wiki/Serverless_computing “Serverless Wiki” [3]: https://kubernetes.io/docs/concepts/architecture/nodes/ “Node” [4]: https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/ “自定义调度” [5]: https://github.com/kubernetes-sigs/descheduler “重调度” [6]: https://aws.amazon.com/ec2/spot/?nc1=h_ls “Aws Spot” [7]: https://github.com/kubernetes/autoscaler “autoscaler” [8]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ “HPA” [9]: https://github.com/kubernetes/design-proposals-archive/blob/main/autoscaling/vertical-pod-autoscaler.md “VPA” [10]: https://kubernetes.io/zh-cn/docs/concepts/architecture/nodes/ “Cordon” [11]: https://kubernetes.io/docs/tasks/administer-cluster/safely-drain-node/ “Drain” [12]: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/ “PDB” [13]: https://kubernetes.io/docs/reference/access-authn-authz/extensible-admission-controllers/ “Dynamic Admission Control” [14]: https://kubernetes.io/docs/concepts/scheduling-eviction/kube-scheduler/ “Scheduler” [15]: https://kubernetes.io/docs/concepts/extend-kubernetes/#scheduler-extensions “扩展调度” [16]: https://kubernetes.io/docs/tasks/extend-kubernetes/configure-multiple-schedulers/ “多调度器” [17]: https://kubernetes.io/docs/concepts/scheduling-eviction/scheduling-framework/ “scheduling-framework” [18]: https://github.com/kubernetes-sigs/descheduler “重调度” [19]: https://github.com/koordinator-sh/koordinator “koordinator” [20]: https://github.com/Tencent/Caelus “Caelus” [21]: https://hadoop.apache.org/ “hadoop” [22]: https://mp.weixin.qq.com/s/xqsNeN28TCS5YzesBUIsxw “干货 | 容器成本降低50%，携程在AWS Spot上的实践” [23]: http://cloud.qutoutiao.net/ “趣头条” [24]: https://spot.io/ “spotio” [25]: https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html “spot-fleet” [26]: https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-groups.html “ASG” [27]: https://aws.amazon.com/cloudwatch/ “cloudwatch” [28]: https://aws.amazon.com/lambda/ “lambda” [29]: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/ “HPA” [30]: https://keda.sh/ “KEDA” [31]: https://github.com/gocrane/crane “EHPA” [32]: https://www.alibabacloud.com/blog/599120 “AHPA” [33]: https://github.com/kubernetes-sigs/prometheus-adapter “prometheus-adapter” [34]: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/getting-started.md “prometheus-monitor” [35]: https://help.aliyun.com/product/26590.html “阿里云DTS” [36]: https://www.serverless.com/ “serverless” [37]: https://knative.dev/ “knative” [38]: https://www.openfaas.com/ “openfaas” [39]: https://cloud.tencent.com/developer/article/1505214 “腾讯自研业务上云：优化Kubernetes集群负载的技术方案探讨” [40]: https://mp.weixin.qq.com/s/KCHlbyNyJyOuZ9WJyx1qxg Vivo计算平台弹性实践 ","date":"2022-08-01","objectID":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/:8:2","tags":["kubernetes"],"title":"[转载]企业级弹性伸缩和优化建设","uri":"/post/%E8%BD%AC%E8%BD%BD%E4%BC%81%E4%B8%9A%E7%BA%A7%E5%BC%B9%E6%80%A7%E4%BC%B8%E7%BC%A9%E5%92%8C%E4%BC%98%E5%8C%96%E5%BB%BA%E8%AE%BE/"},{"categories":null,"content":"Ingress 资源是 Kubernetes 众多成功故事之一。它创建了一个不同的 Ingress 控制器生态系统，这些控制器以标准化和一致的方式在成千上万的集群中使用。这种标准化帮助用户采用 Kubernetes。然而，在 Ingress 创建 5 年后，有迹象表明，分裂为不同但惊人相似的 CRD 和超载的注释。使 Ingress 普及的可移植性同样也限制了它的未来。 在 2019 年圣地亚哥 Kubecon 大会上，一群热情的贡献者聚集在一起讨论 Ingress 的演变。讨论蔓延到了街对面的酒店大厅，结果就是后来被称为 Gateway API 的东西。这一讨论是基于以下几个关键假设： 作为路由匹配、流量管理和服务暴露基础的 API 标准已经商品化，作为自定义 API 对其实现者和用户几乎没有提供什么价值 可以通过共同的核心 API 资源来表示 L4/L7 路由和流量管理 以一种不牺牲核心 API 的用户体验的方式，为更复杂的功能提供可扩展性是可能的 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:0:0","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"引入 Gateway API 这就引出了允许 Gateway API 在 Ingress 基础上改进的设计原则： 表达能力——除了 HTTP 主机/路径匹配和 TLS 之外，Gateway API 还可以表达 HTTP 头操作、流量加权和镜像、TCP/UDP 路由以及其他只能在 Ingress 中通过自定义注释才能实现的功能。 面向角色的设计——API 资源模型反映了在路由和 Kubernetes 服务网络中常见的职责分离。 可扩展性——资源允许在 API 的不同层上附加任意的配置。这使得在最合适的地方可以进行细粒度定制。 灵活的一致性——Gateway API 定义了不同的一致性级别——核心（强制支持）、扩展（如果支持则可移植）和自定义（没有可移植性保证），统称为灵活的一致性[1]。这促进了一个高度可移植的核心 API（如 Ingress），它仍然为网关控制器实现者提供灵活性。 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:1:0","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Gateway API 是什么样子的？ Gateway API 引入了一些新的资源类型： GatewayClasses 是集群范围的资源，作为模板来显式定义从它们派生的 Gateways 的行为。这在概念上类似于 StorageClasses，但用于联网数据平面。 Gateways 是 GatewayClasses 的部署实例。它们是执行路由的数据平面的逻辑表示，可以是集群内代理、硬件 LB 或云 LB。 路由不是单一的资源，而是代表许多不同协议特定的 Route 资源。HTTPRoute 具有匹配、过滤和路由规则，这些规则应用于能够处理 HTTP 和 HTTPS 流量的 Gateways。类似地，TCPRoutes、UDPRoutes 和 TLSRoutes 也具有特定于协议的语义。此模型还允许 Gateway API 将来增量地扩展其协议支持。 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:1:1","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"网关控制器实现 好消息是，尽管 Gateway 是在Alpha[2]阶段，但已经有几个你可以运行的Gateway 控制器实现[3]。由于它是一个标准化的规范，下面的示例可以在它们中的任何一个上运行，并且应该以完全相同的方式工作。查看入门手册[4]，了解如何安装和使用这些网关控制器之一。 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:1:2","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"Gateway API 例子 在下面的例子中，我们将演示不同 API 资源之间的关系，并带你浏览一个常见的用例： 团队 foo 将他们的应用部署在 foo 命名空间中。他们需要控制应用程序不同页面的路由逻辑。 团队 bar 运行在 bar 命名空间中。他们希望能够对他们的应用进行蓝绿发布以降低风险。 平台团队负责管理 Kubernetes 集群中所有应用的负载均衡器和网络安全。 下面的 foo-route 对 foo 命名空间中的各种服务进行路径匹配，并且还有一个到 404 服务器的默认路由。这将分别通过 foo.example.com/login 和 foo.example.com/home 暴露 foo-auth 和 foo-home 服务： kind: HTTPRoute apiVersion: networking.x-k8s.io/v1alpha1 metadata: name: foo-route namespace: foo labels: gateway: external-https-prod spec: hostnames: - \"foo.example.com\" rules: - matches: - path: type: Prefix value: /login forwardTo: - serviceName: foo-auth port: 8080 - matches: - path: type: Prefix value: /home forwardTo: - serviceName: foo-home port: 8080 - matches: - path: type: Prefix value: / forwardTo: - serviceName: foo-404 port: 8080 bar 团队在同一个 Kubernetes 集群的 bar 命名空间中操作，也希望将他们的应用程序暴露给互联网，但他们也希望控制自己的灰度和蓝绿发布。下面的 HTTPRoute 被配置为以下行为： bar.example.com 的流量： 将 90%的流量发送到 bar-v1 将 10%的流量发送给 bar-v2 对于使用 HTTP 头 env:canary 到 bar.example.com 的流量： 将所有流量发送到 bar-v2 kind: HTTPRoute apiVersion: networking.x-k8s.io/v1alpha1 metadata: name: bar-route namespace: bar labels: gateway: external-https-prod spec: hostnames: - \"bar.example.com\" rules: - forwardTo: - serviceName: bar-v1 port: 8080 weight: 90 - serviceName: bar-v2 port: 8080 weight: 10 - matches: - headers: values: env: canary forwardTo: - serviceName: bar-v2 port: 8080 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:2:0","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"路由和网关绑定 因此，我们有两个匹配的 HTTPRoutes，并将流量路由到不同的服务。你可能想知道，在哪里可以访问这些服务？它们通过哪些网络或 IP 暴露？ 路由如何向客户端暴露由路由绑定[5]来管理，该绑定描述了路由和网关之间如何创建双向关系。当 Routes 被绑定到一个 Gateway 时，这意味着它们的集合路由规则被配置在底层的负载均衡器或代理上，并且路由可以通过网关访问。因此，网关是可以通过路由配置的网络数据平面的逻辑表示。 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:2:1","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"行政委托 Gateway 和 Route 资源之间的分离允许集群管理员将一些路由配置委派给各个团队，同时仍然保持集中控制。以下网关资源在端口 443 上暴露 HTTPS，并使用由集群管理员控制的证书终止端口上的所有通信流。 kind: Gateway apiVersion: networking.x-k8s.io/v1alpha1 metadata: name: prod-web spec: gatewayClassName: acme-lb listeners: - protocol: HTTPS port: 443 routes: kind: HTTPRoute selector: matchLabels: gateway: external-https-prod namespaces: from: All tls: certificateRef: name: admin-controlled-cert 下面的 HTTPRoute 展示了 Route 如何通过它的 kind（HTTPRoute）和资源标签（gateway=external-https-prod）来确保它匹配网关的选择器。 # Matches the required kind selector on the Gateway kind: HTTPRoute apiVersion: networking.x-k8s.io/v1alpha1 metadata: name: foo-route namespace: foo-ns labels: # Matches the required label selector on the Gateway gateway: external-https-prod ... ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:2:2","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"面向角色的设计 当你将它们放在一起时，你就拥有了一个可以被多个团队安全地共享的负载平衡基础设施。Gateway API 不仅是用于高级路由的更具表现力的 API，而且是面向角色的 API，专为多租户基础设施设计。它的可扩展性确保了它将在保持可移植性的同时为未来的用例发展。最终，这些特性将允许 Gateway API 适应不同的组织模型和实现，直到未来。 ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:2:3","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"尝试一下，并参与其中 有许多资源可以查看以了解更多。 查看入门手册，看看可以解决哪些用例。 尝试使用现有的网关控制器之一 或者参与[6]并帮助设计和影响 Kubernetes 服务网络的未来！ ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:2:4","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":null,"content":"参考资料 [1] 灵活的一致性: https://gateway-api.sigs.k8s.io/concepts/guidelines/#conformance [2] Alpha: https://github.com/kubernetes-sigs/gateway-api/releases [3] Gateway 控制器实现: https://gateway-api.sigs.k8s.io/references/implementations/ [4] 入门手册: https://gateway-api.sigs.k8s.io/guides/getting-started/ [5] 路由绑定: https://gateway-api.sigs.k8s.io/concepts/api-overview/#route-binding [6] 参与: https://gateway-api.sigs.k8s.io/contributing/community/ ","date":"2022-07-29","objectID":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/:2:5","tags":null,"title":"通过Gateway API不断演变的Kubernetes网络","uri":"/post/%E9%80%9A%E8%BF%87gateway-api%E4%B8%8D%E6%96%AD%E6%BC%94%E5%8F%98%E7%9A%84kubernetes%E7%BD%91%E7%BB%9C/"},{"categories":["云原生"],"content":"安装kubebuilder brew install kubebuilder kubebuilder version ","date":"2022-07-21","objectID":"/post/da6323/:0:1","tags":["kubebuilder","operator"],"title":"kubebuilder开发operator","uri":"/post/da6323/"},{"categories":["云原生"],"content":"创建项目目录 mkdir custom-controllers cd custom-controllers go mod init controllers.alongparty.cn ","date":"2022-07-21","objectID":"/post/da6323/:0:2","tags":["kubebuilder","operator"],"title":"kubebuilder开发operator","uri":"/post/da6323/"},{"categories":["云原生"],"content":"kubebuilder初始化项目 kubebuilder init --domain controller.alongparty.cn --license apache2 --owner \"kbsonlong\" kubebuilder create api --group controller --version v1 --kind Application make ","date":"2022-07-21","objectID":"/post/da6323/:0:3","tags":["kubebuilder","operator"],"title":"kubebuilder开发operator","uri":"/post/da6323/"},{"categories":["云原生"],"content":"参考资料 使用kubebuilder开发operator详解 ","date":"2022-07-21","objectID":"/post/da6323/:0:4","tags":["kubebuilder","operator"],"title":"kubebuilder开发operator","uri":"/post/da6323/"},{"categories":null,"content":"安装ocserv apt-get install ocserv -y ","date":"2022-07-21","objectID":"/post/90ef46/:0:1","tags":null,"title":"ocserv部署","uri":"/post/90ef46/"},{"categories":null,"content":"申请免费证书 修改dns指向服务器 生成证书 certbot certonly --standalone --preferred-challenges http --agree-tos --email kbsonlong@gmail.com -d myvpn.alongparty.cn # 续签证书 certbot renew --quiet --no-self-upgrade ","date":"2022-07-21","objectID":"/post/90ef46/:0:2","tags":null,"title":"ocserv部署","uri":"/post/90ef46/"},{"categories":null,"content":"修改配置 auth = \"plain[/etc/ocserv/ocpasswd]\" tcp-port = 443 udp-port = 443 run-as-user = nobody run-as-group = daemon socket-file = /var/run/ocserv-socket server-cert = /etc/letsencrypt/live/myvpn.alongparty.cn/fullchain.pem server-key = /etc/letsencrypt/live/myvpn.alongparty.cn/privkey.pem isolate-workers = false max-clients = 16 max-same-clients = 2 rate-limit-ms = 100 server-stats-reset-time = 604800 keepalive = 32400 dpd = 90 mobile-dpd = 1800 switch-to-tcp-timeout = 25 try-mtu-discovery = true cert-user-oid = 0.9.2342.19200300.100.1.1 tls-priorities = \"NORMAL:%SERVER_PRECEDENCE:%COMPAT:-VERS-SSL3.0:-VERS-TLS1.0:-VERS-TLS1.1\" auth-timeout = 240 min-reauth-time = 300 max-ban-score = 80 ban-reset-time = 1200 cookie-timeout = 300 deny-roaming = false rekey-time = 172800 rekey-method = ssl use-occtl = true pid-file = /var/run/ocserv.pid device = vpns predictable-ips = true default-domain = example.com ipv4-network = 10.255.255.0 ipv4-netmask = 255.255.255.0 tunnel-all-dns = true dns = 8.8.8.8 dns = 4.2.2.4 dns = 2001:4860:4860::8888 dns = 2001:4860:4860::8844 ping-leases = false cisco-client-compat = true dtls-legacy = true ","date":"2022-07-21","objectID":"/post/90ef46/:0:3","tags":null,"title":"ocserv部署","uri":"/post/90ef46/"},{"categories":["云原生"],"content":"1限流 ","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:0:0","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["云原生"],"content":"1.1什么是限流 ​ 举个例子，比如我们有个桶，桶里有两个开关，一个往外出水，一个网内注水，当出水的速度慢于注水的速度时，到一定时间水就会从桶里溢出。如果我们限制注水速率，就可以防止水从桶里溢出，这就是限流。 ​ 具体到软件层面，我们把请求速率看做是注水，把系统cpu，内存等资源看做是放水，当请求速率过快，消耗太多资源时系统就可能崩溃。软件限流就是限制tps或qps指标，以达到保护系统的目的，虽然可能部分用户无法服务，但是系统整体还是健康的，还可以对外部提供服务，不是整体挂掉。 ","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:1:0","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["云原生"],"content":"1.2限流算法 1.2.1漏桶算法 就像一个漏斗以下，下面小，上面大。漏桶流出的速率被限制在比较小的范围，当漏桶满时，漏桶就会溢出，进来的请求就会被抛弃掉。特别是应对突发流量，漏桶的速率是恒定的，这样可以有效防止应突发流量导致系统崩溃。 ","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:2:0","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["云原生"],"content":"1.2.2令牌桶算法 令牌桶算法的原理，关键在令牌，它是指往桶里以一个不变的速率放入令牌，当有请求时，如果桶里有令牌，请求就消费一个令牌，请求继续进行；当请求到来，桶里没有令牌时，请求就会被抛弃掉，拒绝服务；当桶里的令牌满时，令牌就会被抛弃掉。 ","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:2:1","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["云原生"],"content":"1.2.3计数器算法 计数器算法是指一段时间设置一个计数器，当有请求时计数器就加一，请求继续进行；在技术器时间范围内，当计数器数值超过指定值，请求就被拒绝；当时间范围结束，就重置计数器。技术器算法有个缺陷，就是如果计数器时间是1分钟，当前1秒来了大量请求，讲技术器用完了，后续59秒时间就没法提供服务。 ","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:2:2","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["云原生"],"content":"1.2实操 ","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:3:0","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["云原生"],"content":"1.2.1 http 1.2.1.1单集群 istio部署和bookinfo实例部署大家自行完成，都看这种深度的文章了这个应该不是事。 1.2.1.1.1集群内服务限流 1.2.1.1.1.1本地限流 cat \u003c\u003cEOF \u003e envoyfilter-local-rate-limit.yaml apiVersion: networking.istio.io/v1alpha3 kind: EnvoyFilter metadata: name: filter-local-ratelimit-svc spec: workloadSelector: labels: app: productpage configPatches: - applyTo: HTTP_FILTER match: listener: filterChain: filter: name: \"envoy.filters.network.http_connection_manager\" patch: operation: INSERT_BEFORE value: name: envoy.filters.http.local_ratelimit typed_config: \"@type\": type.googleapis.com/udpa.type.v1.TypedStruct type_url: type.googleapis.com/envoy.extensions.filters.http.local_ratelimit.v3.LocalRateLimit value: stat_prefix: http_local_rate_limiter token_bucket: max_tokens: 10 tokens_per_fill: 10 fill_interval: 60s filter_enabled: runtime_key: local_rate_limit_enabled default_value: numerator: 100 denominator: HUNDRED filter_enforced: runtime_key: local_rate_limit_enforced default_value: numerator: 100 denominator: HUNDRED response_headers_to_add: - append: false header: key: x-local-rate-limit value: 'true' EOF kubectl apply -f envoyfilter-local-rate-limit.yaml -n istio 说明：本地限流需要通过EnvoyFilter来实现，他不会请求外部服务，在envoy内部实现支持，是一个令牌桶的算法。http filter的名称必须是envoy.filters.http.local_ratelimit，type和typeurl是固定的，stat_prefix可以随便改，表示生成stat的指标前缀。token_bucket配置令牌桶，max_tokens表示最大令牌数量，tokens_per_fill表示每次填充的令牌数量，fill_interval表示填充令牌的间隔。filter_enabled表示启用但不是强制，filter_enforced表示强制，可以配置百分比。response_headers_to_add修改响应头信息，append为false表示修改，true表示添加。runtime_key 运行时的key，具体有啥用不清楚。 执行压测： [root@node01 45]# go-stress-testing -c 10 -n 10000 -u http://192.168.229.134:30945/productpage 开始启动 并发数:10 请求数:10000 请求参数: request: form:http url:http://192.168.229.134:30945/productpage method:GET headers:map[] data: verify:statusCode timeout:30s debug:false ─────┬───────┬───────┬───────┬────────┬────────┬────────┬────────┬────────┬────────┬──────── 耗时│ 并发数│ 成功数│ 失败数│ qps │最长耗时│最短耗时│平均耗时│下载字节│字节每秒│ 错误码 ─────┼───────┼───────┼───────┼────────┼────────┼────────┼────────┼────────┼────────┼──────── 1s│ 7│ 2│ 761│ 2.94│ 124.68│ 1.98│ 3406.97│ 21,476│ 21,470│200:2;429:761 2s│ 10│ 5│ 1636│ 2.55│ 1788.46│ 1.98│ 3928.11│ 52,771│ 26,383│200:5;429:1636 3s│ 10│ 5│ 2962│ 1.70│ 1788.46│ 1.04│ 5871.68│ 76,639│ 25,545│200:5;429:2962 4s│ 10│ 5│ 4459│ 1.28│ 1788.46│ 1.04│ 7810.78│ 103,585│ 25,896│200:5;429:4459 429 Too Many Requests (太多请求) 当你需要限制客户端请求某个服务的数量，也就是限制请求速度时，该状态码就会非常有用 清理： kubectl delete envoyfilter filter-local-ratelimit-svc -n istio 1.2.1.1.1.2全局限流 部署ratelimit 1创建cm cat \u003c\u003c EOF \u003e ratelimit-config.yaml apiVersion: v1 kind: ConfigMap metadata: name: ratelimit-config data: config.yaml: | domain: productpage-ratelimit descriptors: - key: PATH value: \"/productpage\" rate_limit: unit: minute requests_per_unit: 1 - key: PATH rate_limit: unit: minute requests_per_unit: 100 EOF kubectl apply -f ratelimit-config.yaml -n istio 说明: 这个configmap是限速服务用到的配置文件，他是envoy v3版本的限速格式。domain是域名，他会在envoyfilter中被引用，descriptors的PATH,表示请求的路径可以有多个值，rate_limit配置限速配额，这里productpage配了1分钟1个请求，其他url是1分钟100个请求 2创建限速服务deployment cat \u003c\u003c EOF \u003e ratelimit-deploy.yaml apiVersion: v1 kind: Service metadata: name: redis labels: app: redis spec: ports: - name: redis port: 6379 selector: app: redis --- apiVersion: apps/v1 kind: Deployment metadata: name: redis spec: replicas: 1 selector: matchLabels: app: redis template: metadata: labels: app: redis spec: containers: - image: redis:alpine imagePullPolicy: Always name: redis ports: - name: redis containerPort: 6379 restartPolicy: Always serviceAccountName: \"\" --- apiVersion: v1 kind: Service metadata: name: ratelimit labels: app: ratelimit spec: ports: - name: http-port port: 8080 targetPort: 8080 protocol: TCP - name: grpc-port port: 8081 targetPort: 8081 protocol: TCP - name: http-debug port: 6070 targetPort: 6070 protocol: TCP selector: app: ratelimit --- apiVersion: apps/v1 kind: Deployment metadata: name: ratelimit spec: replicas: 1 selector: matchLabels: app: ratelimit strategy: type: Recreate template: metadata: labe","date":"2022-05-23","objectID":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/:3:1","tags":["istio"],"title":"Istio防故障利器","uri":"/post/istio%E9%98%B2%E6%95%85%E9%9A%9C%E5%88%A9%E5%99%A8/"},{"categories":["hugo"],"content":"创建Github Actions流水线 mkdir -p .github/workflows/ touch hugo.yaml 发布到本仓库 name: GitHub Pages Deploy Local REPOSITORY on: push: branches: - master # Set a branch to deploy pull_request: jobs: deploy: runs-on: ubuntu-20.04 concurrency: group: ${{ github.workflow }}-${{ github.ref }} steps: - uses: actions/checkout@v3 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 1 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: '0.91.2' extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.GITHUB_TOKEN }} publish_dir: ./public 发布到另外仓库 name: CI #自动化的名称 on: push: # push的时候触发 branches: # 那些分支需要触发 - master jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 1 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' extended: true - name: Build run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.EXTERNAL_REPOSITORY_TOKEN }} publish_dir: ./public external_repository: kbsonlong/devops.alongparty.cn 注意: 发布到本仓库github_token不需要手动创建GITHUB_TOKEN, 发布到其他仓库personal_token需要提前创建并配置secret变量 创建SSH证书 ssh-keygen -t rsa -b 4096 -C \"$(git config user.email)\" -f gh-pages -N \"\" 配置SSH公钥 配置SSH私钥 使用SSH私钥发布 name: CI #自动化的名称 on: push: # push的时候触发 branches: # 那些分支需要触发 - master jobs: deploy: runs-on: ubuntu-20.04 steps: - uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes (true OR recursive) fetch-depth: 1 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' extended: true - name: Build run: hugo --minify - name: Deploy with PRIVATE KEY uses: peaceiris/actions-gh-pages@v3 with: cname: devops.alongparty.cn env: ACTIONS_DEPLOY_KEY: ${{ secrets.HUGO_DEPLOY_PRIVATE_KEY }} EXTERNAL_REPOSITORY: kbsonlong/devops.alongparty.cn PUBLISH_BRANCH: gh-pages PUBLISH_DIR: ./public 注意: 部署到另外仓库时ssh私钥配置在源仓库, ssh公钥配置在目标仓库或者全局 ","date":"2022-05-23","objectID":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:1","tags":["github actions"],"title":"Github Actions自动部署hugo博客","uri":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo"],"content":"创建GITHUB Personal TOKEN ","date":"2022-05-23","objectID":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:2","tags":["github actions"],"title":"Github Actions自动部署hugo博客","uri":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo"],"content":"创建仓库Secrets变量 ","date":"2022-05-23","objectID":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:3","tags":["github actions"],"title":"Github Actions自动部署hugo博客","uri":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo"],"content":"Github Page配置自定义域名 echo \"\u003c自定义域名\u003e\" \u003estatic/CNAME ","date":"2022-05-23","objectID":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:4","tags":["github actions"],"title":"Github Actions自动部署hugo博客","uri":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["hugo"],"content":"Deploy时过滤静态文件 - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.EXTERNAL_REPOSITORY_TOKEN }} external_repository: kbsonlong/devops.alongparty.cn publish_branch: gh-pages # default: gh-pages publish_dir: ./public exclude_assets: './algolia.json,./*/*.md' # 支持正则过滤,基于编译后的静态文件,根目录publish_dir user_name: 'github-actions[bot]' user_email: 'github-actions[bot]@users.noreply.github.com' commit_message: ${{ github.event.head_commit.message }} tag_name: ${{ steps.prepare_tag.outputs.deploy_tag_name }} tag_message: 'Deployment ${{ steps.prepare_tag.outputs.tag_name }}' ","date":"2022-05-23","objectID":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/:0:5","tags":["github actions"],"title":"Github Actions自动部署hugo博客","uri":"/post/github-actions%E8%87%AA%E5%8A%A8%E9%83%A8%E7%BD%B2hugo%E5%8D%9A%E5%AE%A2/"},{"categories":["《Git》学习笔记"],"content":"rebase分支合并 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:0:0","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"说明 以下 v2 是某个需求的开发分支， dev是总的开发分支，v2 是基于dev分支签出的。 当完成v2的开发后，需要把代码合并到dev，我们可以使用rebase进行合并： # 首先将 v2 push到远程仓库 git add . git commit -m 'xxx' git push origin v2 # 切换到 dev 拉取最新代码 git checkout dev git pull origin dev # 切换到 v2 git checkout v2 git rebase dev # 将 v2 的所有[commit] 变基到(应用到) dev # 切换到 dev git checkout dev git merge v2 # 将 dev分支 快进合并 （此时 (HEAD -\u003e dev, v2) [commit] 两个分支指向同一个提交） # 查看 原v2的[commit]记录 是否在dev分支的最前面（变基成功会把v2的提交记录应用到dev分支的最前面） git log # 如果到这一步发现有问题，尝试使用 git --abort中止变基，如果还是有问题的可以在dev分支上使用《后悔药》操作， 再到v2分支上使用《后悔药》操作，即可使两个分支都回退到 rebase变基 之前的状态 # 试运行项目是否有问题 yarn start git status # 查看状态是否有问题 git push origin dev # 推送到远程仓库的 dev ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:1:0","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"变基要遵守的准则 几个人同时在一个分支上进行开发和提交时，你不要中途执行变基，只有在大家都完成工作之后才可以执行变基。 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:1:1","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"变基的实质 变基操作的实质是丢弃一些现有的提交，然后相应地新建一些内容一样但实际上不同的提交。 因此，变基操作过后的分支将不要再使用。 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:1:2","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"后悔药 # 查看HEAD指针变动记录 git reflog # 记录示例(当前分支是v2): 07c398f (HEAD -\u003e v2, master) HEAD@{0}: checkout: moving from master to v2 07c398f (HEAD -\u003e v2, master) HEAD@{1}: rebase (finish): returning to refs/heads/master 07c398f (HEAD -\u003e v2, master) HEAD@{2}: rebase (start): checkout v2 15a97d8 HEAD@{3}: reset: moving to 15a97d8 07c398f (HEAD -\u003e v2, master) HEAD@{4}: merge v2: Fast-forward 15a97d8 HEAD@{5}: checkout: moving from v2 to master 07c398f (HEAD -\u003e v2, master) HEAD@{6}: rebase (finish): returning to refs/heads/v2 07c398f (HEAD -\u003e v2, master) HEAD@{7}: rebase (pick): C 15a97d8 HEAD@{8}: rebase (start): checkout master # 首次rebase d278ecd HEAD@{9}: checkout: moving from master to v2 # rebase前的状态 15a97d8 HEAD@{10}: commit: D # 可见，示例中最初的 rebase 操作是 HEAD@{8}，想回退到变基前的状态需让指针指向 HEAD@{9} git reset --hard d278ecd # 重置当前分支的HEAD为指定[commit]，同时重置暂存区和工作区，与指定[commit]一致 # 此时打印 log 查看是否回到之前的状态 git log 注意：此操作只能回退当前的分支，如其他分支也要回退，需要切换到该分支并执行上面操作。 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:2:0","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"开发期间的rebase操作 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:3:0","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"背景 有两个分支： dev *v2 2.4-dev 是基于dev切出来的。 提交记录如下： dev a - b - c v2 开发期间，两个分支同时有新的commit ： dev a - b - c - d - e \\ - f - g v2 当前你正在v2进行开发，dev也同时进行开发，并有重大的改变，你需要把dev的提交同步到v2。 需求： 把dev中新的提交同步到v2，且不能影响dev分支。 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:3:1","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"操作步骤 基于最新的 dev 切一个新的分支 dev-copy dev-copy 和 dev 两者的 commit ID 一致。 在dev-copy中执行rebase，将 dev-copy 的提交变基到 v2 git rebase v2 # 将 dev-copy 的提交[commit] 变基到(应用到) v2 删除原v2分支，将dev-copy分支名改为v2 # 当前在 dev-copy 分支 git branch -d v2 # 删除分支 git branch -m dev-copy v2 # 重命名 ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:3:2","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"git cherry-pick 来源：《git cherry-pick 教程》 用于将单个或几个[commit]复制到另一个分支。 基本应用 git cherry-pick \u003ccommitHash\u003e # 将commitHash应用于当前分支 上面命令就会将指定的提交commitHash，应用于当前分支。这会在当前分支产生一个新的提交，当然它们的哈希值会不一样。 git cherry-pick命令的参数，不一定是提交的哈希值，分支名也是可以的，表示转移该分支的最新提交。 转移多个提交 Cherry pick 支持一次转移多个提交。 git cherry-pick \u003cHashA\u003e \u003cHashB\u003e # A和B提交 上面的命令将 A 和 B 两个提交应用到当前分支。这会在当前分支生成两个对应的新提交。 如果想要转移一系列的连续提交，可以使用下面的简便语法。 git cherry-pick A..B # A到B提交，不包含A 上面的命令可以转移从 A 到 B 的所有提交。它们必须按照正确的顺序放置：提交 A 必须早于提交 B，否则命令将失败，但不会报错。 注意，使用上面的命令，提交 A 将不会包含在 Cherry pick 中。如果要包含提交 A，可以使用下面的语法。 git cherry-pick A^..B # A到B提交，包含A ","date":"2020-11-18","objectID":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/:3:3","tags":["Git"],"title":"Git变基合并","uri":"/post/git%E5%8F%98%E5%9F%BA%E5%90%88%E5%B9%B6/"},{"categories":["《Git》学习笔记"],"content":"Git分支-变基 在 Git 中整合来自不同分支的修改主要有两种方法：merge 以及 rebase。 在本节中我们将学习什么是“变基”，怎样使用“变基”，并将展示该操作的惊艳之处，以及指出在何种情况下你应避免使用它。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:0:0","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"变基的基本操作 请回顾之前在 分支的合并 中的一个例子，你会看到开发任务分叉到两个不同分支，又各自提交了更新。 图0. 分叉的提交历史 ▲ 之前介绍过，整合分支最容易的方法是 merge 命令。 它会把两个分支的最新快照（C3 和 C4）以及二者最近的共同祖先（C2）进行三方合并，合并的结果是生成一个新的快照（并提交）。 图1. 通过合并操作来整合分叉的历史 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:1:0","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"概念 变基就是：将某一分支上的所有修改复制到另一分支上 除了merge，还有一种方法：你可以提取在 C4 中引入的补丁和修改，然后在 C3 的基础上应用一次。 在 Git 中，这种操作就叫做 变基（rebase）。 你可以使用 rebase 命令将提交到某一分支上的所有修改都移到另一分支上，就好像“重新播放”一样。 在这个例子中，你可以检出 experiment 分支，然后将它变基到 master 分支上： $ git checkout experiment $ git rebase master # 将experiment上的修改变基到master分支上（将experiment的提交移动到master上。） First, rewinding head to replay your work on top of it... Applying: added staged command 它的原理是首先找到这两个分支（即当前分支 experiment、变基操作的目标基底分支 master） 的最近共同祖先 C2，然后对比当前分支相对于该祖先的历次提交，提取相应的修改并存为临时文件， 然后将当前分支指向目标基底 C3, 最后以此将之前另存为临时文件的修改依序应用。 （译注：写明了 commit id，以便理解，下同） ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:1:1","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"原理 找到当前分支和目标分支的最近共同祖先 对比当前分支相对于该共同祖先的历次提交 提取相应的修改并存为临时文件 将当前分支指向目标分支 将之前临时文件的修改依序应用 图2.将 C4 中的修改变基到 C3 上 ▲ 现在回到 master 分支，进行一次快进合并。 $ git checkout master $ git merge experiment 图3.master 分支的快进合并 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:1:2","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"步骤 先检出源分支，将源分支的修改变基到目标分支。切回目标分支，进行一次快进合并 # 示意： git checkout \u003c源分支\u003e git (源分支的修改)rebase(到) \u003c目标分支\u003e git checkout \u003c目标分支\u003e git merge \u003c源分支\u003e 此时，C4' 指向的快照就和 the merge example 中 C5 指向的快照一模一样了。 这两种整合方法的最终结果没有任何区别，但是 变基使得提交历史更加整洁。 你在查看一个经过变基的分支的历史记录时会发现，尽管实际的开发工作是并行的， 但它们看上去就像是串行的一样，提交历史是一条直线没有分叉。 一般我们这样做的目的是为了确保在向远程分支推送时能保持提交历史的整洁——例如向某个其他人维护的项目贡献代码时。 在这种情况下，你首先在自己的分支里进行开发，当开发完成时你需要先将你的代码变基到 origin/master 上，然后再向主项目提交修改。 这样的话，该项目的维护者就不再需要进行整合工作，只需要快进合并便可。 请注意，无论是通过变基，还是通过三方合并，整合的最终结果所指向的快照始终是一样的，只不过提交历史不同罢了。 变基是将一系列提交按照原有次序依次应用到另一分支上，而合并是把最终结果合在一起。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:1:3","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"优点 变基的优点： 使提交记录更加整洁。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:1:4","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"更有趣的变基例子 在对两个分支进行变基时，所生成的“重放”并不一定要在目标分支上应用，你也可以指定另外的一个分支进行应用。 就像 从一个主题分支里再分出一个主题分支的提交历史 中的例子那样。 你创建了一个主题分支 server，为服务端添加了一些功能，提交了 C3 和 C4。 然后从 C3 上创建了主题分支 client，为客户端添加了一些功能，提交了 C8 和 C9。 最后，你回到 server 分支，又提交了 C10。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:2:0","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"更有趣的变基例子 在对两个分支进行变基时，所生成的“重放”并不一定要在目标分支上应用，你也可以指定另外的一个分支进行应用。 就像 从一个主题分支里再分出一个主题分支的提交历史 中的例子那样。 你创建了一个主题分支 server，为服务端添加了一些功能，提交了 C3 和 C4。 然后从 C3 上创建了主题分支 client，为客户端添加了一些功能，提交了 C8 和 C9。 最后，你回到 server 分支，又提交了 C10。 图4.从一个主题分支里再分出一个主题分支的提交历史 ▲ 假设你希望将 client 中的修改合并到主分支并发布，但暂时并不想合并 server 中的修改， 因为它们还需要经过更全面的测试。这时，你就可以使用 git rebase 命令的 --onto 选项， 选中在 client 分支里但不在 server 分支里的修改（即 C8 和 C9），将它们在 master 分支上重放： $ git rebase --onto master server client 以上命令的意思是：“取出 client 分支，找出它从 server 分支分歧之后的补丁， 然后把这些补丁在 master 分支上重放一遍，让 client 看起来像直接基于 master 修改一样”。这理解起来有一点复杂，不过效果非常酷。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:2:1","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"–onto选项 选中C分支中的但不在B分支里的修改，应用到A分支。 图5.截取主题分支上的另一个主题分支，然后变基到其他分支 ▲ 现在可以快进合并 master 分支了。（如图 快进合并 master 分支，使之包含来自 client 分支的修改）： $ git checkout master $ git merge client 图6.快进合并 `master` 分支，使之包含来自 `client` 分支的修改 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:2:2","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"省去先切换到源分支的步骤 git rebase \u003c目标(当前)分支\u003e \u003c源分支\u003e # 将源分支变基到目标分支。执行此命令后会自动切换到源分支 git checkout \u003c目标分支\u003e git merge \u003c源分支\u003e 注意：使用这个方法要确保源分支上的代码是最新的。 接下来你决定将 server 分支中的修改也整合进来。 使用 git rebase \u003cbasebranch\u003e \u003ctopicbranch\u003e 命令可以直接将主题分支 （即本例中的 server）变基到目标分支（即 master）上。 这样做能省去你先切换到 server 分支，再对其执行变基命令的多个步骤。 $ git rebase master server 如图 将 server 中的修改变基到 master 上 所示，server 中的代码被“续”到了 master 后面。 图7.将 `server` 中的修改变基到 `master` 上 ▲ 然后就可以快进合并主分支 master 了： $ git checkout master $ git merge server 至此，client 和 server 分支中的修改都已经整合到主分支里了， 你可以删除这两个分支，最终提交历史会变成图 最终的提交历史 中的样子： $ git branch -d client $ git branch -d server 图8. 最终的提交历史 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:2:3","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"变基的风险 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:3:0","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"金科玉律 呃，奇妙的变基也并非完美无缺，要用它得遵守一条准则： 如果提交存在于你的仓库之外，而别人可能基于这些提交进行开发，那么不要执行变基。 如果你遵循这条金科玉律，就不会出差错。 否则，人民群众会仇恨你，你的朋友和家人也会嘲笑你，唾弃你。 ::: tip 例如：几个人同时在一个主题分支上进行开发和提交时，你不要中途执行变基，只有在大家都完成工作之后才可以执行变基。 ::: ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:3:1","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"变基的实质 变基操作的实质是丢弃一些现有的提交，然后相应地新建一些内容一样但实际上不同的提交。 如果你已经将提交推送至某个仓库，而其他人也已经从该仓库拉取提交并进行了后续工作，此时，如果你用 git rebase 命令重新整理了提交并再次推送，你的同伴因此将不得不再次将他们手头的工作与你的提交进行整合，如果接下来你还要拉取并整合他们修改过的提交，事情就会变得一团糟。 让我们来看一个在公开的仓库上执行变基操作所带来的问题。 假设你从一个中央服务器克隆然后在它的基础上进行了一些开发。 你的提交历史如图所示： 图9. 克隆一个仓库，然后在它的基础上进行了一些开发 ▲ 然后，某人又向中央服务器提交了一些修改，其中还包括一次合并。 你抓取了这些在远程分支上的修改，并将其合并到你本地的开发分支，然后你的提交历史就会变成这样： 图10. 抓取别人的提交，合并到自己的开发分支 ▲ 接下来，这个人又决定把合并操作回滚，改用变基；继而又用 git push --force 命令覆盖了服务器上的提交历史。 之后你从服务器抓取更新，会发现多出来一些新的提交。 图11. 有人推送了经过变基的提交，并丢弃了你的本地开发所基于的一些提交 ▲ 结果就是你们两人的处境都十分尴尬。 如果你执行 git pull 命令，你将合并来自两条提交历史的内容，生成一个新的合并提交，最终仓库会如图所示： 图12. 你将相同的内容又合并了一次，生成了一个新的提交 ▲ 此时如果你执行 git log 命令，你会发现有两个提交的作者、日期、日志居然是一样的，这会令人感到混乱。 此外，如果你将这一堆又推送到服务器上，你实际上是将那些已经被变基抛弃的提交又找了回来，这会令人感到更加混乱。 很明显对方并不想在提交历史中看到 C4 和 C6，因为之前就是他把这两个提交通过变基丢弃的。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:3:2","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"用变基解决变基 如果你 真的 遭遇了类似的处境，Git 还有一些高级魔法可以帮到你。 如果团队中的某人强制推送并覆盖了一些你所基于的提交，你需要做的就是检查你做了哪些修改，以及他们覆盖了哪些修改。 实际上，Git 除了对整个提交计算 SHA-1 校验和以外，也对本次提交所引入的修改计算了校验和——即 “patch-id”。 如果你拉取被覆盖过的更新并将你手头的工作基于此进行变基的话，一般情况下 Git 都能成功分辨出哪些是你的修改，并把它们应用到新分支上。 举个例子，如果遇到前面提到的 有人推送了经过变基的提交，并丢弃了你的本地开发所基于的一些提交 那种情境，如果我们不是执行合并，而是执行 git rebase teamone/master, Git 将会： 检查哪些提交是我们的分支上独有的（C2，C3，C4，C6，C7） 检查其中哪些提交不是合并操作的结果（C2，C3，C4） 检查哪些提交在对方覆盖更新时并没有被纳入目标分支（只有 C2 和 C3，因为 C4 其实就是 C4’） 把查到的这些提交应用在 teamone/master 上面 从而我们将得到与 你将相同的内容又合并了一次，生成了一个新的提交 中不同的结果，如图 在一个被变基然后强制推送的分支上再次执行变基 所示。 图13. 在一个被变基然后强制推送的分支上再次执行变基 ▲ 要想上述方案有效，还需要对方在变基时确保 C4' 和 C4 是几乎一样的。 否则变基操作将无法识别，并新建另一个类似 C4 的补丁（而这个补丁很可能无法整洁的整合入历史，因为补丁中的修改已经存在于某个地方了）。 在本例中另一种简单的方法是使用 git pull --rebase 命令而不是直接 git pull。 又或者你可以自己手动完成这个过程，先 git fetch，再 git rebase teamone/master。 如果你习惯使用 git pull ，同时又希望默认使用选项 --rebase，你可以执行这条语句 git config --global pull.rebase true 来更改 pull.rebase 的默认配置。 如果你只对不会离开你电脑的提交执行变基，那就不会有事。 如果你对已经推送过的提交执行变基，但别人没有基于它的提交，那么也不会有事。 如果你对已经推送至共用仓库的提交上执行变基命令，并因此丢失了一些别人的开发所基于的提交， 那你就有大麻烦了，你的同事也会因此鄙视你。 如果你或你的同事在某些情形下决意要这么做，请一定要通知每个人执行 git pull --rebase 命令，这样尽管不能避免伤痛，但能有所缓解。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:4:0","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"变基 vs. 合并 至此，你已在实战中学习了变基和合并的用法，你一定会想问，到底哪种方式更好。 在回答这个问题之前，让我们退后一步，想讨论一下提交历史到底意味着什么。 有一种观点认为，仓库的提交历史即是 记录实际发生过什么。 它是针对历史的文档，本身就有价值，不能乱改。 从这个角度看来，改变提交历史是一种亵渎，你使用 谎言 掩盖了实际发生过的事情。 如果由合并产生的提交历史是一团糟怎么办？ 既然事实就是如此，那么这些痕迹就应该被保留下来，让后人能够查阅。 另一种观点则正好相反，他们认为提交历史是 项目过程中发生的事。 没人会出版一本书的第一版草稿，软件维护手册也是需要反复修订才能方便使用。 持这一观点的人会使用 rebase 及 filter-branch 等工具来编写故事，怎么方便后来的读者就怎么写。 现在，让我们回到之前的问题上来，到底合并还是变基好？希望你能明白，这并没有一个简单的答案。 Git 是一个非常强大的工具，它允许你对提交历史做许多事情，但每个团队、每个项目对此的需求并不相同。 既然你已经分别学习了两者的用法，相信你能够根据实际情况作出明智的选择。 总的原则是，只对尚未推送或分享给别人的本地修改执行变基操作清理历史， 从不对已推送至别处的提交执行变基操作，这样，你才能享受到两种方式带来的便利。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/:5:0","tags":["Git"],"title":"Git分支-变基","uri":"/post/git%E5%88%86%E6%94%AF-%E5%8F%98%E5%9F%BA/"},{"categories":["《Git》学习笔记"],"content":"Git分支-分支原理 Git 处理分支的方式可谓是难以置信的轻量，创建新分支这一操作几乎能在瞬间完成，并且在不同分支之间的切换操作也是一样便捷。 与许多其它版本控制系统不同，Git 鼓励在工作流程中频繁地使用分支与合并，哪怕一天之内进行许多次。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:0","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"首次提交 在进行提交操作时，Git 会保存一个提交对象（commit object）。 假设现在有一个工作目录，里面包含了三个将要被暂存和提交的文件。 暂存操作会为每一个文件计算校验和（使用 SHA-1 哈希算法），然后会把当前版本的文件快照保存到 Git 仓库中 （Git 使用 blob 对象来保存它们），最终将校验和加入到暂存区域等待提交： $ git add README test.rb LICENSE $ git commit -m 'The initial commit of my project' 当使用 git commit 进行提交操作时，Git 会先计算每一个子目录（本例中只有项目根目录）的校验和， 然后在 Git 仓库中这些校验和保存为树对象。随后，Git 便会创建一个提交对象， 它除了包含上面提到的那些信息外，还包含指向这个树对象（项目根目录）的指针。 如此一来，Git 就可以在需要的时候重现此次保存的快照。 现在，Git 仓库中有五个对象：三个 blob 对象（保存着文件快照）、一个 树对象 （记录着目录结构和 blob 对象索引）以及一个 提交对象（包含着指向前述树对象的指针和所有提交信息）。 图1. 首次提交对象及其树结构 ▲ 小结： git add 加入暂存操作，会为每个文件创建计算校验和，以及每个文件对应的文件快照（blob对象）。 git commit 提交操作，计算子目录或跟目录的校验和 保存为树对象。随后，创建一个提交对象，包含着指向树对象的指针和所有提交信息。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:1","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"再次提交 做些修改后再次提交，那么这次产生的提交对象会包含一个指向上次提交对象（父对象）的指针。 图2. 提交对象及其父对象 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:2","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"Git 的分支 Git 的分支，其实本质上仅仅是指向提交对象的可变指针。 Git 的默认分支名字是 master。 在多次提交操作之后，你其实已经有一个指向最后那个提交对象的 master 分支。 master 分支指针会在每次提交时自动向前移动。 Git 的 master 分支并不是一个特殊分支。 它就跟其它分支完全没有区别。 图3. 分支及其提交历史 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:3","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"创建分支 Git 是怎么创建新分支的呢？ 很简单，它只是为你创建了一个可以移动的新的指针。 比如，创建一个 testing 分支， 你需要使用 git branch 命令： $ git branch testing 这会在当前所在的提交对象上创建一个指针。 图4. 两个指向相同提交历史的分支 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:4","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"当前分支的指针 Git 是怎么知道当前在哪一个分支上呢？ 很简单，它有一个名为 HEAD 的特殊指针，指向当前所在的本地分支（译注：将 HEAD 想象为当前分支的别名）。 在本例中，你仍然在 master 分支上。 因为 git branch 命令仅仅 创建 一个新分支，并不会自动切换到新分支中去。 图5. HEAD 指向当前所在的分支 ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:5","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"查看当前所在分支 你可以简单地使用 git log 命令查看各个分支当前所指的对象。 提供这一功能的参数是 --decorate。 $ git log --oneline --decorate f30ab (HEAD -\u003e master, testing) add feature # f30ab提交对象 (HEAD当前所在分支 -\u003e master分支，testing 分支) 34ac2 Fixed bug # 34ac2 提交对象 98ca9 The initial commit of my project # 98ca9 提交对象 正如你所见，当前 master 和 testing 分支均指向校验和以 f30ab 开头的提交对象。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:6","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"分支切换 $ git checkout testing # git checkout \u003c分支名\u003e 这样 HEAD 就指向 testing 分支了。 图6. HEAD 指向当前所在的分支 ▲ 那么，这样的实现方式会给我们带来什么好处呢？ 现在不妨再提交一次： $ vim test.rb $ git commit -a -m 'made a change' 图7. HEAD 分支随着提交操作自动向前移动 ▲ 如图所示，你的 testing 分支向前移动了，但是 master 分支却没有，它仍然指向运行 git checkout 时所指的对象。 这就有意思了，现在我们切换回 master 分支看看： $ git checkout master 图8. 检出时 HEAD 随之移动 ▲ 这条命令做了两件事。 一是使 HEAD 指回 master 分支，二是将工作目录恢复成 master 分支所指向的快照内容。 也就是说，你现在做修改的话，项目将始于一个较旧的版本。 本质上来讲，这就是忽略 testing 分支所做的修改，以便于向另一个方向进行开发。 我们不妨再稍微做些修改并提交： $ vim test.rb $ git commit -a -m 'made other changes' 现在，这个项目的提交历史已经产生了分叉（参见 项目分叉历史）。 因为刚才你创建了一个新分支，并切换过去进行了一些工作，随后又切换回 master 分支进行了另外一些工作。 上述两次改动针对的是不同分支：你可以在不同分支间不断地来回切换和工作，并在时机成熟时将它们合并起来。 而所有这些工作，你需要的命令只有 branch、checkout 和 commit。 图9. 项目分叉历史 ▲ 你可以简单地使用 git log 命令查看分叉历史。 运行 git log --oneline --decorate --graph --all ，它会输出你的提交历史、各个分支的指向以及项目的分支分叉情况。 $ git log --oneline --decorate --graph --all * c2b9e (HEAD, master) made other changes | * 87ab2 (testing) made a change |/ * f30ab add feature * 34ac2 fixed bug * 98ca9 initial commit of my project 由于 Git 的分支实质上仅是包含所指对象校验和（长度为 40 的 SHA-1 值字符串）的文件，所以它的创建和销毁都异常高效。 创建一个新分支就相当于往一个文件中写入 41 个字节（40 个字符和 1 个换行符），如此的简单能不快吗？ 这与过去大多数版本控制系统形成了鲜明的对比，它们在创建分支时，将所有的项目文件都复制一遍，并保存到一个特定的目录。 完成这样繁琐的过程通常需要好几秒钟，有时甚至需要好几分钟。所需时间的长短，完全取决于项目的规模。 而在 Git 中，任何规模的项目都能在瞬间创建新分支。 同时，由于每次提交都会记录父对象，所以寻找恰当的合并基础（译注：即共同祖先）也是同样的简单和高效。 这些高效的特性使得 Git 鼓励开发人员频繁地创建和使用分支。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:7","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"创建分支同时切换 通常我们会在创建一个新分支后立即切换过去，可以使用如下命令： git checkout -b \u003cnewbranchname\u003e ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/:0:8","tags":["Git"],"title":"Git分支-分支原理","uri":"/post/git%E5%88%86%E6%94%AF-%E5%88%86%E6%94%AF%E5%8E%9F%E7%90%86/"},{"categories":["《Git》学习笔记"],"content":"Git分支-远程分支 远程引用是对远程仓库的引用（指针），包括分支、标签等等。 远程分支本质上也是一个指针，指向远程地址 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:0","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"查看远程引用列表与信息 git ls-remote \u003cremote\u003e # 远程引用的完整列表 git remote show \u003cremote\u003e # 远程分支的更多信息 上面两行命令比较少用，更常见的做法是利用远程跟踪分支。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:1","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"远程跟踪分支 远程跟踪分支是远程分支状态的引用。它们是你无法移动的本地引用。一旦你进行了网络通信， Git 就会为你移动它们以精确反映远程仓库的状态。请将它们看做书签， 这样可以提醒你该分支在远程仓库中的位置就是你最后一次连接到它们的位置。 它们以 \u003cremote\u003e/\u003cbranch\u003e 的形式命名。 例如，如果你想要查看最后一次与远程仓库 origin 通信时 master 分支的状态，你可以查看 origin/master 分支。 你与同事合作解决一个问题并且他们推送了一个 iss53 分支，你可能有自己的本地 iss53 分支， 然而在服务器上的分支会以 origin/iss53 来表示。 这可能有一点儿难以理解，让我们来看一个例子。 假设你的网络里有一个在 git.ourcompany.com 的 Git 服务器。 如果你从这里克隆，Git 的 clone 命令会为你自动将其命名为 origin，拉取它的所有数据， 创建一个指向它的 master 分支的指针，并且在本地将其命名为 origin/master。 Git 也会给你一个与 origin 的 master 分支在指向同一个地方的本地 master 分支，这样你就有工作的基础。 笔记：从远程克隆下来的仓库有一个叫origin/master的远程跟踪分支 和 一个本地的master分支 笔记：“origin” 并无特殊含义远程仓库名字 “origin” 与分支名字 “master” 一样，在 Git 中并没有任何特别的含义一样。 同时 “master” 是当你运行 git init 时默认的起始分支名字，原因仅仅是它的广泛使用， “origin” 是当你运行 git clone 时默认的远程仓库名字。 如果你运行 git clone -o booyah，那么你默认的远程分支名字将会是 booyah/master。 图1. 克隆之后的服务器与本地仓库 ▲ 如果你在本地的 master 分支做了一些工作，在同一段时间内有其他人推送提交到 git.ourcompany.com 并且更新了它的 master 分支，这就是说你们的提交历史已走向不同的方向。 即便这样，只要你保持不与 origin 服务器连接（并拉取数据），你的 origin/master 指针就不会移动。 图2. 本地与远程的工作可以分叉 ▲ 如果要与给定的远程仓库同步数据，运行 git fetch \u003cremote\u003e 命令（在本例中为 git fetch origin）。 这个命令查找 “origin” 是哪一个服务器（在本例中，它是 git.ourcompany.com）， 从中抓取本地没有的数据，并且更新本地数据库，移动 origin/master 指针到更新之后的位置。 图3. git fetch 更新你的远程跟踪分支 ▲ 笔记: 本地的 master 分支 可能 和 远程跟踪分支 origin/master 分叉 为了演示有多个远程仓库与远程分支的情况，我们假定你有另一个内部 Git 服务器，仅服务于你的某个敏捷开发团队。 这个服务器位于 git.team1.ourcompany.com。 你可以运行 git remote add 命令添加一个新的远程仓库引用到当前的项目，这个命令我们会在 Git 基础 中详细说明。 将这个远程仓库命名为 teamone，将其作为完整 URL 的缩写。远程仓库名本质上是远程URL的缩写 图4. 添加另一个远程仓库 ▲ 现在，可以运行 git fetch teamone 来抓取远程仓库 teamone 有而本地没有的数据。 因为那台服务器上现有的数据是 origin 服务器上的一个子集， 所以 Git 并不会抓取数据而是会设置远程跟踪分支 teamone/master 指向 teamone 的 master 分支。 图5. 远程跟踪分支 teamone/master ▲ ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:2","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"推送 当你想要公开分享一个分支时，需要将其推送到有写入权限的远程仓库上。 本地的分支并不会自动与远程仓库同步——你必须显式地推送想要分享的分支。 这样，你就可以把不愿意分享的内容放到私人分支上，而将需要和别人协作的内容推送到公开分支。 如果希望和别人一起在名为 serverfix 的分支上工作，你可以像推送第一个分支那样推送它。 运行 git push \u003cremote\u003e \u003cbranch\u003e: $ git push origin serverfix Counting objects: 24, done. Delta compression using up to 8 threads. Compressing objects: 100% (15/15), done. Writing objects: 100% (24/24), 1.91 KiB | 0 bytes/s, done. Total 24 (delta 2), reused 0 (delta 0) To https://github.com/schacon/simplegit * [new branch] serverfix -\u003e serverfix 这里有些工作被简化了。 Git 自动将 serverfix 分支名字展开为 refs/heads/serverfix:refs/heads/serverfix， 那意味着，“推送本地的 serverfix 分支来更新远程仓库上的 serverfix 分支。” 我们将会详细学习 Git 内部原理 的 refs/heads/ 部分， 但是现在可以先把它放在儿。你也可以运行 git push origin serverfix:serverfix， 它会做同样的事——也就是说“推送本地的 serverfix 分支，将其作为远程仓库的 serverfix 分支” 可以通过这种格式来推送本地分支到一个命名不相同的远程分支。 重命名远程仓库上的分支名 如果并不想让远程仓库上的分支叫做 serverfix，可以运行 git push origin serverfix:awesomebranch 来将本地的 serverfix 分支推送到远程仓库上的 awesomebranch 分支。 Note 如何避免每次输入密码如果你正在使用 HTTPS URL 来推送，Git 服务器会询问用户名与密码。 默认情况下它会在终端中提示服务器是否允许你进行推送。如果不想在每一次推送时都输入用户名与密码，你可以设置一个 “credential cache”。 最简单的方式就是将其保存在内存中几分钟，可以简单地运行 git config --global credential.helper cache 来设置它。想要了解更多关于不同验证缓存的可用选项，查看 凭证存储。 下一次其他协作者从服务器上抓取数据时，他们会在本地生成一个远程分支 origin/serverfix，指向服务器的 serverfix 分支的引用： $ git fetch origin remote: Counting objects: 7, done. remote: Compressing objects: 100% (2/2), done. remote: Total 3 (delta 0), reused 3 (delta 0) Unpacking objects: 100% (3/3), done. From https://github.com/schacon/simplegit * [new branch] serverfix -\u003e origin/serverfix 要特别注意的一点是当抓取到新的远程跟踪分支时，本地不会自动生成一份可编辑的副本（拷贝）。 换一句话说，这种情况下，不会有一个新的 serverfix 分支——只有一个不可以修改的 origin/serverfix 指针。 可以运行 git merge origin/serverfix 将这些工作合并到当前所在的分支。 如果想要在自己的 serverfix 分支上工作，可以将其建立在远程跟踪分支之上： $ git checkout -b serverfix origin/serverfix Branch serverfix set up to track remote branch serverfix from origin. Switched to a new branch 'serverfix' 这会给你一个用于工作的本地分支，并且起点位于 origin/serverfix。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:3","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"跟踪分支 从一个远程跟踪分支检出一个本地分支会自动创建所谓的“跟踪分支”（它跟踪的分支叫做“上游分支”）。 跟踪分支是与远程分支有直接关系的本地分支。 如果在一个跟踪分支上输入 git pull，Git 能自动地识别去哪个服务器上抓取、合并到哪个分支。 当克隆一个仓库时，它通常会自动地创建一个跟踪 origin/master 的 master 分支。 然而，如果你愿意的话可以设置其他的跟踪分支，或是一个在其他远程仓库上的跟踪分支，又或者不跟踪 master 分支。 最简单的实例就是像之前看到的那样，运行 git checkout -b \u003cbranch\u003e \u003cremote\u003e/\u003cbranch\u003e。 这是一个十分常用的操作所以 Git 提供了 --track 快捷方式： $ git checkout --track origin/serverfix Branch serverfix set up to track remote branch serverfix from origin. Switched to a new branch 'serverfix' 由于这个操作太常用了，该捷径本身还有一个捷径。 如果你尝试检出的分支 (a) 不存在且 (b) 刚好只有一个名字与之匹配的远程分支，那么 Git 就会为你创建一个跟踪分支： $ git checkout serverfix Branch serverfix set up to track remote branch serverfix from origin. Switched to a new branch 'serverfix' 如果想要将本地分支与远程分支设置为不同的名字，你可以轻松地使用上一个命令增加一个不同名字的本地分支： $ git checkout -b sf origin/serverfix Branch sf set up to track remote branch serverfix from origin. Switched to a new branch 'sf' 现在，本地分支 sf 会自动从 origin/serverfix 拉取。 设置已有的本地分支跟踪一个刚刚拉取下来的远程分支，或者想要修改正在跟踪的上游分支， 你可以在任意时间使用 -u 或 --set-upstream-to 选项运行 git branch 来显式地设置。 $ git branch -u origin/serverfix Branch serverfix set up to track remote branch serverfix from origin. Note 上游快捷方式当设置好跟踪分支后，可以通过简写 @{upstream} 或 @{u} 来引用它的上游分支。 所以在 master 分支时并且它正在跟踪 origin/master 时，如果愿意的话可以使用 git merge @{u} 来取代 git merge origin/master。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:4","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"查看跟踪分支 如果想要查看设置的所有跟踪分支，可以使用 git branch 的 -vv 选项。 这会将所有的本地分支列出来并且包含更多的信息，如每一个分支正在跟踪哪个远程分支与本地分支是否是领先、落后或是都有。 $ git branch -vv iss53 7e424c3 [origin/iss53: ahead 2] forgot the brackets master 1ae2a45 [origin/master] deploying index fix * serverfix f8674d9 [teamone/server-fix-good: ahead 3, behind 1] this should do it testing 5ea463a trying something new 这里可以看到 iss53 分支正在跟踪 origin/iss53 并且 “ahead” 是 2，意味着本地有两个提交还没有推送到服务器上。 也能看到 master 分支正在跟踪 origin/master 分支并且是最新的。 接下来可以看到 serverfix 分支正在跟踪 teamone 服务器上的 server-fix-good 分支并且领先 3 落后 1， 意味着服务器上有一次提交还没有合并入同时本地有三次提交还没有推送。 最后看到 testing 分支并没有跟踪任何远程分支。 需要重点注意的一点是这些数字的值来自于你从每个服务器上最后一次抓取的数据。 这个命令并没有连接服务器，它只会告诉你关于本地缓存的服务器数据。 如果想要统计最新的领先与落后数字，需要在运行此命令前抓取所有的远程仓库。 可以像这样做： $ git fetch --all; git branch -vv ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:5","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"拉取 当 git fetch 命令从服务器上抓取本地没有的数据时，它并不会修改工作目录中的内容。 它只会获取数据然后让你自己合并。 然而，有一个命令叫作 git pull 在大多数情况下它的含义是一个 git fetch 紧接着一个 git merge 命令。 如果有一个像之前章节中演示的设置好的跟踪分支，不管它是显式地设置还是通过 clone 或 checkout 命令为你创建的，git pull 都会查找当前分支所跟踪的服务器与分支， 从服务器上抓取数据然后尝试合并入那个远程分支。 由于 git pull 的魔法经常令人困惑所以通常单独显式地使用 fetch 与 merge 命令会更好一些。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:6","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"删除远程分支 假设你已经通过远程分支做完所有的工作了——也就是说你和你的协作者已经完成了一个特性， 并且将其合并到了远程仓库的 master 分支（或任何其他稳定代码分支）。 可以运行带有 --delete 选项的 git push 命令来删除一个远程分支。 如果想要从服务器上删除 serverfix 分支，运行下面的命令： $ git push origin --delete serverfix To https://github.com/schacon/simplegit - [deleted] serverfix 基本上这个命令做的只是从服务器上移除这个指针。 Git 服务器通常会保留数据一段时间直到垃圾回收运行，所以如果不小心删除掉了，通常是很容易恢复的。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/:0:7","tags":["Git"],"title":"Git分支-远程分支","uri":"/post/git%E5%88%86%E6%94%AF-%E8%BF%9C%E7%A8%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"Git分支的新建与合并-分支操作 文档：Git 分支 - 分支的新建与合并 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:0","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"创建分支并切换 此时有一个需求需要在新的分支iss53上工作： $ git checkout -b iss53 # b表示branch 它是下面两条命令的简写： $ git branch iss53 $ git checkout iss53 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:1","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"切换分支 突然有一个紧急问题要解决，需要在原来的master分支进行修复： $ git checkout master 在切换到master之前，需要iss53分支保持好一个干净的状态（修改都已提交）。 注意：切换分支Git 会重置你的工作目录。 checkout 中文含义 “检出”，checkout \u003cbranch\u003e 检出分支 =\u003e 检出指定分支的代码 =\u003e 重置工作目录并切换分支。 接下来，你要修复这个紧急问题。 建立一个 hotfix 分支，在该分支上工作直到问题解决： $ git checkout -b hotfix # 中间过程在hotfix上修改了代码并提交 $ echo 'test' \u003e ./hotfix.txt $ git add . $ git commit -m 'fixed' ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:2","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"合并分支 $ git checkout master # 首先切回master分支 $ git merge hotfix # 把 hotfix 分支合并过来 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:3","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"删除分支 $ git branch -d hotfix # d表示delete # 然后切回iss53继续工作 $ git checkout iss53 注意删除分支是在 branch 命令上 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:4","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"多次提交之后合并分支 假设你已经修正了 #53 问题，打算合并到master分支： $ git checkout master $ git merga iss53 这看似和之前的合并区别不大。此时你的开发历史从一个更早的地方开始分叉开来（diverged）。 因为，master 分支所在提交并不是 iss53 分支所在提交的直接祖先，Git 不得不做一些额外的工作。 出现这种情况的时候，Git 会使用两个分支的末端所指的快照以及这两个分支的公共祖先，做一个简单的三方合并。 和之前将分支指针向前推进所不同的是，Git 将此次三方合并的结果做了一个新的快照并且自动创建一个新的提交指向它。 这个被称作一次合并提交，它的特别之处在于他有不止一个父提交。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:5","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"遇到冲突时的分支合并 如果你在两个不同的分支中，对同一个文件的同一个部分进行了不同的修改，Git 就没法干净的合并它们，就产生了冲突。 合并过程中出现CONFLICT提升，表示有冲突 $ git merge iss53 Auto-merging index.html CONFLICT (content): Merge conflict in index.html Automatic merge failed; fix conflicts and then commit the result. 使用git status查看未合并状态。 任何因包含合并冲突而有待解决的文件，都会以未合并状态标识出来。 Git 会在有冲突的文件中加入标准的冲突解决标记，这样你可以打开这些包含冲突的文件然后手动解决冲突。 出现冲突的文件会包含一些特殊区段，看起来像下面这个样子： \u003c\u003c\u003c\u003c\u003c\u003c\u003c HEAD:index.html \u003cdiv id=\"footer\"\u003econtact : email.support@github.com\u003c/div\u003e ======= \u003cdiv id=\"footer\"\u003e please contact us at support@github.com \u003c/div\u003e \u003e\u003e\u003e\u003e\u003e\u003e\u003e iss53:index.html 你需要手动解决冲突，解决了所有文件里的冲突之后，对每个文件使用 git add 命令来将其标记为冲突已解决。 一旦暂存这些原本有冲突的文件，Git 就会将它们标记为冲突已解决。 如果你对结果感到满意，并且确定之前有冲突的的文件都已经暂存了，这时你可以输入 git commit 来完成合并提交。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/:0:6","tags":["Git"],"title":"Git分支的新建与合并-分支操作","uri":"/post/git%E5%88%86%E6%94%AF%E7%9A%84%E6%96%B0%E5%BB%BA%E4%B8%8E%E5%90%88%E5%B9%B6-%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C/"},{"categories":["《Git》学习笔记"],"content":"Git分支管理-查看分支 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/:0:0","tags":["Git"],"title":"Git分支管理-查看分支","uri":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"查看分支 $ git branch iss53 * master # 带星号*表示当前所在分支 testing git branch 命令不只是可以创建与删除分支。 如果不加任何参数运行它，会得到当前所有分支的一个列表。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/:0:1","tags":["Git"],"title":"Git分支管理-查看分支","uri":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"查看每个分支的最后提交 $ git branch -v iss53 93b412c fix javascript issue * master 7a98805 Merge branch 'iss53' testing 782fd34 test ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/:0:2","tags":["Git"],"title":"Git分支管理-查看分支","uri":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"查看已(未)合并的分支 --merged 与 --no-merged 这两个选项可以查看哪些分支已经合并或未合并到 当前 分支。 $ git branch --merged # 查看已合并分支列表 iss53 * master 上面列表中分支名字前没有 * 号的分支通常可以使用 git branch -d 删除掉； $ git branch --no-merged # 查看未合并的分支列表 testing 上面显示未合并的分支，尝试使用 git branch -d 命令删除它时会失败： $ git branch -d testing error: The branch 'testing' is not fully merged. If you are sure you want to delete it, run 'git branch -D testing'. 强制删除未合并的分支: $ git branch -D testing 查看指定分支的已(未)合并的分支 上面描述的选项 --merged 和 --no-merged 会在没有给定提交或分支名作为参数时， 分别列出已合并或未合并到 当前 分支的分支。 你总是可以提供一个附加的参数来查看其它分支的合并状态而不必检出它们。 例如，尚未合并到 testing 分支的有哪些？ $ git branch --no-merged testing topicA featureB ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/:0:3","tags":["Git"],"title":"Git分支管理-查看分支","uri":"/post/git%E5%88%86%E6%94%AF%E7%AE%A1%E7%90%86-%E6%9F%A5%E7%9C%8B%E5%88%86%E6%94%AF/"},{"categories":["《Git》学习笔记"],"content":"Git分支开发工作流 文档：Git分支开发工作流 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81/:0:0","tags":["Git"],"title":"Git分支开发工作流","uri":"/post/git%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"categories":["《Git》学习笔记"],"content":"长期分支 因为 Git 使用简单的三方合并，所以就算在一段较长的时间内，反复把一个分支合并入另一个分支，也不是什么难事。 也就是说，在整个项目开发周期的不同阶段，你可以同时拥有多个开放的分支；你可以定期地把某些主题分支合并入其他分支中。 许多使用 Git 的开发者都喜欢使用这种方式来工作，比如只在 master 分支上保留完全稳定的代码，开发过程在dev分支，开发完成后并入test分支进行测试，通过测试的稳定代码才并入master分支中。 dev和test分支不需要保持绝对稳定，但在test通过测试达到稳定状态，就可以被合并入master分支。 事实上我们刚才讨论的，是随着你的提交而不断右移的指针。 稳定分支(master)的指针总是在提交历史中落后一大截，而前沿分支(dev或test)的指针往往比较靠前。 你可以用这种方法维护不同层次的稳定性。 一些大型项目还有一个 proposed（建议） 或 pu: proposed updates（建议更新）分支，它可能因包含一些不成熟的内容而不能进入master 分支。 这么做的目的是使你的分支具有不同级别的稳定性；当它们具有一定程度的稳定性后，再把它们合并入具有更高级别稳定性的分支中。 再次强调一下，使用多个长期分支的方法并非必要，但是这么做通常很有帮助，尤其是当你在一个非常庞大或者复杂的项目中工作时。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81/:0:1","tags":["Git"],"title":"Git分支开发工作流","uri":"/post/git%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"categories":["《Git》学习笔记"],"content":"主题分支 (短期分支) 主题分支对任何规模的项目都适用。 主题分支是一种短期分支，它被用来实现单一特性或其相关工作。 你已经在上一节中你创建的 iss53 和 hotfix 主题分支中看到过这种用法。 你在上一节用到的主题分支（iss53 和 hotfix 分支）中提交了一些更新，并且在它们合并入主干分支之后，你又删除了它们。 这项技术能使你快速并且完整地进行上下文切换（context-switch）——因为你的工作被分散到不同的流水线中，在不同的流水线中每个分支都仅与其目标特性相关，因此，在做代码审查之类的工作的时候就能更加容易地看出你做了哪些改动。 你可以把做出的改动在主题分支中保留几分钟、几天甚至几个月，等它们成熟之后再合并，而不用在乎它们建立的顺序或工作进度。 考虑这样一个例子，你在 master 分支上工作到 C1，这时为了解决一个问题而新建 iss91 分支，在 iss91 分支上工作到 C4，然而对于那个问题你又有了新的想法，于是你再新建一个 iss91v2 分支试图用另一种方法解决那个问题，接着你回到 master 分支工作了一会儿，你又冒出了一个不太确定的想法，你便在 C10 的时候新建一个 dumbidea 分支，并在上面做些实验。 你的提交历史看起来像下面这个样子： 图1. 拥有多个主题分支的提交历史 ▲ 现在，我们假设两件事情：你决定使用第二个方案来解决那个问题，即使用在 iss91v2 分支中方案。 另外，你将 dumbidea 分支拿给你的同事看过之后，结果发现这是个惊人之举。 这时你可以抛弃 iss91 分支（即丢弃 C5 和 C6 提交），然后把另外两个分支合并入主干分支。 最终你的提交历史看起来像下面这个样子： 图2. 合并了 dumbidea 和 iss91v2 分支之后的提交历史 ▲ 我们将会在 分布式 Git 中向你揭示更多有关分支工作流的细节， 因此，请确保你阅读完那个章节之后，再来决定你的下个项目要使用什么样的分支策略（branching scheme）。 请牢记，当你做这么多操作的时候，这些分支全部都存于本地。 当你新建和合并分支的时候，所有这一切都只发生在你本地的 Git 版本库中 —— 没有与服务器发生交互。 ","date":"2020-11-18","objectID":"/post/git%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81/:0:2","tags":["Git"],"title":"Git分支开发工作流","uri":"/post/git%E5%88%86%E6%94%AF%E5%BC%80%E5%8F%91%E5%B7%A5%E4%BD%9C%E6%B5%81/"},{"categories":["《Git》学习笔记"],"content":"Git工具-查看修订版本 Git 能够以多种方式来指定单个提交、一组提交、或者一定范围内的提交。 了解它们并不是必需的，但是了解一下总没坏处。 修订版本指的是：提交 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:0:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"单个修订版本 你可以通过任意一个提交的 40 个字符的完整 SHA-1 散列值来指定它， 不过还有很多更人性化的方式来做同样的事情。本节将会介绍获取单个提交的多种方法。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:1:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"简短的 SHA-1 Git 十分智能，你只需要提供 SHA-1 的前几个字符就可以获得对应的那次提交， 当然你提供的 SHA-1 字符数量不得少于 4 个，并且没有歧义——也就是说， 当前对象数据库中没有其它对象以这段 SHA-1 开头。 例如，要查看你知道其中添加了某个功能的提交，首先运行 git log 命令来定位该提交： $ git log commit 734713bc047d87bf7eac9674765ae793478c50d3 Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Fri Jan 2 18:32:33 2009 -0800 fixed refs handling, added gc auto, updated tests commit d921970aadf03b3cf0e71becdaab3147ba71cdef Merge: 1c002dd... 35cfb2b... Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Thu Dec 11 15:08:43 2008 -0800 Merge commit 'phedders/rdocs' commit 1c002dd4b536e7479fe34593e72e6c6c1819e53b Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Thu Dec 11 14:58:32 2008 -0800 added some blame and merge stuff ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:2:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"查看给定SHA-1值的提交 在本例中，假设你想要的提交其 SHA-1 以 1c002dd.... 开头， 那么你可以用如下几种 git show 的变体来检视该提交（假设简短的版本没有歧义）： $ git show 1c002dd4b536e7479fe34593e72e6c6c1819e53b $ git show 1c002dd4b536e7479f $ git show 1c002d Git 可以为 SHA-1 值生成出简短且唯一的缩写。 如果你在 git log 后加上 --abbrev-commit 参数，输出结果里就会显示简短且唯一的值； 默认使用七个字符，不过有时为了避免 SHA-1 的歧义，会增加字符数： $ git log --abbrev-commit --pretty=oneline ca82a6d changed the version number 085bb3b removed unnecessary test code a11bef0 first commit 通常 8 到 10 个字符就已经足够在一个项目中避免 SHA-1 的歧义。 例如，到 2019 年 2 月为止，Linux 内核这个相当大的 Git 项目， 其对象数据库中有超过 875,000 个提交，包含七百万个对象，也只需要前 12 个字符就能保证唯一性。 Note 关于 SHA-1 的简短说明许多人觉得他们的仓库里有可能出现两个不同的对象其 SHA-1 值相同。 然后呢？如果你真的向仓库里提交了一个对象，它跟之前的某个 不同 对象的 SHA-1 值相同， Git 会发现该对象的散列值已经存在于仓库里了，于是就会认为该对象被写入，然后直接使用它。 如果之后你想检出那个对象时，你将得到先前那个对象的数据。但是这种情况发生的概率十分渺小。 SHA-1 摘要长度是 20 字节，也就是 160 位。 2^80 个随机哈希对象才有 50% 的概率出现一次冲突 （计算冲突机率的公式是 p = (n(n-1)/2) * (1/2^160)) ）。 2^80 是 1.2 x 10^24，也就是一亿亿亿，这是地球上沙粒总数的 1200 倍。举例说一下怎样才能产生一次 SHA-1 冲突。 如果地球上 65 亿个人类都在编程，每人每秒都在产生等价于整个 Linux 内核历史（650 万个 Git 对象）的代码， 并将之提交到一个巨大的 Git 仓库里面，这样持续两年的时间才会产生足够的对象， 使其拥有 50% 的概率产生一次 SHA-1 对象冲突， 这比你编程团队的成员同一个晚上在互不相干的意外中被狼袭击并杀死的机率还要小。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:2:1","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"分支引用 引用特定提交的一种直接方法是，若它是一个分支的顶端的提交， 那么可以在任何需要引用该提交的 Git 命令中直接使用该分支的名称。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:3:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"查看最后一次提交 例如，你想要查看一个分支的最后一次提交的对象，假设 topic1 分支指向提交 ca82a6d... ， 那么以下的命令是等价的： $ git show ca82a6dff817ec66f44342007202690a93763949 $ git show topic1 # topic1是分支名 如果你想知道某个分支指向哪个特定的 SHA-1，或者想看任何一个例子中被简写的 SHA-1， 你可以使用一个叫做 rev-parse 的 Git 探测工具。 你可以在 Git 内部原理 中查看更多关于探测工具的信息。 简单来说，rev-parse 是为了底层操作而不是日常操作设计的。 不过，有时你想看 Git 现在到底处于什么状态时，它可能会很有用。 你可以在你的分支上执行 rev-parse $ git rev-parse topic1 ca82a6dff817ec66f44342007202690a93763949 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:3:1","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"引用日志 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:4:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"HEAD的指向历史 当你在工作时， Git 会在后台保存一个引用日志（reflog）， 引用日志记录了最近几个月你的 HEAD 和分支引用所指向的历史。 你可以使用 git reflog 来查看引用日志 $ git reflog 734713b HEAD@{0}: commit: fixed refs handling, added gc auto, updated d921970 HEAD@{1}: merge phedders/rdocs: Merge made by the 'recursive' strategy. 1c002dd HEAD@{2}: commit: added some blame and merge stuff 1c36188 HEAD@{3}: rebase -i (squash): updating HEAD 95df984 HEAD@{4}: commit: # This is a combination of two commits. 1c36188 HEAD@{5}: rebase -i (squash): updating HEAD 7e05da5 HEAD@{6}: rebase -i (pick): updating HEAD 每当你的 HEAD 所指向的位置发生了变化，Git 就会将这个信息存储到引用日志这个历史记录里。 你也可以通过 reflog 数据来获取之前的提交历史。 如果你想查看仓库中 HEAD 在五次前的所指向的提交，你可以使用 @{n} 来引用 reflog 中输出的提交记录。 $ git show HEAD@{5} 你同样可以使用这个语法来查看某个分支在一定时间前的位置。 例如，查看你的 master 分支在昨天的时候指向了哪个提交，你可以输入 $ git show master@{yesterday} 就会显示昨天 master 分支的顶端指向了哪个提交。 这个方法只对还在你引用日志里的数据有用，所以不能用来查好几个月之前的提交。 可以运行 git log -g 来查看类似于 git log 输出格式的引用日志信息： $ git log -g master commit 734713bc047d87bf7eac9674765ae793478c50d3 Reflog: master@{0} (Scott Chacon \u003cschacon@gmail.com\u003e) Reflog message: commit: fixed refs handling, added gc auto, updated Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Fri Jan 2 18:32:33 2009 -0800 fixed refs handling, added gc auto, updated tests commit d921970aadf03b3cf0e71becdaab3147ba71cdef Reflog: master@{1} (Scott Chacon \u003cschacon@gmail.com\u003e) Reflog message: merge phedders/rdocs: Merge made by recursive. Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Thu Dec 11 15:08:43 2008 -0800 Merge commit 'phedders/rdocs' 值得注意的是，引用日志只存在于本地仓库，它只是一个记录你在 自己 的仓库里做过什么的日志。 其他人拷贝的仓库里的引用日志不会和你的相同，而你新克隆一个仓库的时候，引用日志是空的，因为你在仓库里还没有操作。 git show HEAD@{2.months.ago} 这条命令只有在你克隆了一个项目至少两个月时才会显示匹配的提交—— 如果你刚刚克隆了仓库，那么它将不会有任何结果返回。 Tip 将引用日志想作 Git 版的 shell 历史记录如果你有 UNIX 或者 Linux 的背景，不妨将引用日志想作 Git 版的 shell 历史记录， 重点在于仅与你和你的会话相关，而与他人无关。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:4:1","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"祖先引用 祖先引用是另一种指明一个提交的方式。 如果你在引用的尾部加上一个 ^（脱字符）， Git 会将其解析为该引用的上一个提交。 假设你的提交历史是： $ git log --pretty=format:'%h %s' --graph * 734713b fixed refs handling, added gc auto, updated tests * d921970 Merge commit 'phedders/rdocs' |\\ | * 35cfb2b Some rdoc changes * | 1c002dd added some blame and merge stuff |/ * 1c36188 ignore *.gem * 9b29157 add open3_detach to gemspec file list 你可以使用 HEAD^ 来查看上一个提交，也就是 “HEAD 的父提交”： $ git show HEAD^ commit d921970aadf03b3cf0e71becdaab3147ba71cdef Merge: 1c002dd... 35cfb2b... Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Thu Dec 11 15:08:43 2008 -0800 Merge commit 'phedders/rdocs' Note 在 Windows 上转义脱字符在 Windows 的 cmd.exe 中，^ 是一个特殊字符，因此需要区别对待。 你可以双写它或者将提交引用放在引号中：$ git show HEAD^ # 在 Windows 上无法工作 $ git show HEAD^^ # 可以 $ git show \"HEAD^\" # 可以 你也可以在 ^ 后面添加一个数字来指明想要 哪一个 父提交——例如 d921970^2 代表 “d921970 的第二父提交” 这个语法只适用于合并的提交，因为合并提交会有多个父提交。 合并提交的第一父提交是你合并时所在分支（通常为 master），而第二父提交是你所合并的分支（例如 topic）： $ git show d921970^ commit 1c002dd4b536e7479fe34593e72e6c6c1819e53b Author: Scott Chacon \u003cschacon@gmail.com\u003e Date: Thu Dec 11 14:58:32 2008 -0800 added some blame and merge stuff $ git show d921970^2 commit 35cfb2b795a55793d7cc56a6cc2060b4bb732548 Author: Paul Hedderly \u003cpaul+git@mjr.org\u003e Date: Wed Dec 10 22:22:03 2008 +0000 Some rdoc changes 另一种指明祖先提交的方法是 ~（波浪号）。 同样是指向第一父提交，因此 HEAD~ 和 HEAD^ 是等价的。 而区别在于你在后面加数字的时候。 HEAD~2 代表“第一父提交的第一父提交”，也就是“祖父提交”——Git 会根据你指定的次数获取对应的第一父提交。 例如，在之前的列出的提交历史中，HEAD~3 就是 $ git show HEAD~3 commit 1c3618887afb5fbcbea25b7c013f4e2114448b8d Author: Tom Preston-Werner \u003ctom@mojombo.com\u003e Date: Fri Nov 7 13:47:59 2008 -0500 ignore *.gem 也可以写成 HEAD~~~，也是第一父提交的第一父提交的第一父提交： $ git show HEAD~~~ commit 1c3618887afb5fbcbea25b7c013f4e2114448b8d Author: Tom Preston-Werner \u003ctom@mojombo.com\u003e Date: Fri Nov 7 13:47:59 2008 -0500 ignore *.gem 你也可以组合使用这两个语法——你可以通过 HEAD~3^2 来取得之前引用的第二父提交（假设它是一个合并提交）。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:5:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"提交区间 你已经学会如何单次的提交，现在来看看如何指明一定区间的提交。 当你有很多分支时，这对管理你的分支时十分有用， 你可以用提交区间来解决“这个分支还有哪些提交尚未合并到主分支？”的问题 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:6:0","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"双点 最常用的指明提交区间语法是双点。 这种语法可以让 Git 选出在一个分支中而不在另一个分支中的提交。 例如，你有如下的提交历史 Example history for range selection. Figure 137. Example history for range selection. 你想要查看 experiment 分支中还有哪些提交尚未被合并入 master 分支。 你可以使用 master..experiment 来让 Git 显示这些提交。也就是“在 experiment 分支中而不在 master 分支中的提交”。 为了使例子简单明了，我使用了示意图中提交对象的字母来代替真实日志的输出，所以会显示： $ git log master..experiment D C 反过来，如果你想查看在 master 分支中而不在 experiment 分支中的提交，你只要交换分支名即可。 experiment..master 会显示在 master 分支中而不在 experiment 分支中的提交： $ git log experiment..master F E 查看即将推送到远端的内容 这可以让你保持 experiment 分支跟随最新的进度以及查看你即将合并的内容。 另一个常用的场景是查看你即将推送到远端的内容： $ git log origin/master..HEAD 这个命令会输出在你当前分支中而不在远程 origin 中的提交。 如果你执行 git push 并且你的当前分支正在跟踪 origin/master，由 git log origin/master..HEAD 所输出的提交就是会被传输到远端服务器的提交。如果你留空了其中的一边， Git 会默认为 HEAD。 例如， git log origin/master.. 将会输出与之前例子相同的结果 —— Git 使用 HEAD 来代替留空的一边。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:6:1","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"多点 双点语法很好用，但有时候你可能需要两个以上的分支才能确定你所需要的修订， 比如查看哪些提交是被包含在某些分支中的一个，但是不在你当前的分支上。 Git 允许你在任意引用前加上 ^ 字符或者 --not 来指明你不希望提交被包含其中的分支。 因此下列三个命令是等价的： $ git log refA..refB $ git log ^refA refB $ git log refB --not refA 这个语法很好用，因为你可以在查询中指定超过两个的引用，这是双点语法无法实现的。 比如，你想查看所有被 refA 或 refB 包含的但是不被 refC 包含的提交，你可以使用以下任意一个命令： $ git log refA refB ^refC $ git log refA refB --not refC 这就构成了一个十分强大的修订查询系统，你可以通过它来查看你的分支里包含了哪些东西。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:6:2","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"三点 最后一种主要的区间选择语法是三点，这个语法可以选择出被两个引用 之一 包含但又不被两者同时包含的提交。 再看看之前双点例子中的提交历史。 如果你想看 master 或者 experiment 中包含的但不是两者共有的提交，你可以执行： $ git log master...experiment F E D C 这和通常 log 按日期排序的输出一样，仅仅给出了4个提交的信息。 这种情形下，log 命令的一个常用参数是 --left-right，它会显示每个提交到底处于哪一侧的分支。 这会让输出数据更加清晰。 $ git log --left-right master...experiment \u003c F \u003c E \u003e D \u003e C 有了这些工具，你就可以十分方便地查看你 Git 仓库中的提交。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/:6:3","tags":["Git"],"title":"Git工具-查看修订版本","uri":"/post/git%E5%B7%A5%E5%85%B7-%E6%9F%A5%E7%9C%8B%E4%BF%AE%E8%AE%A2%E7%89%88%E6%9C%AC/"},{"categories":["《Git》学习笔记"],"content":"Git工具-交互式暂存 本节中的几个交互式 Git 命令可以帮助你将文件的特定部分组合成提交。 当你在修改了大量文件后，希望这些改动能拆分为若干提交而不是混杂在一起成为一个提交时，这几个工具会非常有用。 通过这种方式，可以确保提交是逻辑上独立的变更集，同时也会使其他开发者在与你工作时很容易地审核。 如果运行 git add 时使用 -i 或者 --interactive 选项，Git 将会进入一个交互式终端模式，显示类似下面的东西： $ git add -i staged unstaged path 1: unchanged +0/-1 TODO 2: unchanged +1/-1 index.html 3: unchanged +5/-1 lib/simplegit.rb *** Commands *** 1: [s]tatus 2: [u]pdate 3: [r]evert 4: [a]dd untracked 5: [p]atch 6: [d]iff 7: [q]uit 8: [h]elp What now\u003e 可以看到这个命令以和平时非常不同的视图显示了暂存区——基本上与 git status 是相同的信息，但是更简明扼要一些。 它将暂存的修改列在左侧，未暂存的修改列在右侧。 在这块区域后是“Commands”命令区域。 在这里你可以做一些工作，包括暂存文件、取消暂存文件、暂存文件的一部分、添加未被追踪的文件、显示暂存内容的区别。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%9A%82%E5%AD%98/:0:0","tags":["Git"],"title":"Git工具-交互式暂存","uri":"/post/git%E5%B7%A5%E5%85%B7-%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%9A%82%E5%AD%98/"},{"categories":["《Git》学习笔记"],"content":"暂存与取消暂存文件 如果在 What now\u003e 提示符后键入 u 或 2（更新），它会问你想要暂存哪个文件： What now\u003e u staged unstaged path 1: unchanged +0/-1 TODO 2: unchanged +1/-1 index.html 3: unchanged +5/-1 lib/simplegit.rb Update\u003e\u003e 要暂存 TODO 和 index.html 文件，可以输入数字： Update\u003e\u003e 1,2 staged unstaged path * 1: unchanged +0/-1 TODO * 2: unchanged +1/-1 index.html 3: unchanged +5/-1 lib/simplegit.rb Update\u003e\u003e 每个文件前面的 * 意味着选中的文件将会被暂存。 如果在 Update\u003e\u003e 提示符后不输入任何东西并直接按回车，Git 将会暂存之前选择的文件： Update\u003e\u003e updated 2 paths *** Commands *** 1: [s]tatus 2: [u]pdate 3: [r]evert 4: [a]dd untracked 5: [p]atch 6: [d]iff 7: [q]uit 8: [h]elp What now\u003e s staged unstaged path 1: +0/-1 nothing TODO 2: +1/-1 nothing index.html 3: unchanged +5/-1 lib/simplegit.rb 现在可以看到 TODO 与 index.html 文件已经被暂存而 simplegit.rb 文件还未被暂存。 如果这时想要取消暂存 TODO 文件，使用 r 或 3（撤消）选项： *** Commands *** 1: [s]tatus 2: [u]pdate 3: [r]evert 4: [a]dd untracked 5: [p]atch 6: [d]iff 7: [q]uit 8: [h]elp What now\u003e r staged unstaged path 1: +0/-1 nothing TODO 2: +1/-1 nothing index.html 3: unchanged +5/-1 lib/simplegit.rb Revert\u003e\u003e 1 staged unstaged path * 1: +0/-1 nothing TODO 2: +1/-1 nothing index.html 3: unchanged +5/-1 lib/simplegit.rb Revert\u003e\u003e [enter] reverted one path 再次查看 Git 状态，可以看到已经取消暂存 TODO 文件： *** Commands *** 1: [s]tatus 2: [u]pdate 3: [r]evert 4: [a]dd untracked 5: [p]atch 6: [d]iff 7: [q]uit 8: [h]elp What now\u003e s staged unstaged path 1: unchanged +0/-1 TODO 2: +1/-1 nothing index.html 3: unchanged +5/-1 lib/simplegit.rb 如果想要查看已暂存内容的区别，可以使用 d 或 6（区别）命令。 它会显示暂存文件的一个列表，可以从中选择想要查看的暂存区别。 这跟你在命令行指定 git diff --cached 非常相似： *** Commands *** 1: [s]tatus 2: [u]pdate 3: [r]evert 4: [a]dd untracked 5: [p]atch 6: [d]iff 7: [q]uit 8: [h]elp What now\u003e d staged unstaged path 1: +1/-1 nothing index.html Review diff\u003e\u003e 1 diff --git a/index.html b/index.html index 4d07108..4335f49 100644 --- a/index.html +++ b/index.html @@ -16,7 +16,7 @@ Date Finder \u003cp id=\"out\"\u003e...\u003c/p\u003e -\u003cdiv id=\"footer\"\u003econtact : support@github.com\u003c/div\u003e +\u003cdiv id=\"footer\"\u003econtact : email.support@github.com\u003c/div\u003e \u003cscript type=\"text/javascript\"\u003e 通过这些基本命令，可以使用交互式添加模式来轻松地处理暂存区。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%9A%82%E5%AD%98/:1:0","tags":["Git"],"title":"Git工具-交互式暂存","uri":"/post/git%E5%B7%A5%E5%85%B7-%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%9A%82%E5%AD%98/"},{"categories":["《Git》学习笔记"],"content":"暂存补丁 Git 也可以暂存文件的特定部分。 例如，如果在 simplegit.rb 文件中做了两处修改，但只想要暂存其中的一个而不是另一个，Git 会帮你轻松地完成。 在和上一节一样的交互式提示符中，输入 p 或 5（补丁）。 Git 会询问你想要部分暂存哪些文件；然后，对已选择文件的每一个部分，它都会一个个地显示文件区别并询问你是否想要暂存它们： diff --git a/lib/simplegit.rb b/lib/simplegit.rb index dd5ecc4..57399e0 100644 --- a/lib/simplegit.rb +++ b/lib/simplegit.rb @@ -22,7 +22,7 @@ class SimpleGit end def log(treeish = 'master') - command(\"git log -n 25 #{treeish}\") + command(\"git log -n 30 #{treeish}\") end def blame(path) Stage this hunk [y,n,a,d,/,j,J,g,e,?]? 这时有很多选项。 输入 ? 显示所有可以使用的命令列表： Stage this hunk [y,n,a,d,/,j,J,g,e,?]? ? y - stage this hunk n - do not stage this hunk a - stage this and all the remaining hunks in the file d - do not stage this hunk nor any of the remaining hunks in the file g - select a hunk to go to / - search for a hunk matching the given regex j - leave this hunk undecided, see next undecided hunk J - leave this hunk undecided, see next hunk k - leave this hunk undecided, see previous undecided hunk K - leave this hunk undecided, see previous hunk s - split the current hunk into smaller hunks e - manually edit the current hunk ? - print help 通常情况下可以输入 y 或 n 来选择是否要暂存每一个区块， 当然，暂存特定文件中的所有部分或为之后的选择跳过一个区块也是非常有用的。 如果你只暂存文件的一部分，状态输出可能会像下面这样： What now\u003e 1 staged unstaged path 1: unchanged +0/-1 TODO 2: +1/-1 nothing index.html 3: +1/-1 +4/-0 lib/simplegit.rb simplegit.rb 文件的状态很有趣。 它显示出若干行被暂存与若干行未被暂存。 已经部分地暂存了这个文件。 在这时，可以退出交互式添加脚本并且运行 git commit 来提交部分暂存的文件。 也可以不必在交互式添加模式中做部分文件暂存——可以在命令行中使用 git add -p 或 git add --patch 来启动同样的脚本。 更进一步地，可以使用 git reset --patch 命令的补丁模式来部分重置文件， 通过 git checkout --patch 命令来部分检出文件与 git stash save --patch 命令来部分暂存文件。 我们将会在接触这些命令的高级使用方法时了解更多详细信息。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%9A%82%E5%AD%98/:2:0","tags":["Git"],"title":"Git工具-交互式暂存","uri":"/post/git%E5%B7%A5%E5%85%B7-%E4%BA%A4%E4%BA%92%E5%BC%8F%E6%9A%82%E5%AD%98/"},{"categories":["《Git》学习笔记"],"content":"Git 工具 - 重写历史 许多时候，在使用 Git 时，你可能想要修订提交历史。 Git 很棒的一点是它允许你在最后时刻做决定。 你可以在将暂存区内容提交前决定哪些文件进入提交，可以通过 git stash 来决定不与某些内容工作， 也可以重写已经发生的提交就像它们以另一种方式发生的一样。 这可能涉及改变提交的顺序，改变提交中的信息或修改文件，将提交压缩或是拆分， 或完全地移除提交——在将你的工作成果与他人共享之前。 在本节中，你可以学到如何完成这些工作，这样在与他人分享你的工作成果时你的提交历史将如你所愿地展示出来。 Note 在满意之前不要推送你的工作Git 的基本原则之一是，由于克隆中有很多工作是本地的，因此你可以 在本地 随便重写历史记录。 然而一旦推送了你的工作，那就完全是另一回事了，除非你有充分的理由进行更改，否则应该将推送的工作视为最终结果。 简而言之，在对它感到满意并准备与他人分享之前，应当避免推送你的工作。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:0:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"修改最后一次提交 修改你最近一次提交可能是所有修改历史提交的操作中最常见的一个。 对于你的最近一次提交，你往往想做两件事情：简单地修改提交信息， 或者通过添加、移除或修改文件来更改提交实际的内容。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:1:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"修改提交信息 如果，你只是想修改最近一次提交的提交信息，那么很简单： $ git commit --amend 上面这条命令会将最后一次的提交信息载入到编辑器中供你修改。 当保存并关闭编辑器后，编辑器会将更新后的提交信息写入新提交中，它会成为新的最后一次提交。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:1:1","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"修改实际内容 另一方面，如果你想要修改最后一次提交的实际内容，那么流程很相似：首先作出你想要补上的修改， 暂存它们，然后用 git commit --amend 以新的改进后的提交来 替换 掉旧有的最后一次提交， 使用这个技巧的时候需要小心，因为修正会改变提交的 SHA-1 校验和。 它类似于一个小的变基——如果已经推送了最后一次提交就不要修正它。 Tip 修补后的提交可能需要修补提交信息当你在修补一次提交时，可以同时修改提交信息和提交内容。 如果你修补了提交的内容，那么几乎肯定要更新提交消息以反映修改后的内容。另一方面，如果你的修补是琐碎的（如修改了一个笔误或添加了一个忘记暂存的文件）， 那么之前的提交信息不必修改，你只需作出更改，暂存它们，然后通过以下命令避免不必要的编辑器环节即可：$ git commit --amend --no-edit ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:1:2","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"修改多个提交信息 为了修改在提交历史中较远的提交，必须使用更复杂的工具。 Git 没有一个改变历史工具，但是可以使用变基工具来变基一系列提交，基于它们原来的 HEAD 而不是将其移动到另一个新的上面。 通过交互式变基工具，可以在任何想要修改的提交后停止，然后修改信息、添加文件或做任何想做的事情。 可以通过给 git rebase 增加 -i 选项来交互式地运行变基。 必须指定想要重写多久远的历史，这可以通过告诉命令将要变基到的提交来做到。 例如，如果想要修改最近三次提交信息，或者那组提交中的任意一个提交信息， 将想要修改的最近一次提交的父提交作为参数传递给 git rebase -i 命令，即 HEAD~2^ 或 HEAD~3。 记住 ~3 可能比较容易，因为你正尝试修改最后三次提交；但是注意实际上指定了以前的四次提交，即想要修改提交的父提交： $ git rebase -i HEAD~3 再次记住这是一个变基命令——在 HEAD~3..HEAD 范围内的每一个修改了提交信息的提交及其 所有后裔 都会被重写。 不要涉及任何已经推送到中央服务器的提交——这样做会产生一次变更的两个版本，因而使他人困惑。 运行这个命令会在文本编辑器上给你一个提交的列表，看起来像下面这样： pick f7f3f6d changed my name a bit pick 310154e updated README formatting and added blame pick a5f4a0d added cat-file # Rebase 710f0f8..a5f4a0d onto 710f0f8 # # Commands: # p, pick \u003ccommit\u003e = use commit # r, reword \u003ccommit\u003e = use commit, but edit the commit message # e, edit \u003ccommit\u003e = use commit, but stop for amending # s, squash \u003ccommit\u003e = use commit, but meld into previous commit # f, fixup \u003ccommit\u003e = like \"squash\", but discard this commit's log message # x, exec \u003ccommand\u003e = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with 'git rebase --continue') # d, drop \u003ccommit\u003e = remove commit # l, label \u003clabel\u003e = label current HEAD with a name # t, reset \u003clabel\u003e = reset HEAD to a label # m, merge [-C \u003ccommit\u003e | -c \u003ccommit\u003e] \u003clabel\u003e [# \u003coneline\u003e] # . create a merge commit using the original merge commit's # . message (or the oneline, if no original merge commit was # . specified). Use -c \u003ccommit\u003e to reword the commit message. # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 需要重点注意的是相对于正常使用的 log 命令，这些提交显示的顺序是相反的。 运行一次 log 命令，会看到类似这样的东西： $ git log --pretty=format:\"%h %s\" HEAD~3..HEAD a5f4a0d added cat-file 310154e updated README formatting and added blame f7f3f6d changed my name a bit 注意其中的反序显示。 交互式变基给你一个它将会运行的脚本。 它将会从你在命令行中指定的提交（HEAD~3）开始，从上到下的依次重演每一个提交引入的修改。 它将最旧的而不是最新的列在上面，因为那会是第一个将要重演的。 你需要修改脚本来让它停留在你想修改的变更上。 要达到这个目的，你只要将你想修改的每一次提交前面的 ‘pick’ 改为 ‘edit’。 例如，只想修改第三次提交信息，可以像下面这样修改文件： edit f7f3f6d changed my name a bit pick 310154e updated README formatting and added blame pick a5f4a0d added cat-file 当保存并退出编辑器时，Git 将你带回到列表中的最后一次提交，把你送回命令行并提示以下信息： $ git rebase -i HEAD~3 Stopped at f7f3f6d... changed my name a bit You can amend the commit now, with git commit --amend Once you're satisfied with your changes, run git rebase --continue 这些指令准确地告诉你该做什么。 输入 $ git commit --amend 修改提交信息，然后退出编辑器。 然后，运行 $ git rebase --continue 这个命令将会自动地应用另外两个提交，然后就完成了。 如果需要将不止一处的 pick 改为 edit，需要在每一个修改为 edit 的提交上重复这些步骤。 每一次，Git 将会停止，让你修正提交，然后继续直到完成。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:2:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"重新排序提交 也可以使用交互式变基来重新排序或完全移除提交。 如果想要移除 “added cat-file” 提交然后修改另外两个提交引入的顺序，可以将变基脚本从这样： pick f7f3f6d changed my name a bit pick 310154e updated README formatting and added blame pick a5f4a0d added cat-file 改为这样： pick 310154e updated README formatting and added blame pick f7f3f6d changed my name a bit 当保存并退出编辑器时，Git 将你的分支带回这些提交的父提交，应用 310154e 然后应用 f7f3f6d，最后停止。 事实修改了那些提交的顺序并完全地移除了 “added cat-file” 提交。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:3:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"压缩提交 通过交互式变基工具，也可以将一连串提交压缩成一个单独的提交。 在变基信息中脚本给出了有用的指令： # # Commands: # p, pick \u003ccommit\u003e = use commit # r, reword \u003ccommit\u003e = use commit, but edit the commit message # e, edit \u003ccommit\u003e = use commit, but stop for amending # s, squash \u003ccommit\u003e = use commit, but meld into previous commit # f, fixup \u003ccommit\u003e = like \"squash\", but discard this commit's log message # x, exec \u003ccommand\u003e = run command (the rest of the line) using shell # b, break = stop here (continue rebase later with 'git rebase --continue') # d, drop \u003ccommit\u003e = remove commit # l, label \u003clabel\u003e = label current HEAD with a name # t, reset \u003clabel\u003e = reset HEAD to a label # m, merge [-C \u003ccommit\u003e | -c \u003ccommit\u003e] \u003clabel\u003e [# \u003coneline\u003e] # . create a merge commit using the original merge commit's # . message (or the oneline, if no original merge commit was # . specified). Use -c \u003ccommit\u003e to reword the commit message. # # These lines can be re-ordered; they are executed from top to bottom. # # If you remove a line here THAT COMMIT WILL BE LOST. # # However, if you remove everything, the rebase will be aborted. # # Note that empty commits are commented out 如果，指定 “squash” 而不是 “pick” 或 “edit”，Git 将应用两者的修改并合并提交信息在一起。 所以，如果想要这三次提交变为一个提交，可以这样修改脚本： pick f7f3f6d changed my name a bit squash 310154e updated README formatting and added blame squash a5f4a0d added cat-file 当保存并退出编辑器时，Git 应用所有的三次修改然后将你放到编辑器中来合并三次提交信息： # This is a combination of 3 commits. # The first commit's message is: changed my name a bit # This is the 2nd commit message: updated README formatting and added blame # This is the 3rd commit message: added cat-file 当你保存之后，你就拥有了一个包含前三次提交的全部变更的提交。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:4:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"拆分提交 拆分一个提交会撤消这个提交，然后多次地部分地暂存与提交直到完成你所需次数的提交。 例如，假设想要拆分三次提交的中间那次提交。 想要将它拆分为两次提交：第一个 “updated README formatting”，第二个 “added blame” 来代替原来的 “updated README formatting and added blame”。 可以通过修改 rebase -i 的脚本来做到这点，将要拆分的提交的指令修改为 “edit”： pick f7f3f6d changed my name a bit edit 310154e updated README formatting and added blame pick a5f4a0d added cat-file 然后，当脚本带你进入到命令行时，重置那个提交，拿到被重置的修改，从中创建几次提交。 当保存并退出编辑器时，Git 带你到列表中第一个提交的父提交，应用第一个提交（f7f3f6d）， 应用第二个提交（310154e），然后让你进入命令行。 那里，可以通过 git reset HEAD^ 做一次针对那个提交的混合重置，实际上将会撤消那次提交并将修改的文件取消暂存。 现在可以暂存并提交文件直到有几个提交，然后当完成时运行 git rebase --continue： $ git reset HEAD^ $ git add README $ git commit -m 'updated README formatting' $ git add lib/simplegit.rb $ git commit -m 'added blame' $ git rebase --continue Git 在脚本中应用最后一次提交（a5f4a0d），历史记录看起来像这样： $ git log -4 --pretty=format:\"%h %s\" 1c002dd added cat-file 9b29157 added blame 35cfb2b updated README formatting f3cc40e changed my name a bit 再次强调，这些改动了所有在列表中的提交的 SHA-1 校验和，所以要确保列表中的提交还没有推送到共享仓库中。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:5:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"核武器级选项：filter-branch 有另一个历史改写的选项，如果想要通过脚本的方式改写大量提交的话可以使用它——例如，全局修改你的邮箱地址或从每一个提交中移除一个文件。 这个命令是 filter-branch，它可以改写历史中大量的提交，除非你的项目还没有公开并且其他人没有基于要改写的工作的提交做的工作，否则你不应当使用它。 然而，它可以很有用。 你将会学习到几个常用的用途，这样就得到了它适合使用地方的想法。 Caution git filter-branch 有很多陷阱，不再推荐使用它来重写历史。 请考虑使用 git-filter-repo，它是一个 Python 脚本，相比大多数使用 filter-branch 的应用来说，它做得要更好。它的文档和源码可访问 https://github.com/newren/git-filter-repo 获取。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:6:0","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"从每一个提交中移除一个文件 这经常发生。 有人粗心地通过 git add . 提交了一个巨大的二进制文件，你想要从所有地方删除。 可能偶然地提交了一个包括一个密码的文件，然而你想要开源项目。 filter-branch 是一个可能会用来擦洗整个提交历史的工具。 为了从整个提交历史中移除一个叫做 passwords.txt 的文件，可以使用 --tree-filter 选项给 filter-branch： $ git filter-branch --tree-filter 'rm -f passwords.txt' HEAD Rewrite 6b9b3cf04e7c5686a9cb838c3f36a8cb6a0fc2bd (21/21) Ref 'refs/heads/master' was rewritten --tree-filter 选项在检出项目的每一个提交后运行指定的命令然后重新提交结果。 在本例中，你从每一个快照中移除了一个叫作 passwords.txt 的文件，无论它是否存在。 如果想要移除所有偶然提交的编辑器备份文件，可以运行类似 git filter-branch --tree-filter 'rm -f *~' HEAD 的命令。 最后将可以看到 Git 重写树与提交然后移动分支指针。 通常一个好的想法是在一个测试分支中做这件事，然后当你决定最终结果是真正想要的，可以硬重置 master 分支。 为了让 filter-branch 在所有分支上运行，可以给命令传递 --all 选项。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:6:1","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"使一个子目录做为新的根目录 假设已经从另一个源代码控制系统中导入，并且有几个没意义的子目录（trunk、tags 等等）。 如果想要让 trunk 子目录作为每一个提交的新的项目根目录，filter-branch 也可以帮助你那么做： $ git filter-branch --subdirectory-filter trunk HEAD Rewrite 856f0bf61e41a27326cdae8f09fe708d679f596f (12/12) Ref 'refs/heads/master' was rewritten 现在新项目根目录是 trunk 子目录了。 Git 会自动移除所有不影响子目录的提交。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:6:2","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"全局修改邮箱地址 另一个常见的情形是在你开始工作时忘记运行 git config 来设置你的名字与邮箱地址， 或者你想要开源一个项目并且修改所有你的工作邮箱地址为你的个人邮箱地址。 任何情形下，你也可以通过 filter-branch 来一次性修改多个提交中的邮箱地址。 需要小心的是只修改你自己的邮箱地址，所以你使用 --commit-filter： $ git filter-branch --commit-filter ' if [ \"$GIT_AUTHOR_EMAIL\" = \"schacon@localhost\" ]; then GIT_AUTHOR_NAME=\"Scott Chacon\"; GIT_AUTHOR_EMAIL=\"schacon@example.com\"; git commit-tree \"$@\"; else git commit-tree \"$@\"; fi' HEAD 这会遍历并重写每一个提交来包含你的新邮箱地址。 因为提交包含了它们父提交的 SHA-1 校验和，这个命令会修改你的历史中的每一个提交的 SHA-1 校验和， 而不仅仅只是那些匹配邮箱地址的提交。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/:6:3","tags":["Git"],"title":"Git工具-重写历史","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E5%86%99%E5%8E%86%E5%8F%B2/"},{"categories":["《Git》学习笔记"],"content":"Git 工具 - 重置揭密 在继续了解更专业的工具前，我们先探讨一下 Git 的 reset 和 checkout 命令。 在初遇的 Git 命令中，这两个是最让人困惑的。 它们能做很多事情，所以看起来我们很难真正地理解并恰当地运用它们。 针对这一点，我们先来做一个简单的比喻。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:0:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"三棵树 理解 reset 和 checkout 的最简方法，就是以 Git 的思维框架（将其作为内容管理器）来管理三棵不同的树。 “树” 在我们这里的实际意思是 “文件的集合”，而不是指特定的数据结构。 （在某些情况下索引看起来并不像一棵树，不过我们现在的目的是用简单的方式思考它。） Git 作为一个系统，是以它的一般操作来管理并操纵这三棵树的： 树 用途 HEAD 上一次提交的快照，下一次提交的父结点 Index 预期的下一次提交的快照 Working Directory 沙盒 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:1:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"HEAD HEAD 是当前分支引用的指针，它总是指向该分支上的最后一次提交。 这表示 HEAD 将是下一次提交的父结点。 通常，理解 HEAD 的最简方式，就是将它看做 该分支上的最后一次提交 的快照。 其实，查看快照的样子很容易。 下例就显示了 HEAD 快照实际的目录列表，以及其中每个文件的 SHA-1 校验和： $ git cat-file -p HEAD tree cfda3bf379e4f8dba8717dee55aab78aef7f4daf author Scott Chacon 1301511835 -0700 committer Scott Chacon 1301511835 -0700 initial commit $ git ls-tree -r HEAD 100644 blob a906cb2a4a904a152... README 100644 blob 8f94139338f9404f2... Rakefile 040000 tree 99f1a6d12cb4b6f19... lib Git 的 cat-file 和 ls-tree 是底层命令，它们一般用于底层工作，在日常工作中并不使用。 不过它们能帮助我们了解到底发生了什么。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:1:1","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"索引 索引是你的 预期的下一次提交。 我们也会将这个概念引用为 Git 的“暂存区”，这就是当你运行 git commit 时 Git 看起来的样子。 Git 将上一次检出到工作目录中的所有文件填充到索引区，它们看起来就像最初被检出时的样子。 之后你会将其中一些文件替换为新版本，接着通过 git commit 将它们转换为树来用作新的提交。 $ git ls-files -s 100644 a906cb2a4a904a152e80877d4088654daad0c859 0 README 100644 8f94139338f9404f26296befa88755fc2598c289 0 Rakefile 100644 47c6340d6459e05787f644c2447d2595f5d3a54b 0 lib/simplegit.rb 再说一次，我们在这里又用到了 git ls-files 这个幕后的命令，它会显示出索引当前的样子。 确切来说，索引在技术上并非树结构，它其实是以扁平的清单实现的。不过对我们而言，把它当做树就够了。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:1:2","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"工作目录 最后，你就有了自己的 工作目录（通常也叫 工作区）。 另外两棵树以一种高效但并不直观的方式，将它们的内容存储在 .git 文件夹中。 工作目录会将它们解包为实际的文件以便编辑。 你可以把工作目录当做 沙盒。在你将修改提交到暂存区并记录到历史之前，可以随意更改。 $ tree . ├── README ├── Rakefile └── lib └── simplegit.rb 1 directory, 3 files ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:1:3","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"工作流程 经典的 Git 工作流程是通过操纵这三个区域来以更加连续的状态记录项目快照的。 让我们来可视化这个过程：假设我们进入到一个新目录，其中有一个文件。 我们称其为该文件的 v1 版本，将它标记为蓝色。 现在运行 git init，这会创建一个 Git 仓库，其中的 HEAD 引用指向未创建的 master 分支。 此时，只有工作目录有内容。 现在我们想要提交这个文件，所以用 git add 来获取工作目录中的内容，并将其复制到索引中。 接着运行 git commit，它会取得索引中的内容并将它保存为一个永久的快照， 然后创建一个指向该快照的提交对象，最后更新 master 来指向本次提交。 此时如果我们运行 git status，会发现没有任何改动，因为现在三棵树完全相同。 现在我们想要对文件进行修改然后提交它。 我们将会经历同样的过程；首先在工作目录中修改文件。 我们称其为该文件的 v2 版本，并将它标记为红色。 如果现在运行 git status，我们会看到文件显示在 “Changes not staged for commit” 下面并被标记为红色，因为该条目在索引与工作目录之间存在不同。 接着我们运行 git add 来将它暂存到索引中。 此时，由于索引和 HEAD 不同，若运行 git status 的话就会看到 “Changes to be committed” 下的该文件变为绿色 ——也就是说，现在预期的下一次提交与上一次提交不同。 最后，我们运行 git commit 来完成提交。 现在运行 git status 会没有输出，因为三棵树又变得相同了。 切换分支或克隆的过程也类似。 当检出一个分支时，它会修改 HEAD 指向新的分支引用，将 索引 填充为该次提交的快照， 然后将 索引 的内容复制到 工作目录 中。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:2:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"重置的作用 在以下情景中观察 reset 命令会更有意义。 为了演示这些例子，假设我们再次修改了 file.txt 文件并第三次提交它。 现在的历史看起来是这样的： 让我们跟着 reset 看看它都做了什么。 它以一种简单可预见的方式直接操纵这三棵树。 它做了三个基本操作。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:3:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"第 1 步：移动 HEAD reset 做的第一件事是移动 HEAD 的指向。 这与改变 HEAD 自身不同（checkout 所做的）；reset 移动 HEAD 指向的分支。 这意味着如果 HEAD 设置为 master 分支（例如，你正在 master 分支上）， 运行 git reset 9e5e6a4 将会使 master 指向 9e5e6a4。 无论你调用了何种形式的带有一个提交的 reset，它首先都会尝试这样做。 使用 reset --soft，它将仅仅停在那儿。 现在看一眼上图，理解一下发生的事情：它本质上是撤销了上一次 git commit 命令。 当你在运行 git commit 时，Git 会创建一个新的提交，并移动 HEAD 所指向的分支来使其指向该提交。 当你将它 reset 回 HEAD~（HEAD 的父结点）时，其实就是把该分支移动回原来的位置，而不会改变索引和工作目录。 现在你可以更新索引并再次运行 git commit 来完成 git commit --amend 所要做的事情了（见 修改最后一次提交）。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:3:1","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"第 2 步：更新索引（–mixed） 注意，如果你现在运行 git status 的话，就会看到新的 HEAD 和以绿色标出的它和索引之间的区别。 接下来，reset 会用 HEAD 指向的当前快照的内容来更新索引。 如果指定 --mixed 选项，reset 将会在这时停止。 这也是默认行为，所以如果没有指定任何选项（在本例中只是 git reset HEAD~），这就是命令将会停止的地方。 现在再看一眼上图，理解一下发生的事情：它依然会撤销一上次 提交，但还会 取消暂存 所有的东西。 于是，我们回滚到了所有 git add 和 git commit 的命令执行之前。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:3:2","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"第 3 步：更新工作目录（–hard） reset 要做的的第三件事情就是让工作目录看起来像索引。 如果使用 --hard 选项，它将会继续这一步。 现在让我们回想一下刚才发生的事情。 你撤销了最后的提交、git add 和 git commit 命令 以及 工作目录中的所有工作。 必须注意，--hard 标记是 reset 命令唯一的危险用法，它也是 Git 会真正地销毁数据的仅有的几个操作之一。 其他任何形式的 reset 调用都可以轻松撤消，但是 --hard 选项不能，因为它强制覆盖了工作目录中的文件。 在这种特殊情况下，我们的 Git 数据库中的一个提交内还留有该文件的 v3 版本， 我们可以通过 reflog 来找回它。但是若该文件还未提交，Git 仍会覆盖它从而导致无法恢复。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:3:3","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"回顾 reset 命令会以特定的顺序重写这三棵树，在你指定以下选项时停止： 移动 HEAD 分支的指向 （若指定了 --soft，则到此停止） 使索引看起来像 HEAD （若未指定 --hard，则到此停止） 使工作目录看起来像索引 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:3:4","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"通过路径来重置 前面讲述了 reset 基本形式的行为，不过你还可以给它提供一个作用路径。 若指定了一个路径，reset 将会跳过第 1 步，并且将它的作用范围限定为指定的文件或文件集合。 这样做自然有它的道理，因为 HEAD 只是一个指针，你无法让它同时指向两个提交中各自的一部分。 不过索引和工作目录 可以部分更新，所以重置会继续进行第 2、3 步。 现在，假如我们运行 git reset file.txt （这其实是 git reset --mixed HEAD file.txt 的简写形式，因为你既没有指定一个提交的 SHA-1 或分支，也没有指定 --soft 或 --hard），它会： 移动 HEAD 分支的指向 （已跳过） 让索引看起来像 HEAD （到此处停止） 所以它本质上只是将 file.txt 从 HEAD 复制到索引中。 它还有 取消暂存文件 的实际效果。 如果我们查看该命令的示意图，然后再想想 git add 所做的事，就会发现它们正好相反。 这就是为什么 git status 命令的输出会建议运行此命令来取消暂存一个文件。 （查看 取消暂存的文件 来了解更多。） 我们可以不让 Git 从 HEAD 拉取数据，而是通过具体指定一个提交来拉取该文件的对应版本。 我们只需运行类似于 git reset eb43bf file.txt 的命令即可。 它其实做了同样的事情，也就是把工作目录中的文件恢复到 v1 版本，运行 git add 添加它， 然后再将它恢复到 v3 版本（只是不用真的过一遍这些步骤）。 如果我们现在运行 git commit，它就会记录一条“将该文件恢复到 v1 版本”的更改， 尽管我们并未在工作目录中真正地再次拥有它。 还有一点同 git add 一样，就是 reset 命令也可以接受一个 --patch 选项来一块一块地取消暂存的内容。 这样你就可以根据选择来取消暂存或恢复内容了。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:4:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"压缩 我们来看看如何利用这种新的功能来做一些有趣的事情——压缩提交。 假设你的一系列提交信息中有 “oops.”“WIP” 和 “forgot this file”， 聪明的你就能使用 reset 来轻松快速地将它们压缩成单个提交，也显出你的聪明。 （压缩提交 展示了另一种方式，不过在本例中用 reset 更简单。） 假设你有一个项目，第一次提交中有一个文件，第二次提交增加了一个新的文件并修改了第一个文件，第三次提交再次修改了第一个文件。 由于第二次提交是一个未完成的工作，因此你想要压缩它。 那么可以运行 git reset --soft HEAD~2 来将 HEAD 分支移动到一个旧一点的提交上（即你想要保留的最近的提交）： 然后只需再次运行 git commit： 现在你可以查看可到达的历史，即将会推送的历史，现在看起来有个 v1 版 file-a.txt 的提交， 接着第二个提交将 file-a.txt 修改成了 v3 版并增加了 file-b.txt。 包含 v2 版本的文件已经不在历史中了。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:5:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"检出 最后，你大概还想知道 checkout 和 reset 之间的区别。 和 reset 一样，checkout 也操纵三棵树，不过它有一点不同，这取决于你是否传给该命令一个文件路径。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:6:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"不带路径 运行 git checkout [branch] 与运行 git reset --hard [branch] 非常相似，它会更新所有三棵树使其看起来像 [branch]，不过有两点重要的区别。 首先不同于 reset --hard，checkout 对工作目录是安全的，它会通过检查来确保不会将已更改的文件弄丢。 其实它还更聪明一些。它会在工作目录中先试着简单合并一下，这样所有_还未修改过的_文件都会被更新。 而 reset --hard 则会不做检查就全面地替换所有东西。 第二个重要的区别是 checkout 如何更新 HEAD。 reset 会移动 HEAD 分支的指向，而 checkout 只会移动 HEAD 自身来指向另一个分支。 例如，假设我们有 master 和 develop 分支，它们分别指向不同的提交；我们现在在 develop 上（所以 HEAD 指向它）。 如果我们运行 git reset master，那么 develop 自身现在会和 master 指向同一个提交。 而如果我们运行 git checkout master 的话，develop 不会移动，HEAD 自身会移动。 现在 HEAD 将会指向 master。 所以，虽然在这两种情况下我们都移动 HEAD 使其指向了提交 A，但_做法_是非常不同的。 reset 会移动 HEAD 分支的指向，而 checkout 则移动 HEAD 自身。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:6:1","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"带路径 运行 checkout 的另一种方式就是指定一个文件路径，这会像 reset 一样不会移动 HEAD。 它就像 git reset [branch] file 那样用该次提交中的那个文件来更新索引，但是它也会覆盖工作目录中对应的文件。 它就像是 git reset --hard [branch] file（如果 reset 允许你这样运行的话）， 这样对工作目录并不安全，它也不会移动 HEAD。 此外，同 git reset 和 git add 一样，checkout 也接受一个 --patch 选项，允许你根据选择一块一块地恢复文件内容。 ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:6:2","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"总结 希望你现在熟悉并理解了 reset 命令，不过关于它和 checkout 之间的区别，你可能还是会有点困惑，毕竟不太可能记住不同调用的所有规则。 下面的速查表列出了命令对树的影响。 “HEAD” 一列中的 “REF” 表示该命令移动了 HEAD 指向的分支引用，而 “HEAD” 则表示只移动了 HEAD 自身。 特别注意 WD Safe? 一列——如果它标记为 NO，那么运行该命令之前请考虑一下。 HEAD Index Workdir WD Safe? Commit Level reset --soft [commit] REF NO NO YES reset [commit] REF YES NO YES reset --hard [commit] REF YES YES NO checkout \u003ccommit\u003e HEAD YES YES YES File Level reset [commit] \u003cpaths\u003e NO YES NO YES checkout [commit] \u003cpaths\u003e NO YES YES NO ","date":"2020-11-18","objectID":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/:7:0","tags":["Git"],"title":"Git工具-重置揭密","uri":"/post/git%E5%B7%A5%E5%85%B7-%E9%87%8D%E7%BD%AE%E6%8F%AD%E5%AF%86/"},{"categories":["《Git》学习笔记"],"content":"Git基础与命令 官方文档（中文）：https://git-scm.com/book/zh/v2 本文档是根据官方文档来编写的，以官方文档为准。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:0:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"Git基础 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"全局配置 git config --global user.name 'your name' git config --global user.email 'xxx@xx.com' 自报家门 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:1","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"检查配置信息 git config --list ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:2","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"获取帮助 # 获取全局帮助手册 git help # 获取特定命令的详细版帮助手册 (两个命令是等价的) git help \u003c某个命令\u003e git \u003c某个命令\u003e --help # 两个横杠 # 获取特定命令的简明版帮助手册 git \u003c某个命令\u003e -h # 一个横杠 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:3","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"初始化仓库 # 本地目录初始化仓库 git init 如果你是从远程仓库clone的项目，则该项目是已经初始化好的git仓库 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:4","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"克隆远程仓库 # 克隆 git clone \u003curl\u003e # 克隆同时修改目录名 git clone \u003curl\u003e \u003cname\u003e 初次克隆某个仓库的时候，工作目录中的所有文件都属于已跟踪文件，并处于未修改状态，因为 Git 刚刚检出了它们， 而你尚未编辑过它们 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:5","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"检查文件状态 # 查看详细状态说明 git status # 查看简明状态说明 git status -s # -s 或 --short M README # 已修改，但未暂存 （M的位置靠右，红色） MM Rakefile # 已修改，暂存后又作了修改（有暂存和未暂存） A lib/git.rb # 新添加到暂存区，未提交 M lib/simplegit.rb # 已修改，已暂存 （M的位置靠左，绿色） ?? LICENSE.txt # 新添加，未跟踪 git目录中的文件状态包含：是否跟踪、是否修改、是否已存入暂存区 参数的一个横杠表示缩写，两个横杠表示全称。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:6","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"加入暂存区 (跟踪文件) # 文件加入暂存区（跟踪指定文件) git add \u003cfiles\u003e git add 命令使用文件或目录的路径作为参数；如果参数是目录的路径，该命令将递归地跟踪该目录下的所有文件。 add 命令是将文件加入到暂存区，commit 命令的提交到本地仓库，push 命令是推送到远程仓库。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:7","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"忽略文件 添加一个名为 .gitignore 的文件，列出要忽略的文件的模式 *.[oa] # 忽略以 .o 或 .a 结尾的文件（一般这类文件是编译过程出现） *~ # 忽略以 ~ 结尾的文件（一般是文本编辑软件保存的副本） 文件 .gitignore 的格式规范如下： 所有空行或者以 # 开头的行都会被 Git 忽略（注释符号）。 可以使用标准的 glob 模式匹配，它会递归地应用在整个工作区中。 glob 模式是指 shell 所使用的简化了的正则表达式 匹配模式可以以（/）开头防止递归。 匹配模式可以以（/）结尾指定目录。 要忽略指定模式以外的文件或目录，可以在模式前加上叹号（!）取反。 星号（*）匹配零个或多个任意字符 [abc] 匹配任何一个列在方括号中的字符 （这个例子要么匹配一个 a，要么匹配一个 b，要么匹配一个 c） 问号（?）只匹配一个任意字符 [0-9] 表示匹配所有 0 到 9 的数字。在方括号中使用短划线分隔两个字符， 表示所有在这两个字符范围内的都可以匹配 使用两个星号（**）表示匹配任意中间目录，比如 a/**/z 可以匹配 a/z 、 a/b/z 或 a/b/c/z 等。 # 忽略所有的 .a 文件 *.a # 但跟踪所有的 lib.a，即便你在前面忽略了 .a 文件 !lib.a # 只忽略当前目录下的 TODO 文件，而不忽略 subdir/TODO /TODO # 忽略任何目录下名为 build 的文件夹 build/ # 忽略 doc/notes.txt，但不忽略 doc/server/arch.txt doc/*.txt # 忽略 doc/ 目录及其所有子目录下的 .pdf 文件 doc/**/*.pdf GitHub 有一个十分详细的针对数十种项目及语言的 .gitignore 文件列表， 你可以在 https://github.com/github/gitignore 找到它。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:8","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"查看修改的具体内容 git diff # 比较修改之后还没有暂存起来的变化内容。 git diff --staged # 查看已暂存的将要添加到下次提交里的内容 git status 只能查看文件变动的状态，并不能查看具体修改了哪些内容。使用git diff可以看到具体变动的内容。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:9","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"提交更新 git commit # 未带参数的会打开默认文本编辑器让你输入提交说明 git commit -m '提交说明' # 带-m参数直接输入提交说明 使用git commit提交更新，在此之前，务必确认所有变动已经被git add添加到暂存区。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:10","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"跳过使用暂存区域 git commit -a -m '提交说明' 添加-a选项可以跳过git add 步骤，把已经跟踪过的文件一并提交。 注意：这个操作无法提交未跟踪的文件。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:1:11","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"Git 基础 - 查看提交历史 git log 不传入任何参数的默认情况下，git log 会按时间先后顺序列出所有的提交，最近的更新排在最上面。 此命令打印的数据中有一项是一长串的 SHA-1 校验码。 带入-p或--patch 查看提交的具体差异： git log -p -2 # -p显示差异 -2显示最近的提交次数 --stat 显示每次提交的差异统计 git log --stat --pretty 这个选项可以使用不同于默认格式的方式展示提交历史 这个选项有一些内建的子选项供你使用。 比如 oneline 会将每个提交放在一行显示，在浏览大量的提交时非常有用。 另外还有 short，full 和 fuller 选项，它们展示信息的格式基本一致，但是详尽程度不一： $ git log --pretty=oneline ca82a6dff817ec66f44342007202690a93763949 changed the version number 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 removed unnecessary test a11bef06a3f659402fe7563abf99ad00de2209e6 first commit 最有意思的是 format ，可以定制记录的显示格式。 这样的输出对后期提取分析格外有用——因为你知道输出的格式不会随着 Git 的更新而发生改变： $ git log --pretty=format:\"%h - %an, %ar : %s\" ca82a6d - Scott Chacon, 6 years ago : changed the version number 085bb3b - Scott Chacon, 6 years ago : removed unnecessary test a11bef0 - Scott Chacon, 6 years ago : first commit git log --pretty=format 常用的选项 列出了 format 接受的常用格式占位符的写法及其代表的意义。 当 oneline 或 format 与另一个 log 选项 --graph 结合使用时尤其有用。 这个选项添加了一些 ASCII 字符串来形象地展示你的分支、合并历史： $ git log --pretty=format:\"%h %s\" --graph * 2d3acf9 ignore errors from SIGCHLD on trap * 5e3ee11 Merge branch 'master' of git://github.com/dustin/grit |\\ | * 420eac9 Added a method for getting the current branch. * | 30e367c timeout code and tests * | 5a09431 add timeout protection to grit * | e1193f8 support for heads with slashes in them |/ * d6016bc require time for xmlschema * 11d191e Merge branch 'defunkt' into local ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:2:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"Git 基础 - 撤消操作 你提交后发现忘记了暂存某些需要的修改，可以像下面这样操作： $ git commit -m 'initial commit' $ git add forgotten_file $ git commit --amend # 重新提交，且只有一次提交记录 最终你只会有一个提交——第二次提交将代替第一次提交的结果。 更多撤销操作请了解 reset命令。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:3:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"Git 基础 - 远程仓库的使用 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"查看远程仓库 git remote # 仅显示远程仓库的名称 git remote -v # 显示远程仓库的名称 + 地址 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:1","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"添加远程仓库 git remote add \u003c远程仓库名\u003e \u003curl\u003e ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:2","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"从远程仓库中抓取与拉取 就如刚才所见，从远程仓库中获得数据，可以执行： git fetch \u003cremote\u003e 这个命令会访问远程仓库，从中拉取所有你还没有的数据。 执行完成后，你将会拥有那个远程仓库中所有分支的引用，可以随时合并或查看。 注意： git fetch 命令只会将数据下载到你的本地仓库——它并不会自动合并或修改你当前的工作。 当准备好时你必须手动将其合并入你的工作。 git pull 用 git pull 命令来自动抓取后合并该远程分支到当前分支。 这或许是个更加简单舒服的工作流程。默认情况下，git clone 命令会自动设置本地 master 分支跟踪克隆的远程仓库的 master 分支（或其它名字的默认分支）。 运行 git pull 通常会从最初克隆的服务器上抓取数据并自动尝试合并到当前所在的分支。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:3","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"推送到远程仓库 git push \u003cremote\u003e \u003cbranch\u003e # git push origin master ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:4","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"查看某个远程仓库 git remote show \u003cremote\u003e # git remote show origin 查看远程仓库的详细信息。这个命令列出了当你在特定的分支上执行 git push 会自动地推送到哪一个远程分支 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:5","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"远程仓库的重命名与移除 git remote rename \u003c原名\u003e \u003c新名\u003e # 重命名 git remote remove paul \u003cremote\u003e# 移除远程仓库 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:4:6","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"Git 基础 - 打标签 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"列出标签 git tag # 完整标签列表 git tag -l \"v2.0*\" # 只显示包含 v2.0 的标签。 注意加星号(*) -l 或 --list 都可以。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:1","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"创建标签 Git 支持两种标签：轻量标签（lightweight）与附注标签（annotated）。 轻量标签很像一个不会改变的分支——它只是某个特定提交的引用。 而附注标签是存储在 Git 数据库中的一个完整对象， 它们是可以被校验的，其中包含打标签者的名字、电子邮件地址、日期时间， 此外还有一个标签信息，并且可以使用 GNU Privacy Guard （GPG）签名并验证。 通常会建议创建附注标签，这样你可以拥有以上所有信息。但是如果你只是想用一个临时的标签， 或者因为某些原因不想要保存这些信息，那么也可以用轻量标签。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:2","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"附注标签 git tag -a v1.4 -m \"my version 1.4\" # -a表示add， -m 表示附件信息 通过使用 git show 命令可以看到标签信息和与之对应的提交信息： git show v1.4 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:3","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"轻量标签 轻量标签本质上是将提交校验和存储到一个文件中——没有保存任何其他信息。 创建轻量标签，不需要使用 -a、-s 或 -m 选项，只需要提供标签名字： git tag v1.4-lw # 不需要添加选项 这时，如果在标签上运行 git show，你不会看到额外的标签信息。 命令只会显示出提交信息： $ git show v1.4-lw commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u003cschacon@gee-mail.com\u003e Date: Mon Mar 17 21:52:11 2008 -0700 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:4","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"后期打标签 你也可以对过去的提交打标签。 假设提交历史是这样的： $ git log --pretty=oneline 166ae0c4d3f420721acbb115cc33848dfcc2121a started write support 9fceb02d0ae598e95dc970b74767f19372d61af8 updated rakefile 8a5cbc430f1a9c3d00faaeffd07798508422908a updated readme 现在，假设在 v1.2 时你忘记给项目打标签，也就是在 “updated rakefile” 提交。 你可以在之后补上标签。 要在那个提交上打标签，你需要在命令的末尾指定提交的校验和（或部分校验和）： $ git tag -a v1.2 9fceb02 # 打的标签属于附注标签 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:5","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"共享标签 git push 命令并不会传送标签到远程仓库服务器上。 在创建完标签后你必须显式地推送标签到共享服务器上。 这个过程就像共享远程分支一样——你可以运行 git push origin \u003ctagname\u003e。 git push origin v1.5 # 显式地推送标签到远程仓库 git push origin --tags # 一次性推送所有不在远程仓库上的标签 现在，当其他人从仓库中克隆或拉取，他们也能得到你的那些标签。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:6","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"删除标签 要删除掉你本地仓库上的标签，可以使用命令 git tag -d \u003ctagname\u003e。 例如，可以使用以下命令删除一个轻量标签： $ git tag -d v1.4-lw Deleted tag 'v1.4-lw' (was e7d5add) 注意上述命令并不会从任何远程仓库中移除这个标签，你必须用 git push \u003cremote\u003e :refs/tags/\u003ctagname\u003e 来更新你的远程仓库： 第一种变体是 git push \u003cremote\u003e :refs/tags/\u003ctagname\u003e ： $ git push origin :refs/tags/v1.4-lw To /git@github.com:schacon/simplegit.git - [deleted] v1.4-lw 上面这种操作的含义是，将冒号前面的空值推送到远程标签名，从而高效地删除它。 第二种更直观的删除远程标签的方式是： $ git push origin --delete \u003ctagname\u003e ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:7","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"检出标签 如果你想查看某个标签所指向的文件版本，可以使用 git checkout 命令， 虽然这会使你的仓库处于“分离头指针（detached HEAD）”的状态——这个状态有些不好的副作用： $ git checkout 2.0.0 Note: checking out '2.0.0'. You are in 'detached HEAD' state. You can look around, make experimental changes and commit them, and you can discard any commits you make in this state without impacting any branches by performing another checkout. If you want to create a new branch to retain commits you create, you may do so (now or later) by using -b with the checkout command again. Example: git checkout -b \u003cnew-branch\u003e HEAD is now at 99ada87... Merge pull request #89 from schacon/appendix-final $ git checkout 2.0-beta-0.1 Previous HEAD position was 99ada87... Merge pull request #89 from schacon/appendix-final HEAD is now at df3f601... add atlas.json and cover image 在“分离头指针”状态下，如果你做了某些更改然后提交它们，标签不会发生变化， 但你的新提交将不属于任何分支，并且将无法访问，除非通过确切的提交哈希才能访问。 因此，如果你需要进行更改，比如你要修复旧版本中的错误，那么通常需要创建一个新分支： $ git checkout -b version2 v2.0.0 Switched to a new branch 'version2' 如果在这之后又进行了一次提交，version2 分支就会因为这个改动向前移动， 此时它就会和 v2.0.0 标签稍微有些不同，这时就要当心了。 ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:5:8","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"Git 命令别名 Git 并不会在你输入部分命令时自动推断出你想要的命令。 如果不想每次都输入完整的 Git 命令，可以通过 git config 文件来轻松地为每一个命令设置一个别名。 这里有一些例子你可以试试： $ git config --global alias.co checkout $ git config --global alias.br branch $ git config --global alias.ci commit $ git config --global alias.st status 这意味着，当要输入 git commit 时，只需要输入 git ci。 在创建你认为应该存在的命令时这个技术会很有用。 例如，为了解决取消暂存文件的易用性问题，可以向 Git 中添加你自己的取消暂存别名： $ git config --global alias.unstage 'reset HEAD --' 这会使下面的两个命令等价： $ git unstage fileA $ git reset HEAD -- fileA 这样看起来更清楚一些。 通常也会添加一个 last 命令，像这样： $ git config --global alias.last 'log -1 HEAD' 这样，可以轻松地看到最后一次提交： $ git last commit 66938dae3329c7aebe598c2246a8e6af90d04646 Author: Josh Goebel \u003cdreamer3@example.com\u003e Date: Tue Aug 26 19:48:51 2008 +0800 test for current head Signed-off-by: Scott Chacon \u003cschacon@example.com\u003e 可以看出，Git 只是简单地将别名替换为对应的命令。 然而，你可能想要执行外部命令，而不是一个 Git 子命令。 如果是那样的话，可以在命令前面加入 ! 符号。 如果你自己要写一些与 Git 仓库协作的工具的话，那会很有用。 我们现在演示将 git visual 定义为 gitk 的别名： $ git config --global alias.visual '!gitk' ","date":"2020-11-18","objectID":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/:6:0","tags":["Git"],"title":"Git基础与命令","uri":"/post/git%E5%9F%BA%E7%A1%80%E4%B8%8E%E5%91%BD%E4%BB%A4/"},{"categories":["《Git》学习笔记"],"content":"常用Git命令清单 一般来说，日常使用只要记住下图6个命令，就可以了。但是熟练使用，恐怕要记住60～100个命令。 下面是我整理的常用 Git 命令清单。几个专用名词的译名如下。 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:0:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"一、新建代码库 # 在当前目录新建一个Git代码库 $ git init # 新建一个目录，将其初始化为Git代码库 $ git init [project-name] # 下载一个项目和它的整个代码历史 $ git clone [url] ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:1:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"二、配置 Git的设置文件为.gitconfig，它可以在用户主目录下（全局配置），也可以在项目目录下（项目配置）。 # 显示当前的Git配置 $ git config --list # 编辑Git配置文件 $ git config -e [--global] # 设置提交代码时的用户信息 $ git config [--global] user.name \"[name]\" $ git config [--global] user.email \"[email address]\" ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:2:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"三、增加/删除文件 # 添加指定文件到暂存区 $ git add [file1] [file2] ... # 添加指定目录到暂存区，包括子目录 $ git add [dir] # 添加当前目录的所有文件到暂存区 $ git add . # 添加每个变化前，都会要求确认 # 对于同一个文件的多处变化，可以实现分次提交 $ git add -p # 删除工作区文件，并且将这次删除放入暂存区 $ git rm [file1] [file2] ... # 停止追踪指定文件，但该文件会保留在工作区 $ git rm --cached [file] # 改名文件，并且将这个改名放入暂存区 $ git mv [file-original] [file-renamed] ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:3:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"四、代码提交 # 提交暂存区到仓库区 $ git commit -m [message] # 提交暂存区的指定文件到仓库区 $ git commit [file1] [file2] ... -m [message] # 提交工作区自上次commit之后的变化，直接到仓库区 $ git commit -a # 提交时显示所有diff信息 $ git commit -v # 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] # 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:4:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"五、分支 # 列出所有本地分支 $ git branch # 列出所有远程分支 $ git branch -r # 列出所有本地分支和远程分支 $ git branch -a # 新建一个分支，但依然停留在当前分支 $ git branch [branch-name] # 新建一个分支，并切换到该分支 $ git checkout -b [branch] # 新建一个分支，指向指定commit $ git branch [branch] [commit] # 新建一个分支，与指定的远程分支建立追踪关系 $ git branch --track [branch] [remote-branch] # 切换到指定分支，并更新工作区 $ git checkout [branch-name] # 切换到上一个分支 $ git checkout - # 建立追踪关系，在现有分支与指定的远程分支之间 $ git branch --set-upstream [branch] [remote-branch] # 合并指定分支到当前分支 $ git merge [branch] # 选择一个commit，合并进当前分支 $ git cherry-pick [commit] # 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:5:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"六、标签 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:6:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"七、查看信息 # 显示有变更的文件 $ git status # 显示当前分支的版本历史 $ git log # 显示commit历史，以及每次commit发生变更的文件 $ git log --stat # 搜索提交历史，根据关键词 $ git log -S [keyword] # 显示某个commit之后的所有变动，每个commit占据一行 $ git log [tag] HEAD --pretty=format:%s # 显示某个commit之后的所有变动，其\"提交说明\"必须符合搜索条件 $ git log [tag] HEAD --grep feature # 显示某个文件的版本历史，包括文件改名 $ git log --follow [file] $ git whatchanged [file] # 显示指定文件相关的每一次diff $ git log -p [file] # 显示过去5次提交 $ git log -5 --pretty --oneline # 显示所有提交过的用户，按提交次数排序 $ git shortlog -sn # 显示指定文件是什么人在什么时间修改过 $ git blame [file] # 显示暂存区和工作区的差异 $ git diff # 显示暂存区和上一个commit的差异 $ git diff --cached [file] # 显示工作区与当前分支最新commit之间的差异 $ git diff HEAD # 显示两次提交之间的差异 $ git diff [first-branch]...[second-branch] # 显示今天你写了多少行代码 $ git diff --shortstat \"@{0 day ago}\" # 显示某次提交的元数据和内容变化 $ git show [commit] # 显示某次提交发生变化的文件 $ git show --name-only [commit] # 显示某次提交时，某个文件的内容 $ git show [commit]:[filename] # 显示当前分支的最近几次提交 $ git reflog ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:7:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"八、远程同步 # 下载远程仓库的所有变动 $ git fetch [remote] # 显示所有远程仓库 $ git remote -v # 显示某个远程仓库的信息 $ git remote show [remote] # 增加一个新的远程仓库，并命名 $ git remote add [shortname] [url] # 取回远程仓库的变化，并与本地分支合并 $ git pull [remote] [branch] # 上传本地指定分支到远程仓库 $ git push [remote] [branch] # 强行推送当前分支到远程仓库，即使有冲突 $ git push [remote] --force # 推送所有分支到远程仓库 $ git push [remote] --all ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:8:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"九、撤销 # 恢复暂存区的指定文件到工作区 $ git checkout [file] # 恢复某个commit的指定文件到暂存区和工作区 $ git checkout [commit] [file] # 恢复暂存区的所有文件到工作区 $ git checkout . # 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变 $ git reset [file] # 重置暂存区与工作区，与上一次commit保持一致 $ git reset --hard # 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变 $ git reset [commit] # 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致 $ git reset --hard [commit] # 重置当前HEAD为指定commit，但保持暂存区和工作区不变 $ git reset --keep [commit] # 新建一个commit，用来撤销指定commit # 后者的所有变化都将被前者抵消，并且应用到当前分支 $ git revert [commit] # 暂时将未提交的变化移除，稍后再移入 $ git stash $ git stash pop ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:9:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"十、常用操作组合 ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:10:0","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":["《Git》学习笔记"],"content":"1. 修改本地分支名和远程分支名 git branch -m old_branch new_branch # 重命名本地分支 git push origin :old_branch # 删除远程旧分支（分支名前有冒号） git push --set-upstream origin new_branch # 推送新的分支，并设置本地分支跟踪新的远程分支 相关文章： 《如何撤销 Git 操作？》 《git cherry-pick 教程》 复制某分支上的部分提交到另一个分支上（相对于可以选择指定提交的 rebase 操作）。 命令清单来源：https://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html ","date":"2020-11-18","objectID":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/:10:1","tags":["Git"],"title":"常用Git命令清单","uri":"/post/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/"},{"categories":null,"content":"离线 - 蜷缩的蜗牛","date":"0001-01-01","objectID":"/offline/","tags":null,"title":"","uri":"/offline/"},{"categories":null,"content":"Hey Welcome here 👋 ","date":"0001-01-01","objectID":"/offline/:1:0","tags":null,"title":"","uri":"/offline/"},{"categories":null,"content":"目前正在学习Service Mesh ","date":"0001-01-01","objectID":"/offline/:2:0","tags":null,"title":"","uri":"/offline/"},{"categories":null,"content":"汇编和工具: 🛠 Check for a detailed stats here :point_right: Sourcerer ","date":"0001-01-01","objectID":"/offline/:3:0","tags":null,"title":"","uri":"/offline/"}]