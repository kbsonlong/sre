<rss xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title>kubernetes - 标签 - 蜷缩的蜗牛</title><link>https://www.alongparty.cn/tags/kubernetes/</link><description>kubernetes - 标签 - 蜷缩的蜗牛</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><managingEditor>kbsonlong@gmail.com (kbsonlong)</managingEditor><webMaster>kbsonlong@gmail.com (kbsonlong)</webMaster><copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright><lastBuildDate>Tue, 18 Apr 2023 21:53:59 +0800</lastBuildDate><atom:link href="https://www.alongparty.cn/tags/kubernetes/" rel="self" type="application/rss+xml"/><item><title>源码分析 kubernetes scheduler 核心调度器的实现原理</title><link>https://www.alongparty.cn/posts/a3f5fa/</link><pubDate>Tue, 18 Apr 2023 21:53:59 +0800</pubDate><author>kbsonlong</author><guid>https://www.alongparty.cn/posts/a3f5fa/</guid><description>基于 kubernetes v1.27.0 源码分析 scheduler 调度器 k8s scheduler 的主要职责是为新创建的 pod 寻找一个最合适的 node 节点, 然后进行 bind node 绑定, 后面 kubelet 才会监听到并创建真正的 pod. 那么问题来了, 如</description></item><item><title>企业级弹性伸缩和优化建设</title><link>https://www.alongparty.cn/posts/6ac5f6/</link><pubDate>Mon, 01 Aug 2022 09:54:52 +0800</pubDate><author>kbsonlong</author><guid>https://www.alongparty.cn/posts/6ac5f6/</guid><description><![CDATA[<p>什么是弹性伸缩？弹性伸缩和成本优化是何关系？ 应该如何做好企业级弹性伸缩与成本优化建设？</p>
<h2 id="一-背景">一 背景</h2>
<p>传统意义上来讲，弹性伸缩主要解决的问题是容量规划与实际负载的矛盾, 这矛盾通常因为资源使用普遍具有以下几个问题导致：</p>
<blockquote>
<p>（1）在线服务申请资源时考虑到突发流量和服务稳定性，预留大量的 buffer 资源，造成资源申请量普遍远超实际使用量。</p>
</blockquote>
<blockquote>
<p>（2）大部分在线服务的潮汐现象、波峰波谷特征非常明显，保留过多常态资源造成巨大浪费。</p>
</blockquote>
<blockquote>
<p>（3）开发和运维评估和配置的资源规格不合理，并且动态更新不及时。</p>
</blockquote>]]></description></item><item><title>理解 Kubernetes 的亲和性调度</title><link>https://www.alongparty.cn/posts/understand-kubernetes-affinity/</link><pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate><author>kbsonlong</author><guid>https://www.alongparty.cn/posts/understand-kubernetes-affinity/</guid><description><![CDATA[<p>一般情况下我们部署的 POD 是通过集群自动调度选择某个节点的，默认情况下调度器考虑的是资源足够，并且负载尽量平均，但是有的时候我们需要能够更加细粒度的去控制 POD 的调度，比如我们内部的一些服务 gitlab 之类的也是跑在<code>Kubernetes</code>集群上的，我们就不希望对外的一些服务和内部的服务跑在同一个节点上了，害怕内部服务对外部的服务产生影响；有的时候呢我们两个服务直接交流比较频繁，又希望能够将这两个服务的 POD 调度到同样的节点上。这就需要用到 Kubernetes 里面的一个概念：亲和性，亲和性主要分为两类：<code>nodeAffinity</code>和<code>podAffinity</code>。</p>]]></description></item></channel></rss>